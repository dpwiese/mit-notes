\chapter{Preliminaries}

\section{Introduction}

\subsection{Complex Numbers}

Any complex number can be represented in exponential form, recalling Euler's formula $e^{j\theta}=\cos(\theta)+j\sin(\theta)$.
Considering this representation of a complex number $re^{j\theta}=r\cos(\theta)+jr\sin(\theta)$ we can see that in the complex plane $r$ represents the magnitude of the complex number, and $\theta$ is the angle.
Additionally, the angle of a product of two complex numbers is the sum of the angles of each complex number.
That is
\begin{equation*}
  \angle c_{1}c_{2}=\angle c_{1}\angle c_{2}
\end{equation*}

\subsection{Inverting a 2\texorpdfstring{$\times$}{x}2 Matrix}

For the following $2\times 2$ matrix $A$
\begin{equation*}
  A=\begin{bmatrix} a & b \\ c & d \end{bmatrix}
\end{equation*}
the inverse $A^{-1}$ is:
\begin{equation*}
  A^{-1}=\frac{1}{\det(A)}\begin{bmatrix} d & -b \\ -c & a \end{bmatrix}
\end{equation*}

\section{Norms}

\subsection{Introduction}

In this note several types of norms will be explained.
Given two real numbers, the notion of the ``size'' of these numbers is apparent.
However, given quantity such as a vector or a matrix, we may by interested in how ``big'' they are when compared to another vector or matrix, respectively.
A norm is a strictly positive measure of the ``magnitude'' of such a quantity.
In particular, a norm is an operation on a vector that returns a non-negative quantity.

In the following section, the capital letter $A$ will be reserved to denote matrices, while the lower case letter $x$ will be used for vectors, and time dependency will be added to imply time-varying vector-values signals.
$H(t)$, $g(t)$ and $G(s)$ for systems described by transfer functions?
Vectors are assumed to be columns.
The four types of norms described in this section are:
\begin{enumerate}
  \item{Vector}
  \item{Matrix}
  \item{Signal}
  \item{System}
\end{enumerate}

\subsubsection{Properties of Norms}
Norms satisfy three basic properties below, where $x,y,z\in\mathbb{R}^{n}$, and $\alpha\in\mathbb{R}$.
\begin{enumerate}
  \setlength{\itemsep}{-4pt}
  \item{Norms are always non-negative: $\|x\|\geq0$, and the norm of the zero element is zero: $\|x\|=0$ if and only if $x=0$}
  \item{Norms are scalable: $\|\alpha x\|=|\alpha|\|x\|$}
  \item{Norms satisfy the triangle inequality: $\|x+y\|\leq\|x\|+\|y\|$}
\end{enumerate}
There are some more properties of norms which can be constructed from these four.

\subsection{Vector Norms}

There are several common norms which are used to determine the ``length'' of a given vector, described below.
Often vector norms are denoted by the lowercase letter $l_{p}$.

\paragraph{p-Norm}
Denoted $\|x\|_{p}$, and defined as follows.
\begin{equation*}
  \|x\|_{p}=\left(\sum_{i=1}^{n}|x_{i}|^{p}\right)^{\frac{1}{p}}
\end{equation*}

\paragraph{2-Norm}
The 2-norm, or Euclidean-norm is denoted $\|x\|_{2}=\|x\|$.
This is basically an extension of Euclidean length to $n$-dimensional spaces.
Taken by squaring each entry of the vector, adding up all the squares, and then taking the square root.
\begin{equation*}
  \|x\|_{2}=\left(\sum_{i=1}^{n}|x_{i}|^{2}\right)^{\frac{1}{2}}=\sqrt{\sum_{i=1}^{n}|x_{i}|^{2}}
\end{equation*}
\begin{equation*}
  \|x\|_{2}=\sqrt{x^{\text{H}}x}
\end{equation*}

\paragraph{1-Norm}
The 1-norm, or Taxicab norm is denoted $\|x\|_{1}$.
This norm corresponds to distance in a similar way as the Euclidean norm, but is given by the length of the vector that a taxicab driver would have to drive along a rectangular street grid.
It is taken by adding up the absolute value of each entry of the vector and adding them all up.
\begin{equation*}
  \|x\|_{1}=\sum_{i=1}^{n}|x_{i}|
\end{equation*}

\paragraph{$\infty$-Norm}
Denoted $\|x\|_{\infty}$.
The infinity norm of a vector $x$ is the largest magnitude of an entry of the vector.
\begin{equation*}
  \|x\|_{\infty}=\text{max}\{|x_{1}|,|x_{2}|,\dots,|x_{n}|\}
\end{equation*}

\subsubsection{Examples}

\begin{example}
  \textbf{Vector norms}
  Let $v=\begin{bmatrix} 3 & 0 & -4 \end{bmatrix}^{\top}$.
  The following norms are
  \begin{equation*}
    \begin{split}
      \|v\|_{2}&=\sqrt{v^{\top}v}=\sqrt{9+0+16}=5 \\
      \|v\|_{1}&=3+4=7 \\
      \|v\|_{\infty}&=4
    \end{split}
  \end{equation*}
  %You can verify that the scalability and triangle inequality properties are satisfied for the vector $v$
\end{example}

\subsection{Matrix Norms}
Matrix norms are an extension of vector norms.
After having been introduced to vector norms, it is not immediately intuitive how to extend this concept to a meaningful measure of the ``size'' of a given matrix.
Two matrix norms described below are induced norms and entry wise norms.

\subsubsection{Induced Norms}

Induced norms are norms on a matrix $A$ which require multiplication of the $A$ by a vector $x$, and then evaluate the norm of the resulting vector, normalized by $\|x\|_{p}$.

\paragraph{Induced $p$-Norm}
The general definition for an induced norm is given below.
\begin{equation*}
  \|A\|_{p}=\max_{x\neq0}\frac{\|Ax\|_{p}}{\|x\|_{p}}=\max\left\{\|Ax\|_{p}\;:\;x\in K^{n}\;\text{with }\|x\|_{p}=1\right\}
\end{equation*}
where $p\in\mathbb{N}^{+}$.
Depending on what particular value of $p$ is used for evaluating this norm, there are different interpretations, some of the common ones which are described below.

\paragraph{Induced 1-Norm}
For the induced taxicab, or 1-norm, this corresponds to taking the maximum absolute column sum of the matrix.

\paragraph{Induced $\infty$-Norm}
For the induced infinity norm, it is calculated by taking the maximum absolute row sum of the matrix.

\paragraph{Induced 2-Norm}
The induced Euclidean, or 2-norm for a square matrix $A$ is given by the largest singular value of $A$.
The singular values of $A$ are given by taking the square root of the eigenvalues of $A^{\text{H}}A$.
That is:
\begin{equation*}
\|A\|_{1}=\sqrt{\lambda_{\max}(A^{\text{H}}A)}=\sigma_{\max}(A)
\end{equation*}

\subsubsection{Entrywise Norms}
Entrywise norms are matrix norms which are taken directly on a matrix $A$ itself, without first requiring multiplication by a vector $x$.

\paragraph{Frobenius Norm}
The Frobenius norm is calculated by taking the absolute value of each entry of the matrix $A$, squaring it, adding them all together, and then taking the square root.
\begin{equation*}
\|A\|_{\text{F}}=\sqrt{\sum_{i=1}^{m}\sum_{j=1}^{n}|A_{i,j}|^{2}}=\sqrt{\text{tr}(A^{\text{H}}A)}=\sqrt{\text{tr}(AA^{\text{H}})}
\end{equation*}

\subsubsection{Examples}

\begin{example}
\textbf{Matrix norms}
Let $A=\begin{bmatrix} 3 & 0 \\ 2 & -4 \end{bmatrix}^{\top}$.
The following norms are
\begin{equation*}
\begin{split}
\|A\|_{2}&=4.76 \\
\|A\|_{1}&=5 \\
\|A\|_{\infty}&=6 \\
\|A\|_{\text{F}}&=5.39
\end{split}
\end{equation*}
\end{example}

\subsection{Signal Norms}

The next quantity which we apply the concept of a norm to is that of a signal.
Given a signal (either vector-valued or scalar), we wish to determine some measure of its magnitude.
Perhaps the signal is very large at one instance of time, and small everywhere else, or maybe it is moderately large for all time.
Whatever the case may be, we wish to have some way to quantify these varying degrees of the ``largeness'' of a signal.

Often signal norms are denoted using the capital letter $L_{p}$.
The notation $L$ in $L_{p}$ refers to the fact that the integrand in (2.7) should be Lebesgue-integrable for the integral to exist.
This is a generalization of the standard (Riemann) integral to a more general class of functions.
See DDV Chapter 15.
Signals norms are generalizations of vector norms.
The signal norms we consider in this subsection are the following:

\begin{itemize}
  \item{1-norm: action}
  \item{2-norm squared: signal energy}
  \item{$\infty$-norm: peak signal magnitude}
  \item{signal power (average energy)}
\end{itemize}
For the vector valued signal $x(t)$ the following norms are given.
\paragraph{$L_{p}$ Norm}
\begin{equation*}
  \|x(t)\|_{L_{p}}=\left(\int_{-\infty}^{\infty}\|x(t)\|^{p}dt\right)^{\frac{1}{p}}
\end{equation*}

\paragraph{$L_{1}$ Norm}
\begin{equation*}
  \|x(t)\|_{L_{1}}=\int_{-\infty}^{\infty}\|x(t)\|dt
\end{equation*}

\paragraph{$L_{2}$ Norm}
\begin{equation*}
  \|x(t)\|_{L_{2}}=\sqrt{\int_{-\infty}^{\infty}\|x(t)\|^{2}dt}
\end{equation*}

\paragraph{$L_{\infty}$ Norm}
\begin{equation*}
  \|x(t)\|_{L_{\infty}}=\sup_{t}\|x(t)\|
\end{equation*}

\subsubsection{Examples}

\begin{example}
\textbf{Signal norms}
Let $x(t)=$.
The following norms are
\begin{equation*}
\begin{split}
\|x(t)\|_{L_{2}}&= \\
\|x(t)\|_{L_{1}}&= \\
\|x(t)\|_{L_{\infty}}&=
\end{split}
\end{equation*}
\end{example}

\subsubsection{Existence of Signals in Normed Spaces?}

Explain here what notation $e(t)\in\mathcal{L}^{\infty}$ and so on.

\subsection{System Norms}

In addition to the $H_{2}$ norm, which we have seen gives a characterization of the average gain of a system, a perhaps more fundamental norm for systems is the $H_{\infty}$ norm, which provides a measure of a worst-case system gain.
The $H_{\infty}$ norm is simply a measure of the largest factor by which any sinusoid is magnified by the system.

\paragraph{$L_{1}$ Induced Norm}

\paragraph{$L_{2}$ Induced Norm}
\begin{equation*}
  \|G(s)\|_{2}=\sqrt{\int_{0}^{\infty}\text{tr}[{g(t)}^{\text{T}}g(t)]dt}
\end{equation*}
\begin{equation*}
  \|G(s)\|_{2}=\sqrt{\frac{1}{2\pi}\int_{-\infty}^{\infty}\text{tr}[{G(j\omega)}^{\text{H}}G(j\omega)]d\omega}
\end{equation*}
\begin{equation*}
  \|G(s)\|_{2}=\sup_{\omega}(\sigma_{\max}G(j\omega))
\end{equation*}
\begin{equation*}
  \|G(s)\|_{2}=\sqrt{\text{tr}(B^{\text{T}}QB)} \quad \text{where} \quad
  QA+A^{\text{T}}Q+C^{\text{T}}C=0
\end{equation*}
\begin{equation*}
  \|G(s)\|_{2}=\sqrt{\text{tr}(CPC^{\text{T}})} \quad \text{where} \quad
  AP+PA^{\text{T}}+BB^{\text{T}}=0
\end{equation*}

\paragraph{$L_{\infty}$ Induced Norm}

\section{Canonical State-Space Forms}

There are four standard, or canonical state space forms into which a transfer function can be written.
Two of these forms, namely the observable canonical form and the controllable canonical form, are often called companion forms.
The other two canonical forms are modal and Jordan canonical forms.
Each of these four different state space realizations has its own uses and benefits, which will be outlined below.
The form of controllable and observable canonical forms will be shown below, where the former will contain a row whose coefficients are that of the transfer function denominator polynomial, and the latter a column.
If the row of coefficients is on the bottom of the system A matrix, this is sometimes referred to as controllability, and on the top referred to as controller.
Likewise the column of coefficients on the left is called observer, and on the right observability.
See Kailath (1980).

Often the easiest way to demonstrate the process of writing a transfer function in state space form is by example.
The following examples will illustrate the conversion process for small systems, but this procedure will extend to systems with arbitrarily large numerators and denominators.
For these first examples, assume every transfer function is strictly proper, i.e.\ the order of the numerator is less than the order of the denominator.
See the following section for proper transfer functions.

\subsubsection{Controller Canonical Form}

Given the following transfer function, convert to controller canonical form.
Converting this transfer function to a state space representation in controller canonical form will result in a system that is guaranteed to be controllable.
\begin{equation*}
  G(s)=\frac{b_2s^2+b_1s+b_0}{s^3+a_2s^2+a_1s+a_0}
\end{equation*}
A transfer function is an expression of an output/input.
If $y$ is used to indicate an output, $u$ an input, and $x$ a state, the above transfer function can be written:
\begin{equation*}
  G(s)=\frac{y}{u}=\frac{y}{x}\frac{x}{u}
\end{equation*}
Using this representation, the transfer function can be split into two products:
\begin{equation*}
  \frac{y}{x}=b_2s^2+b_1s+b_0
\end{equation*}
and:
\begin{equation*}
  \frac{x}{u}=\frac{1}{s^3+a_2s^2+a_1s+a_0}
\end{equation*}
Rearranging each of these equations and taking the inverse Laplace transform:
\begin{equation*}
  y=b_2\ddot{x}+b_1\dot{x}+b_0x
\end{equation*}
and:
\begin{equation*}
  \dddot{x}+a_2\ddot{x}+a_1\dot{x}+a_0x=u
\end{equation*}
The order of the system, i.e.\ the number of state variables needed is equal to the order of the transfer function denominator.
For this example, 3 state variables are needed.
Define $x_1$ to be the first state variable, and build each subsequent state variable as a derivative of the first one.
\begin{equation*}
  \begin{split}
    x_1&=x \\
    x_2&=\dot{x}_1=\dot{x} \\
    x_3&=\dot{x}_2=\ddot{x}
  \end{split}
\end{equation*}
Plugging in these state variable definitions:
\begin{equation*}
  y=b_2x_3+b_1x_2+b_0x_1
\end{equation*}
and:
\begin{equation*}
  \dot{x}_3+a_2x_3+a_1x_2+a_0x_1=u
\end{equation*}
Rearranging the above:
\begin{equation*}
  \dot{x}_3=-a_2x_3-a_1x_2-a_0x_1+u
\end{equation*}
Rearranging the state variable definitions and assembling the above into matrix form gives:
\begin{equation*}
  \begin{split}
    \dot{x}_1&=x_2 \\
    \dot{x}_2&=x_3 \\
    \dot{x}_3&=-a_0x_1-a_1x_2-a_2x_3+u
  \end{split}
\end{equation*}
and:
\begin{equation*}
  \begin{bmatrix}
    \dot{x}_1 \\ %[0.6em]
    \dot{x}_2 \\
    \dot{x}_3 \\
  \end{bmatrix}=
  \begin{bmatrix}
    0 & 1 & 0 \\ %[0.6em]
    0 & 0 & 1 \\
    -a_0 & -a_1 & -a_2 \\
  \end{bmatrix}
  \begin{bmatrix}
    x_1 \\ %[0.6em]
    x_2 \\
    x_3 \\
  \end{bmatrix}+
  \begin{bmatrix}
    0 \\ %[0.6em]
    0 \\
    1 \\
  \end{bmatrix}u
\end{equation*}

\begin{equation*}
  y=
  \begin{bmatrix}
    b_0 & b_1 & b_2
  \end{bmatrix}
  \begin{bmatrix}
    x_1 \\ %[0.6em]
    x_2 \\
    x_3 \\
  \end{bmatrix}
\end{equation*}


\subsubsection{Observer Canonical Form}

\begin{equation*}
  G(s)=\frac{y}{u}=\frac{b_2s^2+b_1s+b_0}{s^3+a_2s^2+a_1s+a_0}
\end{equation*}

\begin{equation*}
  {y}{(s^3+a_2s^2+a_1s+a_0)}={u}{(b_2s^2+b_1s+b_0)}
\end{equation*}

\begin{equation*}
  \dddot{y}+a_2\ddot{y}+a_1\dot{y}+a_0y=b_2\ddot{u}+b_1\dot{u}+b_0u
\end{equation*}

\begin{equation*}
  \dddot{y}=b_2\ddot{u}-a_2\ddot{y}+b_1\dot{u}-a_1\dot{y}+b_0u-a_0y
\end{equation*}

\begin{equation*}
  \dot{y}=b_2{u}-a_2{y}+\int(b_1{u}-a_1{y})+\iint(b_0u-a_0y)
\end{equation*}

\begin{equation*}
  y=x_1
\end{equation*}

\begin{equation*}
  \dot{x}_1=b_2{u}-a_2{x}_1+\int(b_1{u}-a_1{x_1})+\iint(b_0u-a_0x_1)
\end{equation*}

\begin{equation*}
  x_2=\int(b_1{u}-a_1{x_1})+\iint(b_0u-a_0x_1)
\end{equation*}

\begin{equation*}
  \dot{x}_2=(b_1{u}-a_1{x_1})+\int(b_0u-a_0x_1)
\end{equation*}

\begin{equation*}
  x_3=\int{b_0u-a_0x_1}
\end{equation*}

\begin{equation*}
  \dot{x}_3={b_0u-a_0x_1}
\end{equation*}

\begin{equation*}
  \begin{split}
    \dot{x}_1&=-a_2{x}_1+x_2+b_2{u} \\
    \dot{x}_2&=-a_1{x_1}+x_3+b_1{u} \\
    \dot{x}_3&=-a_0x_1+b_0u
  \end{split}
\end{equation*}

\begin{equation*}
  \begin{bmatrix}
    \dot{x}_1 \\ %[0.6em]
    \dot{x}_2 \\
    \dot{x}_3 \\
  \end{bmatrix}=
  \begin{bmatrix}
    -a_2 & 1 & 0 \\ %[0.6em]
    -a_1 & 0 & 1 \\
    -a_0 & 0 & 0 \\
  \end{bmatrix}
  \begin{bmatrix}
    x_1 \\ %[0.6em]
    x_2 \\
    x_3 \\
  \end{bmatrix}+
  \begin{bmatrix}
    b_2 \\ %[0.6em]
    b_1 \\
    b_0 \\
  \end{bmatrix}u
\end{equation*}

\begin{equation*}
  y=
  \begin{bmatrix}
    1 & 0 & 0
  \end{bmatrix}
  \begin{bmatrix}
    x_1 \\ %[0.6em]
    x_2 \\
    x_3 \\
  \end{bmatrix}
\end{equation*}

\subsubsection{Modal Canonical Form}

\begin{equation*}
  G(s)=\frac{b_2s^2+b_1s+b_0}{(s+a_1)(s+a_2)(s+a_3)}
\end{equation*}

\begin{equation*}
  G(s)=\frac{b_2s^2+b_1s+b_0}{(s+a_1)(s+a_2)(s+a_3)}=\frac{r_1}{(s+a_1)}+\frac{r_2}{(s+a_2)}+\frac{r_3}{(s+a_3)}
\end{equation*}

\begin{equation*}
  b_2s^2+b_1s+b_0=(s+a_2)(s+a_3)r_1+(s+a_1)(s+a_3)r_2+(s+a_1)(s+a_2)r_3
\end{equation*}

\begin{equation*}
b_2s^2+b_1s+b_0=[s^2+(a_2+a_3)+a_2a_3]r_1+[s^2+(a_1+a_3)+a_2a_3]r_2+[s^2+(a_2+a_3)+a_1a_2]r_3
\end{equation*}
Equating polynomial coefficients:
\begin{equation*}
  \begin{split}
    b_2&=r_1+r_2+r_3 \\
    b_1&=(a_2+a_3)r_1+(a_1+a_3)r_2+(a_1+a_2)r_3 \\
    b_0&=a_2a_3r_1+a_1a_3r_2+a_1a_2r_3
  \end{split}
\end{equation*}
For the arbitrarily large transfer function, this will give $n$ equations in $n$ unknowns, where $n$ is the order of the denominator polynomial, allowing the partial fraction expansion to be completed.
\begin{equation*}
  G(s)=\frac{y}{u}=\frac{r_1}{(s+a_1)}+\frac{r_2}{(s+a_2)}+\frac{r_3}{(s+a_3)}
\end{equation*}
\begin{equation*}
  \frac{y}{u}=\frac{y}{x}\frac{x}{u}=\frac{r_1}{(s+a_1)}+\frac{r_2}{(s+a_2)}+\frac{r_3}{(s+a_3)}
\end{equation*}
\begin{equation*}
  \frac{x}{u}=\frac{x_1}{u}+\frac{x_2}{u}+\frac{x_3}{u}=\frac{r_1}{(s+a_1)}+\frac{r_2}{(s+a_2)}+\frac{r_3}{(s+a_3)}
\end{equation*}
\begin{equation*}
  \frac{x_1}{u}=\frac{r_1}{(s+a_1)}
\end{equation*}
\begin{equation*}
  \frac{x_2}{u}=\frac{r_2}{(s+a_2)}
\end{equation*}
\begin{equation*}
  \frac{x_3}{u}=\frac{r_3}{(s+a_3)}
\end{equation*}
\begin{equation*}
  \dot{x}_1=-a_1x_1+r_1u
\end{equation*}
\begin{equation*}
  \dot{x}_2=-a_2x_2+r_2u
\end{equation*}
\begin{equation*}
  \dot{x}_3=-a_3x_3+r_3u
\end{equation*}
\begin{equation*}
  \begin{bmatrix}
    \dot{x}_1 \\ %[0.6em]
    \dot{x}_2 \\
    \dot{x}_3 \\
  \end{bmatrix}=
  \begin{bmatrix}
    -a_1 & 0 & 0 \\ %[0.6em]
    0 & a_2 & 0 \\
    0 & 0 & -a_3 \\
  \end{bmatrix}
  \begin{bmatrix}
    x_1 \\ %[0.6em]
    x_2 \\
    x_3 \\
  \end{bmatrix}+
  \begin{bmatrix}
    r_1 \\ %[0.6em]
    r_2 \\
    r_3 \\
  \end{bmatrix}u
\end{equation*}
\begin{equation*} y=
  \begin{bmatrix}
    1 & 1 & 1
  \end{bmatrix}
  \begin{bmatrix}
    x_1 \\ %[0.6em]
    x_2 \\
    x_3 \\
  \end{bmatrix}
\end{equation*}
\begin{equation*}
  \begin{bmatrix}
    \dot{x}_1 \\ %[0.6em]
    \dot{x}_2 \\
    \dot{x}_3 \\
  \end{bmatrix}=
  \begin{bmatrix}
    -a_1 & 0 & 0 \\ %[0.6em]
    0 & a_2 & 0 \\
    0 & 0 & -a_3 \\
  \end{bmatrix}
  \begin{bmatrix}
    x_1 \\ %[0.6em]
    x_2 \\
    x_3 \\
  \end{bmatrix}+
  \begin{bmatrix}
    1 \\ %[0.6em]
    1 \\
    1 \\
  \end{bmatrix}u
\end{equation*}
\begin{equation*} y=
  \begin{bmatrix}
    r_1 & r_2 & r_3
  \end{bmatrix}
  \begin{bmatrix}
    x_1 \\ %[0.6em]
    x_2 \\
    x_3 \\
  \end{bmatrix}
\end{equation*}

\subsubsection{Jordan Canonical Form}
Lec.\ 7\textemdash6

\subsection{Proper Transfer Functions}

\section{Singular Values}

A measure of the ``smallness'' of the matrix is needed: the singular values.
The singular value decomposition of a matrix $M$ is the following factorization, where $(\cdot)^{*}$ denotes the Hermitian, or conjugate transpose.
\begin{equation*}
  M=U\Sigma V^{*}
\end{equation*}
where $U$ and $V^{*}$ are real or complex unitary matrices, i.e.\ $U^{*}U=UU^{*}=I$, and $\Sigma$ is diagonal matrix with nonnegative real numbers on the diagonal.
The diagonal entries of $\Sigma$ are the singular values of $M$.
Taking the Hermitian transpose of $M$ gives $M^{*}=(U\Sigma V^{*})^{*}=V\Sigma^{*}U^{*}$.
Both pre- and post- multiplying $M$ with its Hermitian transpose:
\begin{equation*}
  \begin{split}
    MM^{*}&=U\Sigma V^{*}V\Sigma^{*}U^{*}=U\Sigma \Sigma^{*}U^{*} \\
    M^{*}M&=V\Sigma^{*}U^{*}U\Sigma V^{*}=V\Sigma^{*}\Sigma V^{*}
  \end{split}
\end{equation*}
Since $\Sigma$ is diagonal, this can be rearranged into the following eigenvalue problems, allowing the singular values to be found as the non-zero eigenvalues of $M^{*}M$ or $MM^{*}$.
\begin{equation*}
  \begin{split}
    (MM^{*})U&=U(\Sigma \Sigma^{*}) \\
    (M^{*}M)V&=V(\Sigma^{*}\Sigma)
  \end{split}
\end{equation*}

When the matrix $M$ is a transfer function matrix $H(j\omega)$, the magnitude at a any frequency $\omega$ will depend on the direction of the input.
Different singular values will be excited depending on the input.
However, for any input the magnitude of $H(j\omega)$ is bounded above by its maximum singular value $\overline{\sigma}(H(j\omega))$ and below by its minimum singular value $\underline{\sigma}(H(j\omega))$.
For performance and stability robustness $\underline{\sigma}(H(j\omega))$ should be large at low frequencies and $\overline{\sigma}(H(j\omega))$ should be small at high frequencies.

To generate the singular value plot for the linear system $\dot{x}=Ax+Bu$ with output given by $y=Cx$, the transfer function matrix $H$ must first be calculated:
\begin{equation*}
  H(s)=C(sI-A)^{-1}B
\end{equation*}
When the linear system $\dot{x}=Ax+Bu$ is augmented with integral error states, and full state feedback control law $u=-Kx$ is used, the linear system becomes $\dot{x}= (A-B_1K)x+B_2x_{i,r}$, $y=Ix$, with transfer function matrix
\begin{equation*}
  H(s)=I(sI-(A-B_{1}K))^{-1}B_{2}
\end{equation*}
The singular values for each transfer function matrix $H$ above can then be plotted versus frequency.

\section{Positive Definiteness}

The matrix $BB^{\text{T}}=(BB^{\text{T}})^{\text{T}}$ is symmetric for all $B$.
In addition, $BB^{\text{T}}>0$ is positive definite.
Definition of positive definiteness: $x^{\text{T}}BB^{\text{T}}x>0$.
$x\in\mathbb{R}^{n\times 1}$ and $B\in\mathbb{R}^{n\times m}$.
Define $C=B^{\text{T}}x$, where $C\in\mathbb{R}^{m\times1}$ giving $C^{\text{T}}C=\|C\|_{2}^{2}>0\;\forall C\neq0$

\section{Sensitivity Analysis}

\subsection{Introduction}

\noindent The system $\dot{x}=f(x_,u)$ describing the dynamics of the GHV was previously linearized and written
\begin{equation*}
  \dot{x}=Ax+Bu
\end{equation*}
where the state vector x for the model is in body axes as shown in previous work.
It is desired to transform this linear system to use a new state which describes the GHV dynamics in stability axes.
The subscript $(\cdot)_{s}$ indicates stability axes, and the state vector is shown below.
\begin{equation*}
  \label{stability_x_1}
  x_{s} =
  [\begin{array}{cccccccccccc}
    V_{T} &  \alpha & \beta & p & q & r & \phi & \theta & \psi & \lambda & \tau & \mathscr{R}
  \end{array}]^T
\end{equation*}
After completing the transformation from body to stability axes, it was verified that the system poles had not changed between $A$ and $A_{s}$.
Next, a linear transformation was needed in order to rearrange the states in $x_{s}$ so that the longitudinal and lateral/directional states would be grouped together, and any states which did not influence the flight dynamics could be truncated.
This transformation was accomplished using the transformation matrix $\mathbb{O}$.
The entries of $\mathbb{O}$ are zero everywhere, with the exception of ones placed to rearrange the states as described above.
\begin{equation*}
  \label{stability_x_2}
  x_{s}' =
  [\begin{array}{ccccc|cccc|ccc} % chktex 44
    V_{T} &  \alpha & q &\theta & \mathscr{R} & \beta &p & r & \phi &\psi &\lambda & \tau
  \end{array}]^T
\end{equation*}
Defining the transformation
\begin{equation*}
  x_{s}'=\mathbb{O}x_{s}
\end{equation*}
\begin{equation*}
  x_{s}=\mathbb{O}^{-1}x_{s}'
\end{equation*}
\begin{equation*}
  \dot{x}_{s}=\mathbb{O}^{-1}\dot{x}_{s}'
\end{equation*}
\begin{equation*}
  \dot{x}_{s}=A_{s}x_{s}+B_{s}u
\end{equation*}
\begin{equation*}
  \mathbb{O}^{-1}\dot{x}_{s}'=A_{s}\mathbb{O}^{-1}x_{s}'+B_{s}u
\end{equation*}
\begin{equation*}
  \dot{x}_{s}'=\mathbb{O}A\mathbb{O}^{-1}x_{s}'+\mathbb{O}B_{s}u
\end{equation*}
\begin{equation*}
  {A}_{s}'=\mathbb{O}A_{s}\mathbb{O}^{-1}
\end{equation*}
\begin{equation*}
  \dot{x}_{s}'=A_{s}'x_{s}'+B_{s}'u
\end{equation*}

%Truncating $\psi$, $\lambda$, and $\tau$
%\begin{equation*}
%\dot{\tilde{x}}_{s}=\tilde{A}_{s}\tilde{x}_{s}+\tilde{B}_{s}u
%\end{equation*}
%The new state vector $\tilde{x}_{s}$ is given in stability axes, with states grouped according to their modal contributions, and truncating states which have negligible contributions to the modes.
%  \begin{equation*}\label{stability_x}
%\tilde{x}_{s}=[\begin{array}{ccccc|cccc}
%                V_{T} &  \alpha & q &\theta & \mathscr{R} & \beta & p & r & \phi
%              \end{array}]^T
%\end{equation*}
%The longitudinal states are
%  \begin{equation*}
%\tilde{x}_{s,long} = [\begin{array}{ccccc}
%                V_{T} &  \alpha & q &\theta & \mathscr{R}
%              \end{array}]^T
%\end{equation*}
%and the lateral states
%  \begin{equation*}
%\tilde{x}_{s,lat} = [\begin{array}{cccc}
%                \beta & p & r & \phi
%              \end{array}]^T
%\end{equation*}

\subsection{Examining Modal Decomposition} %ref etkin pg66

After rearranging the original state-space system with state vector $x$ into system with state vector $x_{s}'$, the system was examined to check the validity of decoupling the lateral and longitudinal dynamics, and the truncation of the navigation states.
Looking at the following transformed state-space system shown above, and considering only the initial condition response, the following autonomous system results
\begin{equation*}
  \dot{x}_{s}'=A_{s}'x_{s}'
\end{equation*}
The following transformation is introduced
\begin{equation*}
  x_{s}'=\mathbb{V}q
\end{equation*}
where $\mathbb{V}$ is the matrix of eigenvectors $\mathbb{V}\triangleq[\begin{array}{c;{2pt/2pt}c;{2pt/2pt}c} \mathrm{\textbf{v}}_{1} & \cdots & \mathrm{\textbf{v}}_{n} \end{array}]$ giving
\begin{equation*}
  \dot{x}_{s}'=\mathbb{V}\dot{q}
\end{equation*}
\begin{equation*}
  \dot{q}=\mathbb{V}^{-1}A_{s}'\mathbb{V}q
\end{equation*}
The matrix $\mathbb{V}A_{s}'\mathbb{V}^{-1}$ must be examined.
\begin{equation*}
  A_{s}'\mathbb{V}=A_{s}'[
  \begin{array}
    {c;{2pt/2pt}c;{2pt/2pt}c} \mathrm{\textbf{v}}_{1} & \cdots & \mathrm{\textbf{v}}_{n}
  \end{array}
  ]=[
  \begin{array}
    {c;{2pt/2pt}c;{2pt/2pt}c} A_{s}'\mathrm{\textbf{v}}_{1} & \cdots & A_{s}'\mathrm{\textbf{v}}_{n}
  \end{array}
  ]=[
  \begin{array}
    {c;{2pt/2pt}c;{2pt/2pt}c} \mathrm{\textbf{v}}_{1}\lambda_{1} & \cdots & \mathrm{\textbf{v}}_{n}\lambda_{n}
  \end{array}
  ]=\mathbb{V}\Lambda{}
\end{equation*}
giving
\begin{equation*}
  \dot{q}=\Lambda{q}
\end{equation*}
where $\Lambda$ is the diagonal matrix of eigenvalues.
The solution is given by
\begin{equation*}
  q(t)=e^{\Lambda{t}}q(0)
\end{equation*}
Selecting an initial condition as a scalar multiple of an eigenvector $\mathrm{\textbf{v}}_{i}$, i.e.\ $x(0)=\alpha_{i}\mathrm{\textbf{v}}_{i}$ then $q(0)=\mathbb{V}^{-1}x(0)=\alpha_{i}\mathbb{V}^{-1}\mathrm{\textbf{v}}_{i}$.
But since $\mathbb{V}^{-1}\mathrm{\textbf{v}}_{i}=\mathbb{I}$ where $\mathbb{I}$ is the identity matrix, $\mathbb{V}^{-1}\mathrm{\textbf{v}}_{i}$ is just the $\mathrm{i^{th}}$ column of $\mathbb{I}$.
In other words, the initial condition $q(0)$ will have zeros everywhere, and $\alpha$ in the $\mathrm{i^{th}}$ row.
\begin{equation*}
  q(t)=\alpha e^{\lambda_{i}t}
\end{equation*}
This shows that only the mode corresponding to $\lambda_{i}$ will be present in the response from an initial condition along the $\mathrm{i^{th}}$ eigenvector.
The response in terms of $x_{s}'$ corresponding to $\lambda_{i}$ is then given by
\begin{equation*}
  x_{s}'(t)=\alpha_{i}e^{\Lambda_{i}t}\mathrm{\textbf{v}}_{i}
\end{equation*}
Based on this unforced modal response, if any entries in $\mathrm{\textbf{v}}_{i}$ are ``small'' relative to the others, the corresponding states are thus not influential in determining the initial condition response.

\subsection{The Sensitivity Matrix}


\chapter{State Feedback Control}

\section{Introduction}

\section{The Regulation Problem}

The plants for which we will seek to design controllers will be represented in the following form.
\begin{equation*}
  \dot{x}_{p}=A_{p}x_{p}+B_{p}u
\end{equation*}
The LQR controller will be explained in this section.
The LQR control is a full state feedback, static gain controller.
That is, the control input is calculated using the entire plant state $x_{p}$, and multiplied by a constant gain matrix $K_{p}$ to get the control input $u$.
The control law for the LQR controller is
\begin{equation*}
  u=K_{p}^{\top}x_{p}
\end{equation*}
The method of obtaining the gain matrix will not be discussed here.
There is a lot of information available about the process of obtaining $K_{p}$, but for the purposes of this section, what needs to be known is only that given a controllable plant, we can use \textsc{Matlab} to generate $K_{p}$ that will stabilize a given plant, and place the closed-loop poles in a ``good'' way.
This command is: \texttt{Kp = -lqr(Ap,Cp,Qlqr,Rlqr)'}

The LQR controller as described above is of little use for the control applications we are interested in, as it eliminates the ability to provide external reference commands, and serves only to regulate the system to the origin.

\section{The Tracking Problem}

This control architecture is known as the LQR-servomechanism, LQR-PI control, or LQR with integral action.
This structure uses LQR control where the plant is augmented with an integrator to ensure tracking of a reference command.
This is done by adding states to the state-space representation, and adding an additional input matrix through which the reference command enters.
Given the following open-loop plant
\begin{equation}
  \label{eqn.linear.openloopsystem}
  \begin{split}
    \dot{x}_{p}&=A_{p}x_{p}+B_{p}u \\
    z&=C_{pz}x_{p}+D_{pz}u
  \end{split}
\end{equation}
where $A_{p}\in\mathbb{R}^{n_{p}\times n_{p}}$, $B_{p}\in\mathbb{R}^{n_{p}\times m}$, and $C_{p}\in\mathbb{R}^{\ell\times n_{p}}$ and $z\in\mathbb{R}^{n_{e}}$ is the regulated output, where the number of regulated outputs is not to exceed the number of inputs, that is $n_{e}\leq m$.
Given that the state is available for measurement, \emph{the control goal is to design a control input $u$ so that the closed-loop system has bounded solutions and $z$ tends to the reference command $z_{\text{cmd}}$ asymptotically.}
In order to ensure command tracking, we introduce integral action, and for this purpose an additional state $x_e$ is defined as
\begin{equation*}
  \dot{x}_{e}=z_{\text{cmd}}-z
\end{equation*}
and the plant in~\eqref{eqn.linear.openloopsystem} is augmented to lead to the following extended open-loop dynamics
\begin{equation}
  \label{eqn.state.uncsystemfull}
  \begin{split}
    \begin{bmatrix}
      \dot{x}_{p} \\
      \dot{x}_{e}
    \end{bmatrix}
    &=
    \begin{bmatrix}
      A_{p} & 0 \\
      -C_{pz} & 0
    \end{bmatrix}
    \begin{bmatrix}
      x_{p} \\
      x_{e}
    \end{bmatrix}
    +
    \begin{bmatrix}
      B_{p} \\
      -D_{pz}
    \end{bmatrix} u
    +
    \begin{bmatrix}
      0 \\
      I
    \end{bmatrix}z_{\text{cmd}}
  \end{split}
\end{equation}
The system in~\eqref{eqn.state.uncsystemfull} can be written more compactly as
\begin{equation}
  \label{eqn.state.uncsystem}
  \dot{x}=Ax+Bu+B_{\text{cmd}}z_{\text{cmd}}
\end{equation}
where $A\in\mathbb{R}^{n\times n}$, $B\in\mathbb{R}^{n\times m}$, $B_{\text{cmd}}\in\mathbb{R}^{n\times n_{e}}$, and $C\in\mathbb{R}^{p\times n}$ are the known matrices given by
\begin{equation*}
  A=
  \begin{bmatrix}
    A_{p} & 0_{n_{p}\times n_{e}} \\
    -C_{pz} & 0_{n_{e}\times n_{e}}
  \end{bmatrix} \quad
  B=
  \begin{bmatrix}
    B_{p} \\
    -D_{pz}
  \end{bmatrix}
  \quad
  B_{\text{cmd}}=
  \begin{bmatrix}
    0_{n_{p}\times m} \\
    I_{n_{e}\times n_{e}}
  \end{bmatrix}
\end{equation*}
Thus, when the augmented system in Equation~\eqref{eqn.state.uncsystemfull} reaches steady state, $\dot{x}_{e}$ will be zero, and $z=z_{\text{cmd}}$.
The following control law will be used:
\begin{equation}
  \label{eqn.state.control}
  u=K_{x}^{\top}x
\end{equation}
Substituting the control law~\eqref{eqn.state.control} into~\eqref{eqn.state.uncsystem}
\begin{equation*}
  \begin{split}
    \dot{x}&=Ax+BK_{x}^{\top}x+B_{\text{cmd}}z_{\text{cmd}} \\
    &=\left(A+BK_{x}^{\top}\right)x+B_{\text{cmd}}z_{\text{cmd}}
  \end{split}
\end{equation*}
The gain $K_{x}^{\top}$ is selected to ensure the closed loop matrix $A+BK_{x}^{\top}$ is a Hurwitz.

\begin{example}
  \textbf{Integral Augmented LQR Control Synthesis: Longitudinal Aircraft Dynamics}
  Consider the following state-space model describing the longitudinal short-period dynamics of an aircraft.
  Given this system, the goal is to design a state feedback controller to track pitch rate commands.
  \begin{align*}
    \begin{bmatrix}
      \dot{\alpha} \\
      \dot{q}
    \end{bmatrix}&=
    \begin{bmatrix}
      \frac{Z_{\alpha}}{V} & 1 \\
      M_{\alpha} & M_{q}
    \end{bmatrix}
    \begin{bmatrix}
      \alpha \\
      q
    \end{bmatrix}+
    \begin{bmatrix}
      \frac{Z_{\delta_{e}}}{V} \\
      M_{\delta_{e}}
    \end{bmatrix}\delta_{e}
  \end{align*}
  where $\alpha$ is the angle of attack, $q$ the pitch rate, and $\delta_{e}$ the elevator deflection angle.
  The state vector is $x_{p}=\begin{bmatrix} \alpha & q \end{bmatrix}^{\top}$.
  With pitch rate as an output his system can be expressed more compactly as
  \begin{align*}
    \dot{x}_{p}&=A_{p}x_{p}+B_{p}u \\
    z&=C_{pz}x_{p}
  \end{align*}
  where
  \begin{equation*}
    C_{pz}=
    \begin{bmatrix}
      0 & 1
    \end{bmatrix}
  \end{equation*}
  To enforce reference tracking we augment the system with an integrator as described above, and get the following extended open-loop dynamics
  \begin{align*}
    \begin{bmatrix}
      \dot{\alpha} \\
      \dot{q} \\
      \dot{q}_{e}
    \end{bmatrix}&=
    \begin{bmatrix}
      \frac{Z_{\alpha}}{V} & 1 & 0 \\
      M_{\alpha} & M_{q} & 0 \\
      0 & -1 & 0
    \end{bmatrix}
    \begin{bmatrix}
      \alpha \\
      q \\
      q_{e}
    \end{bmatrix}+
    \begin{bmatrix}
      \frac{Z_{\delta_{e}}}{V} \\
      M_{\delta_{e}} \\
      0
    \end{bmatrix}\delta_{e}+
    \begin{bmatrix}
      0 \\
      0 \\
      1
    \end{bmatrix}q_{\text{cmd}}
  \end{align*}
  As shown above, these extended open-loop dynamics can be written more compactly as
  \begin{equation*}
    \dot{x}=Ax+Bu+B_{\text{cmd}}z_{\text{cmd}}
  \end{equation*}
\end{example}

\lstinputlisting{../assets/code/make_lqrpi.m}

\subsection{State-Space Controller Representation}
Now that the fundamental loop transfer functions are found, we now want to be able to actually apply this when using LQR-PI full state feedback controllers.
Thus, it is important to show an example of how to represent an LQR-PI controller in state space form, and from there be able to calculate the loop transfer functions.

\begin{figure}[H]
  %\fontsize{16pt}{16pt}\selectfont
  \begin{center}
    \begin{tikzpicture}[auto, scale=1.0, every node/.style={transform shape}, node distance=1.0cm, >=latex']
      \node[squareblock, minimum height=2cm, minimum width=2cm, label=above:{Controller}] (block1){$K(s)$};
      \node[left=of block1.150, node distance=5.0cm] (j1) {};
      \node[left of=j1, node distance=1.9cm] (input1) {};
      \node[whitesum,left=of block1.200, node distance=1.5cm] (sum1) {};
      \node[input, left of=sum1, node distance=1.5cm](input2){};
      \node[squareblock, minimum height=2cm, minimum width=2cm, right of=block1, label=above:{Plant},node distance=3.5cm] (block2) {$G(s)$};
      \node[output, right of=block2,node distance=2.5cm] (output1) {};
      \draw[->](input1) -- node[near start]{$z_{\text{cmd}}$} (block1.150);
      \draw[->](input2) -- node[near start]{$r$} node[pos=0.9] {$+$} (sum1);
      \draw[->](sum1) -- node{$e$} (block1.200);
      \draw[->](block1) -- node[name=u]{$u$} (block2);
      \draw[->](block2) -- node[name=y]{$x$} (output1);
      \node[input, below of=u, node distance=1.8cm](tee){};
      \draw[-](y) |- (tee);
      \draw[->](tee) -| node[pos=0.9]{$-$} (sum1);
    \end{tikzpicture}
    \caption{System block diagram}
  \end{center}
\end{figure}

The LQR-PI controller is represented as the following, where the subscript $(\cdot)_{c}$ is used to denote ``controller'', and the only state in the controller is the integral error state $x_{e}$.
\begin{align*}
  \dot{x}_{e}&=A_{c}x_{e}+B_{c}
  \begin{bmatrix}
    z_{\text{cmd}} \\
    -x_{p}
  \end{bmatrix} \\
  u&=C_{c}x_{e}+D_{c}
  \begin{bmatrix}
    z_{\text{cmd}} \\
    -x_{p}
  \end{bmatrix}
\end{align*}
The control law is a gain matrix multiplied by the state $x=\begin{bmatrix} x_{p}^{\top} & x_{e}^{\top} \end{bmatrix}^{\top}$ which is an augmentation of the plant state $x_{p}$ with error state $x_{e}$.
\begin{align*}
  \dot{x}_{e}&=z_{\text{cmd}}-z \\
  u&=K_{x}^{\top}x \\
  &=
  \begin{bmatrix}
    K_{p}^{\top} & K_{e}^{\top}
  \end{bmatrix}
  \begin{bmatrix}
    x_{p} \\
    x_{e}
  \end{bmatrix}
\end{align*}

\begin{equation*}
  \begin{split}
    \dot{x}_{e}&=z_{\text{cmd}}-C_{pz}x_{p}-D_{pz}u \\
    u&=K_{e}^{\top}x_{e}+K_{p}^{\top}x_{p}
  \end{split}
\end{equation*}

\begin{equation*}
  \begin{split}
    \dot{x}_{e}&=z_{\text{cmd}}-C_{pz}x_{p}-D_{pz}(K_{e}^{\top}x_{e}+K_{p}^{\top}x_{p}) \\
    u&=K_{e}^{\top}x_{e}+K_{p}^{\top}x_{p}
  \end{split}
\end{equation*}

\begin{equation*}
  \begin{split}
    \dot{x}_{e}&=-D_{pz}K_{e}^{\top}x_{e}+z_{\text{cmd}}-(C_{pz}+D_{pz}K_{p}^{\top})x_{p} \\
    u&=K_{e}^{\top}x_{e}+K_{p}^{\top}x_{p}
  \end{split}
\end{equation*}

\begin{equation*}
  \begin{split}
    \dot{x}_{e}&=-D_{pz}K_{e}^{\top}x_{e}+
    \begin{bmatrix}
      1 & C_{pz}+D_{pz}K_{p}^{\top}
    \end{bmatrix}
    \begin{bmatrix}
      z_{\text{cmd}} \\
      -x_{p}
    \end{bmatrix} \\
    u&=K_{e}^{\top}x_{e}+
    \begin{bmatrix}
      0 & -K_{p}^{\top}
    \end{bmatrix}
    \begin{bmatrix}
      z_{\text{cmd}} \\
      -x_{p}
    \end{bmatrix}
  \end{split}
\end{equation*}

Looking at this we can see that

\begin{empheq}[box={\labelBox[LQR Controller State-Space Model]}]{alignat=3}
  \begin{split}
    A_{c}&=-D_{pz}K_{e}^{\top} \\
    B_{c}&=
    \begin{bmatrix}
      1 & C_{pz}+D_{pz}K_{p}^{\top}
    \end{bmatrix} \\
    C_{c}&=
    K_{e}^{\top} \\
    D_{c}&=
    \begin{bmatrix}
      0 & -K_{p}^{\top}
    \end{bmatrix}
  \end{split}
\end{empheq}

%\begin{empheq}[box={\labelBox[Test]}]{alignat=3}
%&\mbox{\textbf{Cartesian:}} &\hspace{0.5in} a=b \\[6pt]
%&\mbox{\textbf{Cylindrical:}} &\hspace{0.5in} b=c \\[6pt]
%&\mbox{\textbf{Spherical:}} &\hspace{0.5in} c=d
%\end{empheq}
%
%\begin{empheq}[box={\labelBox[Test]}]{alignat=2}
%\begin{split}
%\mbox{\textbf{Cartesian:}} &\hspace{0.5in} a=b \\[6pt]
%\mbox{\textbf{Cylindrical:}} &\hspace{0.5in} b=c \\[6pt]
%\mbox{\textbf{Spherical:}} &\hspace{0.5in} c=d
%\end{split}
%\end{empheq}

\begin{example}
  \textbf{Integral Augmented LQR Controller State-Space Representation: Longitudinal Aircraft Dynamics}
  The general form of the plant as shown above, but repeated here for the longitudinal subsystem is
  \begin{align*}
    \dot{x}_{p}&=A_{p}x_{p}+B_{p}u \\
    y_{p}&=C_{p}x_{p} \\
    z&=C_{pz}x_{p}+D_{pz}u
  \end{align*}
  For this longitudinal subsystem the plant states are angle of attack $\alpha$, and pitch rate $q$, with the plant input being the elevator deflection angle $\delta_{e}$.
  That is, $x_{p}=\begin{bmatrix} \alpha & q \end{bmatrix}^{\top}$.
  \begin{align*}
    \begin{bmatrix}
      \dot{\alpha} \\
      \dot{q}
    \end{bmatrix}&=
    \begin{bmatrix}
      \frac{Z_{\alpha}}{V} & 1 \\
      M_{\alpha} & M_{q}
    \end{bmatrix}
    \begin{bmatrix}
      \alpha \\
      q
    \end{bmatrix}+
    \begin{bmatrix}
      \frac{Z_{\delta_{e}}}{V} \\
      M_{\delta_{e}}
    \end{bmatrix}\delta_{e} \\
  \end{align*}
  Plugging in some numbers
  \begin{equation*}
    A_{p}=
    \begin{bmatrix}
      1 & 0 \\
      0 & 1
    \end{bmatrix}
    \quad
    B_{p}=
    \begin{bmatrix}
      1 \\
      0
    \end{bmatrix}
    \quad
    C_{p}=
    \begin{bmatrix}
      1 & 0 \\
      0 & 1
    \end{bmatrix}
    \quad
    C_{pz}=
    \begin{bmatrix}
      1 & 0
    \end{bmatrix}
    \quad
    D_{pz}=
    \begin{bmatrix}
      0
    \end{bmatrix}
  \end{equation*}
  The general form of the controller is
  \begin{align*}
    \dot{x}_{e}&=A_{c}x_{e}+B_{c}
    \begin{bmatrix}
      z_{\text{cmd}} \\
      -x_{p}
    \end{bmatrix} \\
    u&=C_{c}x_{e}+D_{c}
    \begin{bmatrix}
      z_{\text{cmd}} \\
      -x_{p}
    \end{bmatrix}
  \end{align*}
  Inputs to controller are $z_{\text{cmd}}=\alpha_{\text{cmd}}$ and $e=-x_{p}=\begin{bmatrix} -\alpha & -q \end{bmatrix}^{\top}$.
  Combining these two inputs into one input $\begin{bmatrix} \alpha_{\text{cmd}} & -\alpha & -q \end{bmatrix}^{\top}$ we get
  \begin{align*}
    \dot{x}_{e}&=
    \begin{bmatrix}
      1 & 1 & 0
    \end{bmatrix}
    \begin{bmatrix}
      \alpha_{\text{cmd}} \\
      -\alpha \\
      -q
    \end{bmatrix} \\
    u&=k_{e}x_{e}+
    \begin{bmatrix}
      0 & -k_{\alpha} & -k_{q}
    \end{bmatrix}
    \begin{bmatrix}
      \alpha_{\text{cmd}} \\
      -\alpha \\
      -q
    \end{bmatrix}
  \end{align*}
  \begin{empheq}[box=\roomyfbox]{equation*}
    A_{c}=0 \quad B_{c}=
    \begin{bmatrix}
      1 & 1 & 0
    \end{bmatrix}
    \quad C_{c}=
    \begin{bmatrix}
      k_{e}
    \end{bmatrix}
    \quad D_{c}=
    \begin{bmatrix}
      0 & -k_{\alpha} & -k_{q}
    \end{bmatrix}
  \end{empheq}
  This state space representation was then converted to a transfer matrix representation for frequency domain analysis.
  This transfer matrix was $1\times3$: controller input $\alpha_{\text{cmd}}$, $-\alpha$, and $-q$ and the output was the elevator deflection angle $\delta_{\text{e}}$.
\end{example}

\subsection{Properties of Extended Open-Loop Dynamics}

\subsubsection{Controllability}
Hautus controllability test Hespanha book page 113.

\begin{thm-dan}[Popov-Belevitch-Hautus Test for Controllability]
  The pair $(A,B)$ is controllable if and only if
  \begin{equation*}
    \text{\normalfont\ rank}\left(
      \begin{bmatrix}
        A-\lambda  I & B
      \end{bmatrix}
    \right)=n,
    \qquad
    \forall\lambda\in\mathbb{C}
  \end{equation*}
\end{thm-dan}

If we apply this test to the extended open-loop dynamics, we get
\begin{equation*}
  \text{rank}\left(
    \begin{bmatrix}
      A_{p}-\lambda I & 0 & B_{p} \\
      -C_{pz} & -\lambda I & -D_{pz}
    \end{bmatrix}
  \right)
  =n_{p}+n_{e}
\end{equation*}
for all $\lambda\neq0$.
So we just need to check the rank when $\lambda=0$ giving the following:
\begin{equation*}
  \text{rank}\left(
    \begin{bmatrix}
      A_{p} & B_{p} \\
      -C_{pz} & -D_{pz}
    \end{bmatrix}
  \right)
  =n_{p}+n_{e}
\end{equation*}

\subsubsection{Observability}

Consider the observability matrix for $\Sigma_{p}$.
Since this system is observable, it has full rank.
\begin{equation*}
  \text{rank}
  \begin{bmatrix}
    C_{p} \\
    C_{p}A_{p} \\
    C_{p}A_{p}^{2} \\
    \vdots \\
    C_{p}A_{p}^{n_{p}-1}
  \end{bmatrix}
  =n_{p}
\end{equation*}
Now look at the controllability matrix for the augmented system
\begin{equation*}
  \begin{bmatrix}
    \begin{bmatrix}
      C_{p} & 0 \\
      0 & I
    \end{bmatrix} \\
    \begin{bmatrix}
      C_{p} & 0 \\
      0 & I
    \end{bmatrix}
    \begin{bmatrix}
      A_{p} & 0 \\
      -C_{pz} & 0
    \end{bmatrix} \\
    \begin{bmatrix}
      C_{p} & 0 \\
      0 & I
    \end{bmatrix}
    \begin{bmatrix}
      A_{p} & 0 \\
      -C_{pz} & 0
    \end{bmatrix}^{2} \\
    \vdots \\
    \begin{bmatrix}
      C_{p} & 0 \\
      0 & I
    \end{bmatrix}
    \begin{bmatrix}
      A_{p} & 0 \\
      -C_{pz} & 0
    \end{bmatrix}^{n-1} \\
  \end{bmatrix}
\end{equation*}
Note that
\begin{equation*}
  \begin{bmatrix}
    A_{p} & 0 \\
    -C_{pz} & 0
  \end{bmatrix}^{2}=
  \begin{bmatrix}
    A_{p} & 0 \\
    -C_{pz} & 0
  \end{bmatrix}
  \begin{bmatrix}
    A_{p} & 0 \\
    -C_{pz} & 0
  \end{bmatrix}=
  \begin{bmatrix}
    A_{p}^{2} & 0 \\
    -C_{pz}A_{p} & 0
  \end{bmatrix}
\end{equation*}
Note that
\begin{equation*}
  \begin{bmatrix}
    A_{p} & 0 \\
    -C_{pz} & 0
  \end{bmatrix}^{n}=
  \begin{bmatrix}
    A_{p}^{n} & 0 \\
    -C_{pz}A_{p}^{n-1} & 0
  \end{bmatrix}
\end{equation*}
So the observability matrix for the extended open-loop dynamics becomes
\begin{equation*}
  \begin{bmatrix}
    \begin{bmatrix}
      C_{p} & 0 \\
      0 & I
    \end{bmatrix} \\
    \begin{bmatrix}
      C_{p}A_{p} & 0 \\
      -C_{pz} & 0
    \end{bmatrix} \\
    \begin{bmatrix}
      C_{p}A_{p}^{2} & 0 \\
      -C_{pz}A_{p} & 0
    \end{bmatrix} \\
    \vdots \\
    \begin{bmatrix}
      C_{p}A_{p}^{n-1} & 0 \\
      C_{pz}A_{p}^{n-2} & 0
    \end{bmatrix} \\
  \end{bmatrix}
\end{equation*}

And we can see that the $n_{e}$ columns that were added to the observability matrix for the extended open-loop dynamics are linearly independent.
So the augmented controllability matrix is full rank.

\subsubsection{Rank of $B$, $C$, and $CB$}

The proof is trivial.

\subsubsection{Transmission Zeros}

Given system $\Sigma_{p}=(A_{p},B_{p},C_{p})$ show that integral augmentation does not add any transmission zeros to the system.
The Rosenbrock system matrix for $\Sigma_{p}$ is
\begin{equation*}
  R_{p}(s)=
  \begin{bmatrix}
    sI-A_{p} & -B_{p} \\
    C_{p} & D_{pz}
  \end{bmatrix}
\end{equation*}
The transmission zeros are the values of $s$ which make $R_{p}(s)$ lose rank.
For the augmented system the Rosenbrock matrix is
\begin{equation*}
  R(s)=
  \begin{bmatrix}
    sI-A_{p} & 0 & -B_{p} \\
    C_{pz} & sI & D_{pz} \\
    C_{p} & 0 & 0 \\
    0 & I & 0
  \end{bmatrix}
\end{equation*}
The augmented Rosenbrock matrix has $2n_{e}$ rows added and $n_{e}$ columns.
When the $\Sigma_{p}$ is tall, that is $m\leq\ell$, then the maximum rank of $R(s)$ is $n_{p}+n_{e}+m$.
The rank of $R(s)$ only drops for values of $s$ which are transmission zeros of $\Sigma_{p}$ due to the extra $n_{e}$ columns being added are linearly independent for all $s$, due to the identity at the bottom.

\subsection{Using Feed Forward}

Finish this section, see 16.31 notes.

\begin{figure}[H]
  %\fontsize{16pt}{16pt}\selectfont
  \begin{center}
    \begin{tikzpicture}[auto, scale=1.0, every node/.style={transform shape}, node distance=1.0cm, >=latex']
      \node[squareblock, minimum height=2cm, minimum width=2cm, label=above:{Controller}] (block1){$K(s)$};
      \node[left=of block1.150, node distance=5.0cm] (j1) {};
      \node[left of=j1, node distance=1.9cm] (input1) {};
      \node[whitesum,left=of block1.200, node distance=1.5cm] (sum1) {};
      \node[input, left of=sum1, node distance=1.5cm](input2){};
      \node[squareblock, minimum height=2cm, minimum width=2cm, right of=block1, label=above:{Plant},node distance=3.5cm] (block2) {$G(s)$};
      \node[output, right of=block2,node distance=2.5cm] (output1) {};
      \draw[->](input1) -- node[near start]{$z_{\text{cmd}}$} (block1.150);
      \draw[->](input2) -- node[near start]{$r$} node[pos=0.9] {$+$} (sum1);
      \draw[->](sum1) -- node{$e$} (block1.200);
      \draw[->](block1) -- node[name=u]{$u$} (block2);
      \draw[->](block2) -- node[name=y]{$x$} (output1);
      \node[input, below of=u, node distance=1.8cm](tee){};
      \draw[-](y) |- (tee);
      \draw[->](tee) -| node[pos=0.9]{$-$} (sum1);
    \end{tikzpicture}
    \caption{System block diagram}
  \end{center}
\end{figure}

\chapter{Output Feedback Control}

\section{Introduction}

When doing full state feedback pole placement problems, it is often the case that the desired pole locations can be achieved without using all of the gains.
When this happens, the question may arise regarding what values to assign to these ``extra'' gains.
In regards to stability (that is, the closed-loop eigenvalue locations) they can be assigned arbitrarily.
However, one may postulate that these gains may be assigned in such a way that will improve the closed-loop performance of the system.
Additionally, the idea of designing a control system with only some of the state variables being fed back to the controller should seem like a reasonable idea.

\section{Projective Output Feedback}

It can be shown that assignment of these ``extra'' gains allows the eigenvectors to be selected, in addition to only the eigenvalues.
These performance benefits may manifest themselves as increased robustness???

\begin{example}
  \textbf{Pole placement}
  Put an example here indicating a full-state feedback pole placement problem with extra degrees of freedom.
\end{example}

\subsection{Static Projective Output Feedback}

% TODO@dpwiese - Can this section be redone with Dp not zero?

The full-state feedback LQR controller is a design which selects feedback gains optimally, based on some user specified performance weights.
Such a design results in good closed-loop performance, but relies on the entire state vector being accessible.
In cases where the entire state is not accessible, projective output feedback will allow an LQR like full state feedback design to be achieved, without requiring full state accessibility.
The following notes are based on Eugene's book Chapter 6, page 165.

Given a state-space plant of the following form
\begin{align*}
  \dot{x}_{p}&=A_{p}x_{p}+B_{p}u \\
  y_{p}&=C_{p}x_{p}
\end{align*}
A full state feedback LQR controller can be designed, with control law
\begin{equation*}
  u=K_{p}^{\top}x_{p}
\end{equation*}
giving the following full-state feedback closed loop system
\begin{align*}
  \dot{x}_{p}&=(A_{p}+B_{p}K_{p}^{\top})x_{p} \\
  y_{p}&=C_{p}x_{p}
\end{align*}
\begin{equation*}
  A_{\text{cl,fs}}=A_{p}+B_{p}K_{p}^{\top}
\end{equation*}
\begin{equation*}
  \dot{x}_{p}=A_{\text{cl,fs}}x_{p}
\end{equation*}

Now it is desired to design an output feedback controller, using gain feedback on only the output $y_{p}$ instead of the entire state $x_{p}$.
That is
\begin{equation*}
  u=K_{y}^{\top}y_{p}
\end{equation*}
giving the following output feedback closed loop system
\begin{equation*}
  \dot{x}=(A_{p}+B_{p}K_{y}^{\top}C_{p})x_{p}
\end{equation*}
\begin{equation*}
  A_{\text{cl,op}}=A_{p}+B_{p}K_{y}^{\top}C_{p}
\end{equation*}
\begin{equation*}
  \dot{x}_{p}=A_{\text{cl,op}}x_{p}
\end{equation*}
The idea is to make the closed loop ``$A$'' matrix when using output feedback as close to the closed-loop ``$A$'' matrix when using full state feedback.
This can be done by requiring that $n_{y}$ eigenvalues of $A_{\text{cl,op}}$ are equal to those of $A_{\text{cl,fs}}$, where $n_{y}$ is the number of outputs.

The eigenvalue problem can be written
\begin{equation*}
  A_{\text{cl,fs}}V=V\Lambda
\end{equation*}
We can require that $n_{y}$ eigenvalues of $A_{\text{cl,fs}}$ are maintained in $A_{\text{cl,op}}$.
That is, taking these $n_{y}$ values of $\Lambda$ gives $\Lambda_{n_{y}}$.
In other words, this requirement gives $n_{y}$ eigenvectors $V_{n_{y}}$ that satisfy
\begin{equation*}
  A_{\text{cl,fs}}V_{n_{y}}=A_{\text{cl,op}}V_{n_{y}}
\end{equation*}
Solving this equation we can find $K_{y}$
\begin{equation*}
  (A_{p}+B_{p}K_{x}^{\top})V_{n_{y}}=(A_{p}+B_{p}K_{y}^{\top}C_{p})V_{n_{y}}
\end{equation*}
\begin{equation*}
  K_{x}^{\top}V_{n_{y}}=K_{y}^{\top}C_{p}V_{n_{y}}
\end{equation*}
\begin{empheq}[box=\roomyfbox]{equation*}
  K_{y}^{\top}=K_{x}^{\top}V_{n_{y}}(C_{p}V_{n_{y}})^{-1}
\end{empheq}

To implement this procedure, first design the full-state feedback LQR controller.
Then pick the eigenvalues and corresponding eigenvectors of this full-state feedback design ``$A$'' matrix $A_{\text{cl,fs}}$ which should be kept in the output feedback design.
This gives you $V_{n_{y}}$ and $\Lambda_{n_{y}}$.
Using $V_{n_{y}}$ and $K_{x}$, solve for the output feedback gain $K_{y}$.

\subsection{Dynamic Projective Output Feedback}

Finish this section using the example problem in Eugene's book.

\subsection{Comparing Full State and Output Projective Feedback}

gain margins?
phase margins?
what happens to these margins if the output feedback gain is increased?
what about an output feedback design which simply takes the full-state feedback gain matrix and deletes the feedback gains corresponding to states which are not accessible?
If output feedback is done by just zeroing out gains corresponding to state variables which are not available for feedback, the system may not be stable.

\section{State Observer/Estimator}

Another way of dealing with control problems in which the full state is not available for feedback is to design a state observer or estimator.
The general block diagram for a closed-loop estimator is shown in the figure below.
\begin{figure}[H]
  % \fontsize{9pt}{9pt}\selectfont
  \begin{center}
    \psfragfig[width=2.6in]{\figurepath/cl_estimator_v3}{%
      \psfrag{u}[bc][bc][1.0]{$u$}
      \psfrag{plant}[bc][bc][1.0]{Plant}
      \psfrag{obsv}[bc][bc][1.0]{Observer}
      \psfrag{pdyn}[bc][bc][1.0]{Plant Model}
      \psfrag{kf}[bc][bc][1.0]{$K_{f}$}
      \psfrag{y}[bc][bc][1.0]{$y_{p}$}
      \psfrag{yh}[bc][bc][1.0]{$\hat{y}_{p}$}
      \psfrag{xh}[bc][bc][1.0]{$\hat{x}$}
      \psfrag{s}[mc][mc][1.0]{$+$}
      \psfrag{m}[bc][bc][1.0]{$-$}
    }
    \caption{Closed loop estimator\label{linear.label_fig_1}}
  \end{center}
\end{figure}
The idea is that an estimator contains a linear model of what the plant is expected to be.
In reality, the parameters assigned within the observer's plant model may not be perfect, but hopefully they are close.
The feedback gain $K_{f}$ is then used to correct the plant model based on differences between the actual output $y$ and estimated output $\hat{y}$.
Then, as this output error is reduced, the state estimate $\hat{x}_{p}$ is improved, and this estimate can then be used for feedback control.

\subsection{LQE Estimator Design: Kalman Filter}

Plant given by the LTI state space system.
State-space form of plant
\begin{align*}
  \dot{x}_{p}&=A_{p}x_{p}+B_{p}u+B_{p2}w \\
  y_{p}&=C_{p}x_{p}+D_{p}u
\end{align*}
Explain the input disturbance term $B_{p2}$ that is up there later, but use this one for now.
\begin{empheq}[box=\roomyfbox]{alignat*=2}
\dot{x}_{p}&=A_{p}x_{p}+B_{p}u \\
y_{p}&=C_{p}x_{p}+D_{p}u
\end{empheq}
The following figure shows a more detailed block diagram of the closed loop estimator, and how one might construct the block diagram in \textsc{Simulink} using basic gains, integrators, and summing blocks.
\begin{figure}[H]
  % \fontsize{9pt}{9pt}\selectfont
  \begin{center}
    \psfragfig[width=4.1in]{\figurepath/cl_estimator_v4}{%
      \psfrag{r}[bc][bc][1.0]{$r$}
      \psfrag{p}[bc][bc][1.0]{$+$}
      % \psfrag{m}[bc][bc][1.0]{$$} % chktex 45
      \psfrag{ci}[mc][mc][1.0]{$C^{-1}$}
      \psfrag{s}[mc][mc][1.0]{$+$}
      \psfrag{i}[mc][mc][1.0]{$\frac{1}{s}$}
      \psfrag{a}[mc][mc][1.0]{$A_{p}$}
      \psfrag{b}[mc][mc][1.0]{$B_{p}$}
      \psfrag{c}[mc][mc][1.0]{$C_{p}$}
      \psfrag{d}[mc][mc][1.0]{$D_{p}$}
      \psfrag{u}[bc][bc][1.0]{$u$}
      \psfrag{y}[bc][bc][1.0]{$-y_{p}$}
      \psfrag{yh}[bc][bc][1.0]{$\hat{y}_{p}$}
      \psfrag{xh}[bc][bc][1.0]{$\hat{x}_{p}$}
      \psfrag{xe}[bc][bc][1.0]{$x_{e}$}
      \psfrag{kc}[mc][mc][1.0]{$K_{x}$}
      \psfrag{kf}[mc][mc][1.0]{$K_{f}$}
      \psfrag{obsv}[tl][tl][1.0]{Observer}
      \psfrag{comp}[tr][tr][1.0]{Compensator}
      \psfrag{plant}[bc][bc][1.0]{Plant}
    }
    \caption{Closed loop estimator\label{linear.label_fig_2}}
  \end{center}
\end{figure}
A closed-loop estimator will then be used to reconstruct the plant state $x_{p}$.
We will call this full state estimate $\hat{x}_{p}$.
The state-space representation for the closed-loop estimator as shown in the block diagram above is given by%Lec.\ 14-7
\begin{align*}
  \dot{\hat{x}}_{p}&=A_{p}\hat{x}_{p}+B_{p}u+K_{f}(\hat{y}_{p}-y_{p}) \\
  \hat{y}_{p}&=C_{p}\hat{x}_{p}+D_{p}u
\end{align*}
Inserting the known expression for the plant output
\begin{align*}
  \dot{\hat{x}}_{p}&=A_{p}\hat{x}_{p}+B_{p}u+K_{f}(C_{p}\hat{x}_{p}+D_{p}u-y_{p}) \\
  \hat{y}_{p}&=C_{p}\hat{x}_{p}+D_{p}u
\end{align*}
Combining terms gives the following closed-loop estimator state-space equations below
\begin{empheq}[box=\roomyfbox]{alignat*=2}
  \dot{\hat{x}}_{p}&=(A_{p}+K_{f}C_{p})\hat{x}_{p}+(B_{p}+K_{f}D_{p})u-K_{f}y_{p} \\
  \hat{y}_{p}&=C_{p}\hat{x}_{p}+D_{p}u
\end{empheq}
Where the inclusion of the state estimate as an output in the above equations is to emphasize that these are the equations which would be used to implement an estimator to use, as possibly part of a controller, in simulation.
The input to the estimator block would be the control $u$, measured plant output $y_{p}$, and the output of the estimator would be the estimated state $\hat{x}_{p}$.
This estimated state would then be used in a feedback control law where ordinarily the actual state $x_{p}$ would have been used, if it were accessible.
Such a control architecture is known as a dynamic output feedback compensator, and is described in more detail in following sections.

How to obtain the Kalman filter gain is not covered here, but $K_{f}$ is given by
\begin{align*}
  K_{f}&=P_{f}C^{\top}R_{0}^{-1} \\
  0&=AP_{f}+P_{f}A^{\top}+Q_{0}-P_{f}C^{\top}R_{0}^{-1}CP_{f}
\end{align*}
The Kalman filter gain $K_{f}$ can be found by using the \textsc{Matlab} function \texttt{lqr}.
In order to implement the Kalman filter as given in these equations, the command would be: \texttt{Kf=-lqr(Ap',Cp',Qf,Rf)'}.

\section{The Regulation Problem}

Now it is desired to add the integral error state of the LQR-PI controller to the DOFB architecture.
This will allow external reference commands to be given and followed with zero steady-state error, as well as using only the output, and not the full state, for feedback.

\begin{equation}
  \begin{split}
    \label{eqn.output.regulate}
    \dot{x}_{p}&=A_{p}x_{p}+B_{p}u \\
    y_{p}&=C_{p}x_{p}+D_{p}u \\
  \end{split}
\end{equation}
where $A_{p}\in\mathbb{R}^{n_{p}\times n_{p}}$, $B_{p}\in\mathbb{R}^{n_{p}\times m}$, and $C_{p}\in\mathbb{R}^{\ell\times n_{p}}$.
Given that the state is available for measurement, \emph{the control goal is to design a control input $u$ so that the closed-loop system has bounded solutions and the system is regulated to the origin.}
Now we would like to improve on this idea of using the estimated state $\hat{x}_{p}$ in feedback, just like in the case of full-state LQR feedback control.
We would now like to use this same procedure, but instead of feeding back on the actual state $x_{p}$, we will use a state estimator to generate an estimate of the state $\hat{x}_{p}$.
The combining of an optimal state estimator and optimal controller is known as LQG control.
``For LTI systems with Gaussian models for disturbances and measurement noise, the Kalman filter is the optimal state estimator.
When optimal control (LQR) is combined with optimal state estimation (Kalman filter) the control design is called the Linear Quadratic Gaussian (LQG) problem.''~\cite{lavretskywise.book.2013}
The control law is given by

\begin{equation*}
  u=K_{p}^{\top}\hat{x}_{p}
\end{equation*}

We design a state estimator as described above, and with the proposed control law the combined system, called the compensator, is described by the following equations

\begin{empheq}[box={\roomyfbox}]{alignat*=1}
  \dot{\hat{x}}_{p}&=A_{p}\hat{x}_{p}+B_{p}u+K_{f}(\hat{y}_{p}-y_{p}) \\
  \hat{y}_{p}&=C_{p}\hat{x}_{p}+D_{p}u \\
  u&=K_{p}^{\top}\hat{x}_{p}
\end{empheq}

Substituting the control law and output equation in
\begin{align*}
  \dot{\hat{x}}_{p}&=A_{p}\hat{x}_{p}+B_{p}K_{p}^{\top}\hat{x}_{p}+K_{f}[C_{p}\hat{x}_{p}+D_{p}K_{p}^{\top}\hat{x}_{p}-y_{p}] \\
  u&=K_{p}^{\top}\hat{x}_{p}
\end{align*}
Expanding
\begin{align*}
  \dot{\hat{x}}_{p}&=A_{p}\hat{x}_{p}+B_{p}K_{p}^{\top}\hat{x}_{p}+K_{f}C_{p}\hat{x}_{p}+K_{f}D_{p}K_{p}^{\top}\hat{x}_{p}+K_{f}(-y_{p}) \\
  u&=K_{p}^{\top}\hat{x}_{p}
\end{align*}
Grouping terms

\begin{empheq}[box={\labelBox[Output Feedback Regulator]}]{alignat*=2}
  \dot{\hat{x}}_{p}&=(A_{p}+B_{p}K_{p}^{\top}+K_{f}C_{p}+K_{f}D_{p}K_{p}^{\top})\hat{x}_{p}+K_{f}(-y_{p}) \\
  u&=K_{p}^{\top}\hat{x}_{p}
\end{empheq}

The basic block diagram which describes this combination of an estimator with controller looks just like the LQR controller, and is shown below.
However, now the output $y_{i}$ is being fed back to the controller, instead of the full state $x_{i}$, and the compensator $K(s)$ is of increased complexity.

\begin{figure}[H]
  %\fontsize{16pt}{16pt}\selectfont
  \begin{center}
    \begin{tikzpicture}[auto, scale=1.0, every node/.style={transform shape}, node distance=1.0cm, >=latex']
      \node[squareblock, minimum height=2cm, minimum width=2cm, label=above:{Controller}] (block1){$K(s)$};
      \node[left=of block1.150, node distance=5.0cm] (j1) {};
      \node[left of=j1, node distance=1.9cm] (input1) {};
      \node[whitesum,left=of block1.200, node distance=1.5cm] (sum1) {};
      \node[input, left of=sum1, node distance=1.5cm](input2){};
      \node[squareblock, minimum height=2cm, minimum width=2cm, right of=block1, label=above:{Plant},node distance=3.5cm] (block2) {$G(s)$};
      \node[output, right of=block2,node distance=2.5cm] (output1) {};
      \draw[->](input1) -- node[near start]{$z_{\text{cmd}}$} (block1.150);
      \draw[->](input2) -- node[near start]{$r$} node[pos=0.9] {$+$} (sum1);
      \draw[->](sum1) -- node{$e$} (block1.200);
      \draw[->](block1) -- node[name=u]{$u$} (block2);
      \draw[->](block2) -- node[name=y]{$y$} (output1);
      \node[input, below of=u, node distance=1.8cm](tee){};
      \draw[-](y) |- (tee);
      \draw[->](tee) -| node[pos=0.9]{$-$} (sum1);
    \end{tikzpicture}
    \caption{System block diagram}
  \end{center}
\end{figure}

The following diagram shows a little bit more clearly the internal workings of the DOFB-regulator.

\begin{figure}[H]
  % \fontsize{7pt}{7pt}\selectfont
  \begin{center}
    \psfragfig[width=6.0in]{\figurepath/dofb_regulator_v2}{%
      \psfrag{r}[bc][bc][1.0]{$r$}
      \psfrag{p}[bc][bc][1.0]{$+$}
      % \psfrag{m}[bc][bc][1.0]{$$} % chktex 45
      \psfrag{ci}[mc][mc][1.0]{$C^{-1}$}
      \psfrag{s}[mc][mc][1.0]{$+$}
      \psfrag{i}[mc][mc][1.0]{$\frac{1}{s}$}
      \psfrag{a}[mc][mc][1.0]{$A_{p}$}
      \psfrag{b}[mc][mc][1.0]{$B_{p}$}
      \psfrag{c}[mc][mc][1.0]{$C_{p}$}
      \psfrag{d}[mc][mc][1.0]{$D_{p}$}
      \psfrag{u}[bc][bc][1.0]{$u$}
      \psfrag{y}[bc][bc][1.0]{$-y_{p}$}
      \psfrag{yh}[bc][bc][1.0]{$\hat{y}_{p}$}
      \psfrag{xh}[bc][bc][1.0]{$\hat{x}_{p}$}
      \psfrag{xe}[bc][bc][1.0]{$x_{e}$}
      \psfrag{kc}[mc][mc][1.0]{$K_{p}^{\top}$}
      \psfrag{kf}[mc][mc][1.0]{$K_{f}$}
      \psfrag{obsv}[tl][tl][1.0]{Observer}
      \psfrag{comp}[tr][tr][1.0]{Compensator}
      \psfrag{plant}[bc][bc][1.0]{Plant}
    }
  \end{center}
\end{figure}

It doesn't matter if the estimator feedback term is $\hat{y}_{p}-y_{p}$ or $y_{p}-\hat{y}_{p}$.
All this does is change the sign of $K_{f}$.
We will use the representation shown above to facilitate representation of these equations in the block diagram form with negative feedback at the summing junction for input $r_{2}$.
In addition, the feedback control law can be written with a positive or negative sign.
All of the terms can be combined and substituted and rearranged within these above equations revealing that this dynamic output feedback compensator takes as its input the plant output $y$, and uses it with an LQR full state feedback control law operating on the estimated state $\hat{x}$ to generate the output $u$.
This is called a dynamic output feedback compensator.
This can be implemented as shown in the following block diagram, where the compensator $K(s)$ will contain these additional dynamics, instead of just the integrator and proportional gains as in the LQR-PI controller case.
This representation is also good because the only input to the compensator is the output feedback $e=-y_{p}$, as is represented in the equations.

\section{The Tracking Problem}

Now it is desired to add the integral error state of the LQR-PI controller to the DOFB architecture.
This will allow external reference commands to be given and followed with zero steady-state error, as well as using only the output, and not the full state, for feedback.

\begin{equation}
  \label{eqn.output.openloopsystem}
  \begin{split}
    \dot{x}_{p}&=A_{p}x_{p}+B_{p}u \\
    y_{p}&=C_{p}x_{p}+D_{p}u \\
    z&=C_{pz}x_{p}+D_{pz}u
  \end{split}
\end{equation}
where $A_{p}\in\mathbb{R}^{n_{p}\times n_{p}}$, $B_{p}\in\mathbb{R}^{n_{p}\times m}$, and $C_{p}\in\mathbb{R}^{\ell\times n_{p}}$ and $z\in\mathbb{R}^{n_{e}}$ is the regulated output, where the number of regulated outputs is not to exceed the number of inputs, that is $n_{e}\leq m$.
Given that the state is available for measurement, \emph{the control goal is to design a control input $u$ so that the closed-loop system has bounded solutions and $z$ tends to the reference command $z_{\text{cmd}}$ asymptotically.}
In order to ensure command tracking, we introduce integral action, and for this purpose an additional state $x_e$ is defined as
\begin{equation*}
  \dot{x}_{e}=z_{\text{cmd}}-z
\end{equation*}
and the plant in~\eqref{eqn.output.openloopsystem} is augmented to lead to the following extended open-loop dynamics
\begin{equation}
  \label{eqn.output.uncsystemfull}
  \begin{split}
    \begin{bmatrix}
      \dot{x}_{p} \\
      \dot{x}_{e}
    \end{bmatrix}
    &=
    \begin{bmatrix}
      A_{p} & 0 \\
      -C_{pz} & 0
    \end{bmatrix}
    \begin{bmatrix}
      x_{p} \\
      x_{e}
    \end{bmatrix}
    +
    \begin{bmatrix}
      B_{p} \\
      -D_{pz}
    \end{bmatrix} u
    +
    \begin{bmatrix}
      0 \\
      I
    \end{bmatrix}z_{\text{cmd}} \\
  \end{split}
\end{equation}
The system in~\eqref{eqn.output.uncsystemfull} can be written more compactly as
\begin{equation}
  \begin{split}
    \dot{x}&=Ax+Bu+B_{\text{cmd}}z_{\text{cmd}} \\
    y&=Cx+Du
  \end{split}
\end{equation}
where $A\in\mathbb{R}^{n\times n}$, $B\in\mathbb{R}^{n\times m}$, $B_{\text{cmd}}\in\mathbb{R}^{n\times n_{e}}$, and $C\in\mathbb{R}^{p\times n}$ are the known matrices given by
\begin{equation*}
  A=
  \begin{bmatrix}
    A_{p} & 0_{n_{p}\times n_{e}} \\
    -C_{pz} & 0_{n_{e}\times n_{e}}
  \end{bmatrix} \quad
  B=
  \begin{bmatrix}
    B_{p} \\
    -D_{pz}
  \end{bmatrix}
  \quad
  B_{\text{cmd}}=
  \begin{bmatrix}
    0_{n_{p}\times m} \\
    I_{n_{e}\times n_{e}}
  \end{bmatrix}
  \quad
  C=
  \begin{bmatrix}
    C_{p} & 0_{\ell\times n_{e}} \\
    0_{n_{e}\times n} & I_{n_{e}\times n_{e}}
  \end{bmatrix}
\end{equation*}
In the tracking problem for state feedback, the control law was $u=K_{x}^{\top}x$ where $x=\begin{bmatrix} x_{p}^{\top} & x_{e}^{\top} \end{bmatrix}^{\top}$.
In the case of output feedback $x_{p}$ must be replaced by the estimate as
\begin{equation*}
  \begin{split}
    u&=
    \left[
      \begin{array}{cc}
        K_{p}^{\top} & K_{e}^{\top}
      \end{array}
    \right]
    \left[
      \begin{array}{c}
        \hat{x}_{p} \\
        x_{e}
      \end{array}
    \right] \\
    &=K_{p}^{\top}\hat{x}_{p}+K_{e}^{\top}x_{e}
  \end{split}
\end{equation*}
We now need to design an observer to generate the state estimate.

\subsection{Non-Augmented Observer}

We would now like to use this same procedure, but instead of feeding back on the actual state $x_{p}$, we will use the estimated state $\hat{x}_{p}$.
The integral error term will be the difference between the commanded output value $y_{\text{cmd}}$ and the measured value $y_{p}$.
It can also be defined as the difference between commanded output and estimated output, but that will give different results.
I don't really know what the advantages/disadvantages of doing it either way are yet.
The basic closed-loop estimator equation, with integral error, and feedback control law
The more detailed block diagram is shown in the following figure.

% TODO@dpwiese - FIX THIS FIGURE TO INCLUDE $z$ and $y_{p}$
\begin{figure}[H]
  % \fontsize{7pt}{7pt}\selectfont
  \begin{center}
    \psfragfig[width=6.0in]{\figurepath/dofb_servo_v2}{%
      \psfrag{r}[bc][bc][1.0]{$r$}
      \psfrag{p}[bc][bc][1.0]{$+$}
      % \psfrag{m}[bc][bc][1.0]{$$} % chktex 45
      \psfrag{ci}[mc][mc][1.0]{$1$}
      \psfrag{s}[mc][mc][1.0]{$\Sigma$}
      \psfrag{i}[mc][mc][1.0]{$\frac{1}{s}$}
      \psfrag{a}[mc][mc][1.0]{$A_{p}$}
      \psfrag{b}[mc][mc][1.0]{$B_{p}$}
      \psfrag{c}[mc][mc][1.0]{$C_{p}$}
      \psfrag{d}[mc][mc][1.0]{$D_{p}$}
      \psfrag{u}[bc][bc][1.0]{$u$}
      \psfrag{y}[bc][bc][1.0]{$-y_{p}$}
      \psfrag{yh}[bc][bc][1.0]{$\hat{y}_{p}$}
      \psfrag{xh}[bc][bc][1.0]{$\hat{x}_{p}$}
      \psfrag{xe}[bc][bc][1.0]{$x_{e}$}
      \psfrag{kc}[mc][mc][1.0]{$K_{x}^{\top}$}
      \psfrag{kf}[mc][mc][1.0]{$K_{f}$}
      \psfrag{obsv}[tl][tl][1.0]{Observer}
      \psfrag{comp}[tr][tr][1.0]{Compensator}
      \psfrag{plant}[bc][bc][1.0]{Plant}
    }
    \caption{Observer controller and plant}
  \end{center}
\end{figure}

Propose the following observer
\begin{equation*}
  \begin{split}
    \dot{\hat{x}}_{p}&=A_{p}\hat{x}_{p}+B_{p}u+K_{f}(\hat{y}_{p}-y_{p}) \\
    \hat{y}_{p}&=C_{p}\hat{x}_{p}+D_{p}u \\
  \end{split}
\end{equation*}
Combining this observer with the integral error equation and the control law
\begin{equation*}
  \begin{split}
    \dot{\hat{x}}_{p}&=A_{p}\hat{x}_{p}+B_{p}u+K_{f}(\hat{y}_{p}-y_{p}) \\
    \hat{y}_{p}&=C_{p}\hat{x}_{p}+D_{p}u \\
    \dot{x}_{e}&=z_{\text{cmd}}-z \\
    u&=K_{p}^{\top}\hat{x}_{p}+K_{e}^{\top}x_{e}
  \end{split}
\end{equation*}

\begin{equation*}
  \begin{split}
    \dot{\hat{x}}_{p}&=A_{p}\hat{x}_{p}+B_{p}(K_{p}^{\top}\hat{x}_{p}+K_{e}^{\top}x_{e})+K_{f}[C_{p}\hat{x}_{p}+D_{p}(K_{p}^{\top}\hat{x}_{p}+K_{e}^{\top}x_{e})-y_{p}] \\
    \dot{x}_{e}&=z_{\text{cmd}}-z \\
    u&=K_{p}^{\top}\hat{x}_{p}+K_{e}^{\top}x_{e}
  \end{split}
\end{equation*}

\begin{equation*}
  \begin{split}
    \dot{\hat{x}}_{p}&=A_{p}\hat{x}_{p}+B_{p}K_{p}^{\top}\hat{x}_{p}+B_{p}K_{e}^{\top}x_{e}
    +K_{f}C_{p}\hat{x}_{p}+K_{f}D_{p}K_{p}^{\top}\hat{x}_{p}+K_{f}D_{p}K_{e}^{\top}x_{e}-K_{f}y_{p} \\
    \dot{x}_{e}&=z_{\text{cmd}}-z \\
    u&=K_{p}^{\top}\hat{x}_{p}+K_{e}^{\top}x_{e}
  \end{split}
\end{equation*}

\begin{equation*}
  \begin{split}
    \dot{\hat{x}}_{p}&=(A_{p}+B_{p}K_{p}^{\top}+K_{f}C_{p}+K_{f}D_{p}K_{p}^{\top})\hat{x}_{p}+(B_{p}K_{e}^{\top}+K_{f}D_{p}K_{e}^{\top})x_{e}-K_{f}y_{p} \\
    \dot{x}_{e}&=z_{\text{cmd}}-z \\
    u&=K_{p}^{\top}\hat{x}_{p}+K_{e}^{\top}x_{e}
  \end{split}
\end{equation*}

Combining into a state space representation gives the dynamic output feedback compensator with servomechanism: DOFB-Servo.
\begin{align*}
  \begin{bmatrix}
    \dot{\hat{x}}_{p} \\
    \dot{x}_{e}
  \end{bmatrix}&=
  \begin{bmatrix}
    A_{p}+B_{p}K_{p}^{\top}+K_{f}C_{p}+K_{f}D_{p}K_{p}^{\top} & B_{p}K_{e}^{\top}+K_{f}D_{p}K_{e}^{\top} \\
    0 & 0
  \end{bmatrix}
  \begin{bmatrix}
    \hat{x}_{p} \\
    x_{e}
  \end{bmatrix}+
  \begin{bmatrix}
    0 \\
    I
  \end{bmatrix}z_{\text{cmd}}+
  \begin{bmatrix}
    K_{f} \\
    0
  \end{bmatrix}(-y_{p})+
  \begin{bmatrix}
    0 \\
    I
  \end{bmatrix}(-z) \\
  u&=
  \left[
    \begin{array}{cc}
      K_{p}^{\top} & K_{e}^{\top}
    \end{array}
  \right]
  \left[
    \begin{array}{c}
      \hat{x}_{p} \\
      x_{e}
    \end{array}
  \right]
\end{align*}
Combining both inputs into one the final state-space representation for the DOFB-Servo compensator is had, and will now be used for evaluation of the loop transfer functions.

\begin{empheq}[box={\labelBox[Non-Augmented Observer (Full Compensator)]}]{alignat*=2}
  \begin{split}
    \begin{bmatrix}
      \dot{\hat{x}}_{p} \\
      \dot{x}_{e}
    \end{bmatrix}
    =&
    \begin{bmatrix}
      A_{p}+B_{p}K_{p}^{\top}+K_{f}C_{p}+K_{f}D_{p}K_{p}^{\top} & B_{p}K_{e}^{\top}+K_{f}D_{p}K_{e}^{\top} \\
      0 & 0
    \end{bmatrix}
    \begin{bmatrix}
      \hat{x}_{p} \\ x_{e}
    \end{bmatrix}+
    \begin{bmatrix}
      0 & K_{f} & 0\\
      I & 0 & I
    \end{bmatrix}
    \begin{bmatrix}
      z_{\text{cmd}} \\
      -y_{p} \\
      -z
    \end{bmatrix} \\
    u=&
    \left[
      \begin{array}{cc}
        K_{p}^{\top} & K_{e}^{\top}
      \end{array}
    \right]
    \left[
      \begin{array}{c}
        \hat{x}_{p} \\
        x_{e}
      \end{array}
    \right]
  \end{split}
\end{empheq}

\subsection{Augmented Observer}

The plant for which we will design a dynamic output feedback compensator for is given by
\begin{equation*}
  \begin{split}
    \dot{x}_{p}&=A_{p}x_{p}+B_{p}u \\
    y_{p}&=C_{p}x_{p}+D_{p}u \\
    z&=C_{pz}x_{p}+D_{pz}u
  \end{split}
\end{equation*}
where $x_{p}\in\mathbb{R}^{n_{p}}$, $u\in\mathbb{R}^{m}$, $y_{p}\in\mathbb{R}^{\ell}$ and $z\in\mathbb{R}^{n_{e}}$ is the regulated output.
The integral error state is defined by
\begin{equation}
  \label{eqn.integralerror}
  \dot{x}_{e}=z_{\text{cmd}}-z
\end{equation}
Using the error description in (\ref{eqn.integralerror}), the state vector $x_{p}$ is augmented to include this error by including $x_{e}$ as a state variable
\begin{equation}
  \label{linear.lqrpi_linear_ss_eqn}
  \begin{bmatrix}
    \dot{x}_{p} \\
    \dot{x}_{e}
  \end{bmatrix}
  =
  \begin{bmatrix}
    A_{p} & 0_{n_{p}\times n_{e}} \\
    -C_{pz} & 0_{n_{e}\times n_{e}}
  \end{bmatrix}
  \begin{bmatrix}
    x_{p} \\
    x_{e}
  \end{bmatrix}
  +
  \begin{bmatrix}
    B_{p} \\
    -D_{pz}
  \end{bmatrix}u
  +
  \begin{bmatrix}
    0_{n_{p}\times n_{e}} \\
    I_{n_{e}\times n_{e}}
  \end{bmatrix}z_{\text{cmd}}
\end{equation}
Writing the linear state-space representation in~\eqref{linear.lqrpi_linear_ss_eqn} more compactly using $x=\bigr[\begin{array}{cc} x_{p}^{\top} & x_{e}^{\top} \end{array}\bigr]^{\top}$ as
\begin{equation*}
  \begin{split}
    \dot{x}&=Ax+Bu+B_{\text{cmd}}z_{\text{cmd}} \\
    y&=Cx+Du
  \end{split}
\end{equation*}
where $x\in\mathbb{R}^{n}$, $z_{\text{cmd}}\in\mathbb{R}^{n_{e}}$, $A\in\mathbb{R}^{n\times n}$, $B\in\mathbb{R}^{n\times m}$, $B_{\text{cmd}}\in\mathbb{R}^{n\times n_{e}}$ and where
\begin{equation*}
  A=
  \begin{bmatrix}
    A_{p} & 0 \\
    -C_{pz} & 0
  \end{bmatrix}
  \quad
  B=
  \begin{bmatrix}
    B_{p} \\
    -D_{pz}
  \end{bmatrix}
  \quad
  B_{\text{cmd}}=
  \begin{bmatrix}
    0 \\
    I
  \end{bmatrix}
  \quad
  C=
  \begin{bmatrix}
    C_{p} & 0_{\ell\times n_{e}} \\
    0_{n_{e}\times n_{p}} & I_{n_{e}\times n_{e}}
  \end{bmatrix}
  \qquad
  D=
  \begin{bmatrix}
    D_{p} \\
    0_{n_{e}\times m}
  \end{bmatrix}
\end{equation*}
and where $y\in\mathbb{R}^{p}$ where $p=\ell+n_{e}$.
The difference in this case versus the non-augmented observer approach is that now we will generate an estimator for the augmented system, and use that entire estimate for feedback.
This includes an estimate of the error state.Consider the following observer with control law
\begin{equation*}
  \begin{split}
    \dot{\hat{x}}&=A\hat{x}+Bu+B_{\text{cmd}}z_{\text{cmd}}+L(\hat{y}-y) \\
    \hat{y}&=C\hat{x}+Du \\
    u&=K_{x}^{\top}\hat{x}
  \end{split}
\end{equation*}

\begin{equation*}
  \begin{split}
    \dot{\hat{x}}&=A\hat{x}+BK_{x}^{\top}\hat{x}+B_{\text{cmd}}z_{\text{cmd}}+LC\hat{x}+LDK_{x}^{\top}\hat{x}-Ly \\
    u&=K_{x}^{\top}\hat{x}
  \end{split}
\end{equation*}

\begin{equation*}
  \begin{split}
    \dot{\hat{x}}&=(A+BK_{x}^{\top}+LC+LDK_{x}^{\top})\hat{x}+B_{\text{cmd}}z_{\text{cmd}}-Ly \\
    u&=K_{x}^{\top}\hat{x}
  \end{split}
\end{equation*}

\begin{empheq}[box={\labelBox[Augmented Observer (Observer Only)]}]{alignat=2}
  \begin{split}
    \dot{\hat{x}}&=(A+BK_{x}^{\top}+LC+LDK_{x}^{\top})\hat{x}+
    \begin{bmatrix}
      B_{\text{cmd}} & L
    \end{bmatrix}
    \begin{bmatrix}
      z_{\text{cmd}} \\
      -y
    \end{bmatrix} \\
    u&=K_{x}^{\top}\hat{x}
  \end{split}
\end{empheq}

The above is a representation only of the observer, and not the whole compensator, as the integral error state is also a part of the compensator and needs to be included in the dynamics

\begin{equation*}
  L=
  \begin{bmatrix}
    L_{p} & L_{e}
  \end{bmatrix}
\end{equation*}

\begin{equation*}
  y=
  \begin{bmatrix}
    y_{p} \\
    z
  \end{bmatrix}
\end{equation*}

\begin{equation*}
  \begin{bmatrix}
    z_{\text{cmd}} & -y_{p} & -z
  \end{bmatrix}^{\top}
\end{equation*}

\begin{equation*}
  \begin{split}
    \dot{\hat{x}}&=(A+BK_{x}^{\top}+LC+LDK_{x}^{\top})\hat{x}+
    B_{\text{cmd}}z_{\text{cmd}} - L_{p}y_{p} - L_{e}z \\
    \dot{x}_{e}&=z_{\text{cmd}}-z \\
    u&=K_{x}^{\top}\hat{x}
  \end{split}
\end{equation*}

\begin{empheq}[box={\labelBox[Augmented Observer (Full Compensator)]}]{alignat=2}
  \begin{split}
    \begin{bmatrix}
      \dot{\hat{x}} \\
      \dot{x}_{e}
    \end{bmatrix}
    &=
    \begin{bmatrix}
      A+BK_{x}^{\top}+LC+LDK_{x}^{\top} & 0 \\
      0 & 0
    \end{bmatrix}
    \begin{bmatrix}
      \hat{x} \\
      x_{e}
    \end{bmatrix}+
    \begin{bmatrix}
      B_{\text{cmd}} & L_{p} & L_{e} \\
      1 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
      z_{\text{cmd}} \\
      -y_{p} \\
      -z
    \end{bmatrix} \\
    u&=K_{x}^{\top}\hat{x}
  \end{split}
\end{empheq}

\begin{figure}[H]
  %\fontsize{16pt}{16pt}\selectfont
  \begin{center}
    \begin{tikzpicture}[auto, scale=1.0, every node/.style={transform shape}, node distance=1.0cm, >=latex']
      \node[squareblock, minimum height=2cm, minimum width=2cm, label=above:{Controller}] (block1){$K(s)$};
      \node[left=of block1.150, node distance=5.0cm] (j1) {};
      \node[left of=j1, node distance=1.9cm] (input1) {};
      \node[whitesum,left=of block1.200, node distance=1.5cm] (sum1) {};
      \node[input, left of=sum1, node distance=1.5cm](input2){};
      \node[squareblock, minimum height=2cm, minimum width=2cm, right of=block1, label=above:{Plant},node distance=3.5cm] (block2) {$G(s)$};
      \node[output, right of=block2,node distance=2.5cm] (output1) {};
      \draw[->](input1) -- node[near start]{$z_{\text{cmd}}$} (block1.150);
      \draw[->](input2) -- node[near start]{$r$} node[pos=0.9] {$+$} (sum1);
      \draw[->](sum1) -- node{$e$} (block1.200);
      \draw[->](block1) -- node[name=u]{$u$} (block2);
      \draw[->](block2) -- node[name=y]{$y$} (output1);
      \node[input, below of=u, node distance=1.8cm](tee){};
      \draw[-](y) |- (tee);
      \draw[->](tee) -| node[pos=0.9]{$-$} (sum1);
    \end{tikzpicture}
    \caption{System block diagram}
  \end{center}
\end{figure}

\subsection{Loop Transfer Recovery}

% TODO@dpwiese - Show how to find $T(s)$ by closing the loop for LQR-PI controller.
% TODO@dpwiese - Is LTR for square systems only?

See Lavretsky, Wise page (184) 193.
In analyzing the compensator and understanding loop transfer recovery, we consider two control systems: one state feedback and one output feedback.
If the state feedback system is designed using LQR, then it will have excellent margins.
If the output feedback system is designed using LQG, its margins may be arbitrarily bad.
The process of loop transfer recover attempts to make the LQG controller like the LQR controller.
While this statement is rather vague, the two systems will never be the same, as the LQG controller has many states, whereas the LQR controller without integral action has no states.
However, what we mean by making the LQG controller look like the LQR is that the loop shapes in the frequency domain will be the same over a frequency range of interest, thus recovering the LQR margins.

To do this comparison, we break the loop at the input of both the LQR and LQG controllers.
We look at the transfer function from $u_{i}$ to $u_{o}$ and see how we can change the observer gain so that these two transfer functions start to look the same.
The plant has state-space representation

\begin{equation*}
  \dot{x}_{p}=A_{p}x_{p}+B_{p}u_{i}
\end{equation*}
The transfer function from the plant input to its output is given by

\begin{equation*}
  \frac{x_{p}}{u_{i}}=(sI-A_{p})^{-1}B_{p}
\end{equation*}
The LQR compensator is described by

\begin{equation*}
  u_{o}=-K_{p}^{\top}x_{p}
\end{equation*}
Multiplying the two transfer functions together gives the transfer function through the control loop when it is broken at the plant input for the LQR controller

\begin{equation*}
  \frac{u_{o}}{u_{i}}=-K_{p}^{\top}(sI-A_{p})^{-1}B_{p}
\end{equation*}

Now let's analyze the output feedback compensator.
In this case the plant equation must include the output.
If we dont use a $D$ term the plant is described by
\begin{empheq}{alignat*=2}
  \dot{x}_{p}&=A_{p}x_{p}+B_{p}u_{i} \\
  y_{p}&=C_{p}x_{p}
\end{empheq}
The transfer function from the plant input to its output is given by

\begin{equation*}
  \frac{y_{p}}{u_{i}}=C_{p}(sI-A_{p})^{-1}B_{p}
\end{equation*}
The LQG compensator is described by

\begin{empheq}{alignat*=2}
  \dot{\hat{x}}_{p}&=(A_{p}-K_{f}C_{p}-B_{p}K_{x})\hat{x}+K_{f}y_{p} \\
  u_{o}&=-K_{p}^{\top}\hat{x}_{p}
\end{empheq}
This gives the following transfer function from the input to the compensator (which is the plant output) to the compensator output (the control)

\begin{equation*}
  \frac{u_{o}}{y_{p}}=-K_{p}^{\top}(sI-A_{p}+K_{f}C_{p}+B_{p}K_{p}^{\top})^{-1}K_{f}
\end{equation*}
Multiplying the two transfer functions together gives the transfer function through the control loop when it is broken at the plant input

\begin{equation*}
  \frac{u_{o}}{u_{i}}=-K_{p}^{\top}(sI-A_{p}+K_{f}C_{p}+B_{p}K_{p}^{\top})^{-1}K_{f}C_{p}(sI-A_{p})^{-1}B_{p}
\end{equation*}

\subsection{An LTR Alternative to Output Feedback}

Consider the following MIMO uncertain open-loop system
\begin{equation}
  \label{eqn.linear.openloopsys}
  \begin{split}
    \dot{x}_{p}&=A_{p}x_{p}+B_{p}u \\
    y_{p}&=C_{p}x_{p} \\
    z&=C_{pz}x_{p}+D_{pz}u
  \end{split}
\end{equation}
where $A_{p}\in\mathbb{R}^{n_{p}\times n_{p}}$, $B_{p}\in\mathbb{R}^{n_{p}\times m}$, $C_{p}\in\mathbb{R}^{\ell\times n_{p}}$, $C_{pz}\in\mathbb{R}^{n_{e}\times n_{p}}$ are constant \textit{known} matrices.
$z$ is the regulated output, and the number of regulated outputs cannot exceed the number of inputs, that is $n_{e}\leq m$.
The goal is to design a control input $u$ which will make $z$ tend to the reference command $z_{\text{cmd}}$ asymptotically.

In order to ensure command tracking, we introduce integral action, and for this purpose an additional state $x_e$ is defined as
\begin{equation*}
  \dot{x}_{e}=z_{\text{cmd}}-z
\end{equation*}
and the plant in~\eqref{eqn.linear.openloopsys} is augmented to lead to the following extended open-loop dynamics
\begin{equation}
  \label{eqn.linear.uncsystemfull}
  \begin{split}
    \begin{bmatrix}
      \dot{x}_{p} \\
      \dot{x}_{e}
    \end{bmatrix}
    &=
    \begin{bmatrix}
      A_{p} & 0 \\
      -C_{pz} & 0
    \end{bmatrix}
    \begin{bmatrix}
      x_{p} \\
      x_{e}
    \end{bmatrix}
    +
    \begin{bmatrix}
      B_{p} \\
      -D_{pz}
    \end{bmatrix}u
    +
    \begin{bmatrix}
      0 \\
      I
    \end{bmatrix}z_{\text{cmd}} \\
    \begin{bmatrix}
      y_{p} \\
      x_{e}
    \end{bmatrix}
    &=
    \begin{bmatrix}
      C_{p} & 0 \\
      0 & I
    \end{bmatrix}
    \begin{bmatrix}
      x_{p} \\
      x_{e}
    \end{bmatrix} \\
  \end{split}
\end{equation}
The system in~\eqref{eqn.linear.uncsystemfull} can be written more compactly as
\begin{equation}
  \label{eqn.linear.uncsystem}
  \begin{split}
    \dot{x}&=Ax+Bu+B_{\text{cmd}}z_{\text{cmd}} \\
    y&=Cx
  \end{split}
\end{equation}
where $A\in\mathbb{R}^{n\times n}$, $B\in\mathbb{R}^{n\times m}$, $B_{\text{cmd}}\in\mathbb{R}^{n\times n_{e}}$, and $C\in\mathbb{R}^{p\times n}$ are the known matrices given by
\begin{equation*}
  A=
  \begin{bmatrix}
    A_{p} & 0_{n_{p}\times n_{e}} \\
    -C_{pz} & 0_{n_{e}\times n_{e}}
  \end{bmatrix} \quad
  B=
  \begin{bmatrix}
    B_{p} \\
    -D_{pz}
  \end{bmatrix}
  \quad
  B_{\text{cmd}}=
  \begin{bmatrix}
    0_{n_{p}\times m} \\
    I_{n_{e}\times n_{e}}
  \end{bmatrix}
  \quad
  C=
  \begin{bmatrix}
    C_{p} & 0_{\ell\times n_{e}} \\
    0_{n_{e}\times n} & I_{n_{e}\times n_{e}}
  \end{bmatrix}
\end{equation*}
Note that $p=\ell+n_{e}$.
We make the following assumptions about the system $\Sigma=(A,B,C,0)$ in~\eqref{eqn.linear.uncsystem}.

\begin{ass-dan} $\;$\label{ass.linear.uncsystem}
  \begin{enumerate}[a)] % chktex 9 chktex 10
    \setlength{\itemindent}{0.25in}
    \itemsep0em
    \item{$(A,B)$ is controllable.\label{ass.linear.cont}}
    \item{$(A,C)$ is observable.\label{ass.linear.obsv}}
    \item{$B$, $C$, and $CB$ are full rank.\label{ass.linear.rank}}
    \item{Any transmission zeros of $\Sigma$ are strictly stable.\label{ass.linear.tzero}}
    \item{$\Sigma$ is tall: $p\geq m$.\label{ass.linear.tall}}
  \end{enumerate}
\end{ass-dan}

\begin{rem-dan}
  Assumptions~\ref{ass.linear.uncsystem}\ref{ass.linear.cont} and~\ref{ass.linear.uncsystem}\ref{ass.linear.obsv} are standard.
  Assumption~\ref{ass.linear.uncsystem}\ref{ass.linear.rank} implies that inputs and outputs are not redundant, as well as a MIMO equivalent of relative degree unity.
  Assumption~\ref{ass.linear.uncsystem}\ref{ass.linear.tzero} is a standard requirement for adaptive control.
  Assumption~\ref{ass.linear.uncsystem}\ref{ass.linear.tall} can be considered without loss of generality as the case of wide systems $p<m$ holds by duality.
\end{rem-dan}

\begin{rem-dan}\label{rem.plant}
  Given a system $\Sigma_{p}=(A_{p},B_{p},C_{p},0)$ which satisfies
  %\begin{enumerate}[a)]
  \begin{itemize}
    %\setlength{\itemindent}{0.25in}
    \itemsep0em
    \item{$(A_{p},B_{p})$ is controllable.\label{ass.p.cont}}
    \item{$(A_{p},C_{p})$ is observable.\label{ass.p.obsv}}
    \item{$B_{p}$, $C_{p}$, and $C_{p}B_{p}$ are full rank.\label{ass.p.rank}}
    \item{Any transmission zeros of $\Sigma_{p}$ are strictly stable.\label{ass.p.tzero}}
    \item{The rank of the following matrix is full}
    \begin{equation*}
      \text{rank}
      \left(
        \begin{bmatrix}
          A_{p} & B_{p} \\
          -C_{pz} & -D_{pz}
        \end{bmatrix}
      \right)
      =n_{p}+n_{e}
    \end{equation*}
    %\end{enumerate}
  \end{itemize}
  when augmented with the integral error state as shown in~\eqref{eqn.linear.uncsystemfull} also satisfies Assumption~\ref{ass.linear.uncsystem}\ref{ass.linear.cont}-\ref{ass.linear.tzero}.
  In other words, under these assumptions, integral error augmentation does not destroy controllability or observability, the rank conditions, nor does it add any transmission zeros~\cite{lavretsky.output.2010}.
\end{rem-dan}

\section{PI-Observer and Controller}

Consider again the same plant as before, but this time with a constant sensor bias $d_{\text{out}}$ on the output as represented in the figure below.

\begin{figure}[H]
  \begin{center}
    \begin{tikzpicture}[auto, scale=0.8, every node/.style={transform shape}, node distance=1.0cm, >=latex']
      \node[input](input1){};
      \node[squareblock, right of=input1, label=above:{},node distance=2.5cm] (block1) {Plant};
      \node[whitesum, right of=block1,node distance=2.5cm] (sum2) {};
      \node[output, right of=sum2,node distance=2.0cm] (output1) {};
      \node[input, above of=sum2,node distance=1.5cm] (input3) {};
      %Model box
      \path (input1 |- input1)+(1.0,1.8) node (c) {};
      \path (output1 -| output1)+(-1.0,-1.0) node (d) {};
      \path[draw, dashed] (c) rectangle (d);
      %Draw lines
      \draw[->](input1) -- node[near start]{$u$} (block1);
      \draw[->](block1) -- node{$\bar{z}_{p}$} node[pos=0.9]{$+$} (sum2);
      \draw[->](input3) -- node[near start]{$d_{\text{out}}$} node[pos=0.9]{$+$} (sum2);
      \draw[->](sum2) -- node[pos=0.8]{$z_{p}$} (output1);
    \end{tikzpicture}
  \end{center}
\end{figure}

The equations describing this system are
\begin{align*}
  \dot{x}_{p}&=A_{p}x_{p}+B_{p}u \\
  \bar{z}_{p}&=C_{p}x_{p} \\
  z_{p}&=\bar{y}_{p}+d_{\text{out}}
\end{align*}
First augment this state-space representation with an integral error state $\dot{x}_{e}=z_{\text{cmd}}-\bar{z}_{p}$ for the controller
\begin{align*}
  \begin{bmatrix}
    \dot{x}_{p} \\
    \dot{x}_{e}
  \end{bmatrix}&=
  \begin{bmatrix}
    A_{p} & 0 \\
    -C_{p} & 0
  \end{bmatrix}
  \begin{bmatrix}
    x_{p} \\
    x_{e}
  \end{bmatrix}+
  \begin{bmatrix}
    B_{p} \\
    0
  \end{bmatrix}u+
  \begin{bmatrix}
    0 \\
    I
  \end{bmatrix}z_{\text{cmd}}
\end{align*}
This system can be represented more compactly as follows
\begin{align*}
  \dot{x}&=Ax+Bu+B_{\text{cmd}}z_{\text{cmd}}
\end{align*}
From which we write the regulated output $\bar{z}_{p}$ and the corresponding biased regulated output $z_{p}$ as follows, and also we can define the measured outputs in the same way as $\bar{y}_{p}$ and $y_{p}$ where the measured outputs contain the regulated outputs, but also include as additional outputs the integral error state.
\begin{align*}
  \bar{z}_{p}&=
  \begin{bmatrix}
    C_{p} & 0
  \end{bmatrix}x \\
  &=C_{z}x \\
  z_{p}&=
  \begin{bmatrix}
    C_{p} & 0
  \end{bmatrix}x+d_{\text{out}} \\
  &=C_{z}x+d_{\text{out}}
\end{align*}
and the measured outputs are
\begin{align*}
  \bar{y}_{p}&=
  \begin{bmatrix}
    C_{p} & 0 \\
    0 & I
  \end{bmatrix}x \\
  &=Cx \\
  y_{p}&=
  \begin{bmatrix}
    C_{p} & 0 \\
    0 & I
  \end{bmatrix}x+
  \begin{bmatrix}
    I \\ 0
  \end{bmatrix}d_{\text{out}} \\
  &=Cx+B_{D}d_{\text{out}}
\end{align*}
Together these equations are
\begin{align*}
  \dot{x}&=Ax+Bu+B_{\text{cmd}}z_{\text{cmd}} \\
  \bar{y}_{p}&=Cx \\
  y_{p}&=Cx+B_{D}d_{\text{out}} \\
  \bar{z}_{p}&=C_{z}x \\
  z_{p}&=C_{z}x+d_{\text{out}}
\end{align*}
Using the control law
\begin{equation*}
  u=K_{x}^{\top}x
\end{equation*}
And substituting in, the compact form of the plant augmented with the integral error state, and closed loop with control law is

\begin{empheq}[box={\roomyfbox}]{equation*}
  \begin{alignedat}{1}
    \dot{x}&=A_{\text{ref}}x+B_{\text{cmd}}z_{\text{cmd}} \\
    \bar{y}_{p}&=Cx \\
    y_{p}&=Cx+B_{D}d_{\text{out}}
  \end{alignedat}
\end{empheq}

So, at this point we have basically assumed the state $x_{p}$ was available for measurement and the plant was completely known in determining the above system.
We can now write these dynamics in a different form to include the disturbance as a state.
\begin{align*}
  \begin{bmatrix}
    \dot{x} \\
    \dot{d}_{\text{out}}
  \end{bmatrix}&=
  \begin{bmatrix}
    A_{\text{ref}} & 0 \\
    0 & 0
  \end{bmatrix}
  \begin{bmatrix}
    x \\
    d_{\text{out}}
  \end{bmatrix}+
  \begin{bmatrix}
    B_{\text{cmd}} \\
    0
  \end{bmatrix}z_{\text{cmd}}
\end{align*}
This system can be represented more compactly as follows
\begin{align*}
  \dot{x}_{f}=A_{f}x_{f}+B_{f}z_{\text{cmd}}
\end{align*}
Outputs
\begin{align*}
\bar{z}_{p}&=
  \begin{bmatrix}
  C_{z} & 0
  \end{bmatrix}x_{f} \\
  &=
  \begin{bmatrix}
  C_{p} & 0 & 0
  \end{bmatrix}x_{f} \\
  &=\bar{C}_{zf}x_{f} \\
  z_{p}&=
  \begin{bmatrix}
  C_{z} & 1
  \end{bmatrix}x_{f} \\
  &=
  \begin{bmatrix}
  C_{p} & 0 & 1
  \end{bmatrix}x_{f} \\
  &=C_{zf}x_{f}
\end{align*}
and the measured outputs are
\begin{align*}
  \bar{y}_{p}&=
  \begin{bmatrix}
    C_{p} & 0 & 0 \\
    0 & I & 0
  \end{bmatrix}x_{f} \\
  &=\bar{C}_{f}x_{f} \\
  y_{p}&=
  \begin{bmatrix}
    C_{p} & 0 & I \\
    0 & I & 0
  \end{bmatrix}x_{f} \\
  &=C_{f}x_{f}
\end{align*}
So everything is
\begin{align*}
  \dot{x}_{f}&=A_{f}x_{f}+B_{f}z_{\text{cmd}} \\
  \bar{y}_{p}&=\bar{C}_{f}x_{f} \\
  y_{p}&=C_{f}x_{f} \\
  \bar{z}_{p}&=C_{zf}x_{f} \\
  z_{p}&=C_{zf}x_{f}
\end{align*}
where
\begin{equation*}
  x_{f}=
  \begin{bmatrix}
    x_{p}^{\top} & x_{e}^{\top} & d_{\text{out}}^{\top}
  \end{bmatrix}^{\top}
\end{equation*}
So now we have the plant with a closed-loop LQR-PI controller and disturbance with integrator all expressed in a single system.
The problem is that we cannot implement the above controller as the state $x_{p}$ which was used in the control law is unavailable.
We attempt to estimate not only this state, but also the error state and disturbance.
That is
\begin{align*}
  \dot{\hat{x}}_{f}&=A_{f}\hat{x}_{f}+B_{f}z_{\text{cmd}}+K_{f}(\hat{y}_{p}-y_{p}) \\
  \hat{\bar{y}}_{p}&=\bar{C}_{f}\hat{x}_{f} \\
  \hat{y}_{p}&=C_{f}\hat{x}_{f}
\end{align*}
where
\begin{equation*}
  \hat{x}_{f}=
  \begin{bmatrix}
    \hat{x}_{p}^{\top} & \hat{x}_{e}^{\top} & \hat{d}_{\text{out}}^{\top}
  \end{bmatrix}^{\top}
\end{equation*}
Expanding this estimator representation we get the following
\begin{align*}
  \begin{bmatrix}
    \dot{\hat{x}} \\
    \dot{\hat{d}}_{\text{out}}
  \end{bmatrix}&=
  \begin{bmatrix}
    A_{\text{ref}} & 0 \\
    0 & 0
  \end{bmatrix}
  \begin{bmatrix}
    \hat{x} \\
    \hat{d}_{\text{out}}
  \end{bmatrix}+
  \begin{bmatrix}
    B_{\text{cmd}} \\
    0
  \end{bmatrix}z_{\text{cmd}}+
  \begin{bmatrix}
    L_{v} \\
    L_{I}
  \end{bmatrix}(\hat{y}_{p}-y_{p})
\end{align*}
giving
\begin{empheq}[box={\roomyfbox}]{equation*}
  \begin{alignedat}{1}
    \dot{\hat{x}}_{f}&=A_{\text{ref}}\hat{x}_{f}+B_{\text{cmd}}z_{\text{cmd}}+L_{v}(\hat{y}_{p}-y_{p}) \\
    \dot{\hat{d}}_{\text{out}}&=L_{I}(\hat{y}_{p}-y_{p}) \\
    \hat{\bar{y}}_{p}&=\bar{C}_{f}\hat{x}_{f}
  \end{alignedat}
\end{empheq}

\paragraph{Design PI-Observer First, Then Control Later}
Dealing with an output bias is a dual problem to that of dealing with an input bias using an input integrator like in LQR-PI control.
The first step is to represent the system equations to include the disturbance as an augmented state as shown below.
Mathematically, these equations are exactly the same as above, just represented in a different way.
\begin{align*}
  \begin{bmatrix}
    \dot{x}_{p} \\
    \dot{d}_{\text{out}}
  \end{bmatrix}&=
  \begin{bmatrix}
    A_{p} & 0 \\
    0 & 0
  \end{bmatrix}
  \begin{bmatrix}
    x_{p} \\
    d_{\text{out}}
  \end{bmatrix}+
  \begin{bmatrix}
    B_{p} \\
    0
  \end{bmatrix}u \\
  z_{p}&=
  \begin{bmatrix}
    C_{p} & 1
  \end{bmatrix}
  \begin{bmatrix}
    x_{p} \\
    d_{\text{out}}
  \end{bmatrix}+
  D_{p}u
\end{align*}
More compactly these equations can be written
\begin{align*}
  \dot{x}&=Ax+Bu \\
  z_{p}&=Cx+D_{p}u
\end{align*}
Now we design an estimator for this new system.
The state $z$ and corresponding estimated state $\hat{z}$ are
\begin{equation*}
  z=
  \begin{bmatrix}
    x_{p} \\
    d_{\text{out}}
  \end{bmatrix}
  \hspace{0.5in}
  \hat{z}=
  \begin{bmatrix}
    \hat{x}_{p} \\
    \hat{d}_{\text{out}}
  \end{bmatrix}
\end{equation*}
This allows the biased output $y_{p}$ and the non-biased output $\bar{y}_{p}$ to be estimated, and thus the estimate of the bias to be determined.
\begin{equation*}
  \begin{alignedat}{1}
    \dot{\hat{z}}&=A\hat{z}+Bu+K_{f}(\hat{y}_{p}-y_{p}) \\
    \hat{y}_{p}&=C\hat{z}+D_{p}u \\
    \hat{\bar{y}}_{p}&=\bar{C}\hat{z}+D_{p}u \\
  \end{alignedat}
\end{equation*}
where the output matrix for the estimate of the unbiased output is
\begin{align*}
  \bar{C}&=
  \begin{bmatrix}
    C_{p} & 0
  \end{bmatrix}
\end{align*}
Can also have output matrix for disturbance estimate
\begin{align*}
  C_{\hat{d}}&=
  \begin{bmatrix}
    0 & 1
  \end{bmatrix}
\end{align*}
To make the proportional and integral components of this observer more clear, represent the observer above by splitting up $K_{f}$ and writing
\begin{equation*}
  \begin{alignedat}{1}
    \dot{\hat{x}}_{p}&=A_{p}\hat{x}_{p}+B_{p}u+K_{P}(\hat{y}_{p}-y_{p}) \\
    \dot{\hat{d}}_{\text{out}}&=K_{I}(\hat{y}_{p}-y_{p}) \\
    \hat{y}_{p}&=C_{p}\hat{x}_{p}+\hat{d}_{\text{out}} \\
    \hat{\bar{y}}_{p}&=C_{p}\hat{x}_{p}
  \end{alignedat}
\end{equation*}
where
\begin{align*}
  K_{f}&=
  \begin{bmatrix}
    K_{P} \\
    K_{I}
  \end{bmatrix}
\end{align*}
The thinking here is a little bit different than when creating the integral error state in LQR-PI controller.
In LQR-PI control, this error state is constructed by considering measurements which are available, and asking ourselves what signals should be differenced to make an error which should then be driven to zero.
That is, if we have an unbiased output measurement which we want to drive to some reference value, we difference these, then call this difference the derivative of the error state.
Then, by augmenting the state-space description with this error state, we convince ourselves that at steady state this error derivative must become zero, requiring the measurement to be equal to the command.

With the PI observer it is a little bit different.
That $\hat{y}_{p}$ will track $y_{p}$ at steady state in the presence of an output disturbance is not what we are interested in, but rather that this process gives convergence of $\hat{x}_{p}$ to $x_{p}$.
It is from this estimated state which we can then construct an estimate of the unbiased output $\hat{\bar{y}}_{p}$.
In thinking of this problem it is convenient to think always of the plant as the system which includes the output bias, and concern ourselves only with estimating $\hat{x}_{p}$.

From here we can design a controller.
Here we will use an LQR-PI controller, which has control law
\begin{equation*}
  u=K_{p}^{\top}\hat{x}_{p}+K_{e}^{\top}x_{e}
\end{equation*}
where the integral error state is defined as
\begin{equation*}
  \dot{x}_{e}=r-H\hat{x}_{p}
\end{equation*}

\chapter{Frequency Domain Analysis}

\section{Introduction}

Frequency response method: give a system a sinusoidal input.
The output (will always be?) a sinusoid, with a magnitude and phase which may be different than the input, but the frequency will be the same.
Then, sweep the input frequency across a wide range, and observe how the gain and phase shift of the measured output change with frequency.

\section{Compensator Analysis Using Loop Transfer Functions}

References: see~\cite{lavretskywise.book.2013} (Chapter 5) and Astrom and~\cite{astrom.feedbackintro.2010} (Chapter 11).

\subsubsection{Relative Stability}

This block diagram below encompasses the types of controller designs we want to consider.
If $z_{\text{cmd}}=0$, this is the classical block diagram, where the error signal $e$ is the only input to the controller.
When $r=0$, the input is given directly through $z_{\text{cmd}}$, as is the case with the LQR-PI controller.

\begin{figure}[H]
  \begin{center}
    \begin{tikzpicture}[auto, scale=1.0, every node/.style={transform shape}, node distance=1.0cm, >=latex']
      \node[squareblock, label=above:{Controller}] (block1){$K(s)$};
      \node[left=of block1.150, node distance=5.0cm] (j1) {};
      \node[left of=j1, node distance=1.9cm] (input1) {};
      \node[whitesum,left=of block1.200, node distance=1.5cm] (sum1) {};
      \node[input, left of=sum1, node distance=1.5cm](input2){};
      \node[whitesum, right of=block1, node distance=2.5cm] (sum2) {};
      \node[input, above of=sum2,node distance=1.5cm](input3){};
      \node[squareblock, right of=sum2, label=above:{Plant},node distance=2.5cm] (block2) {$G(s)$};
      \node[whitesum, right of=block2,node distance=2.5cm] (sum3) {};
      \node[input, above of=sum3,node distance=1.5cm](input4){};
      \node[output, right of=sum3,node distance=2.5cm] (output1) {};
      \draw[->](sum3) --  node[name=yi,pos=0.4]{$y_{i}$}(output1);
      \node[whitesum, below of=yi,node distance=2.5cm] (sum4) {};
      \node[input, right of=sum4,node distance=1.5cm](input5){};
      \draw[->](input1) -- node[near start]{$z_{\text{cmd}}$} (block1.150);
      \draw[->](input2) -- node[near start]{$r$} node[pos=0.9] {$+$} (sum1);
      \draw[->](sum1) -- node{$e$} (block1.200);
      \draw[->](block1) -- node{$u_{o}$} node[pos=0.9]{$+$} (sum2);
      \draw[->](input3) -- node[near start]{$d_{in}$} node[pos=0.9] {$+$} (sum2);
      \draw[->](sum2) -- node{$u_{i}$} (block2);
      \draw[->](block2) -- node{$y_{o}$} node[pos=0.95] {$+$} (sum3);
      \draw[->](input4) -- node[near start]{$d_{out}$} node[pos=0.9] {$+$} (sum3);
      \draw[->](yi) -- node[pos=0.9] {$+$} (sum4);
      \draw[->](input5) -- node[near start]{$n$} node[pos=0.9] {$-$} (sum4);
      \draw[->](sum4) -| node{$w$} node[pos=0.95] {$-$} (sum1);
    \end{tikzpicture}
    \caption{General MIMO feedback control block diagram\label{fig.linear.lqrpiblock}}
  \end{center}
\end{figure}

The following section will explain how to determine the various transfer functions of interest which describe a plant and compensator in the block diagram form shown in Figure~\ref{fig.linear.lqrpiblock}.
In order to find the different loop transfer functions, the control loop will be broken at different points, and the transfer function at this broken point evaluated.
This is used to analyze what happens if noise or disturbances are injected at these different loop break points.
The following show how to find the loop transfer functions for MIMO plants and controller.
This is important because unlike SISO systems, multiplication of matrices is not commutative.

% TODO@dpwiese - prove this
Note also:
\begin{equation*}
  L(I+L)^{-1}=(I+L)^{-1}L
\end{equation*}

\subsection{Input}

\paragraph{Loop Transfer Function}
Breaking the loop at the plant input $u$ means to evaluate the transfer function from ``input'' $u_{i}$ to ``output'' $u_{o}$ while all other signals are zero.
\begin{equation*}
  y=G(s)u_{i}
\end{equation*}
\begin{equation*}
  e=-y
\end{equation*}
\begin{equation*}
  u_{o}=K(s)e=-K(s)y
\end{equation*}
\begin{equation*}
  u_{o}=-K(s)G(s)u_{i}=-L_{u}(s)u_{i}
\end{equation*}
\begin{empheq}[box=\roomyfbox]{equation*}
    L_{u}(s)=K(s)G(s)
\end{empheq}

\paragraph{Return Difference Transfer Function}

Differencing the ``input'' $u_{i}$ and ``output'' $u_{o}$ using the expression for output from above:
\begin{equation*}
  u_{i}-u_{o}=u_{i}-K(s)e
\end{equation*}
\begin{equation*}
  u_{i}-u_{o}=u_{i}+K(s)G(s)u_{i}
\end{equation*}
\begin{equation*}
  u_{i}-u_{o}=(I+K(s)G(s))u_{i}
\end{equation*}
\begin{equation*}
  u_{i}-u_{o}=(I+L_{u}(s))u_{i}
\end{equation*}
\begin{empheq}[box=\roomyfbox]{equation*}
  I+L_{u}(s)
\end{empheq}
When plotting this loop shape, it will be large at low frequencies and tend to unity at high frequencies, since the loop transfer function $L_{u}\rightarrow0$ at high frequencies.
This loop will dip below 0 dB, before leveling out, and the more it dips below 0 dB the worse the gain margin is.

\paragraph{Input Sensitivity Transfer Function $S_{u}(s)$}

The input sensitivity transfer function is from $d_{\text{in}}$ to $u_{i}$ while all other signals are zero.
\begin{equation*}
  u_{i}=u_{o}+d_{\text{in}}
\end{equation*}
\begin{equation*}
  u_{o}=K(s)e=-K(s)y
\end{equation*}
\begin{equation*}
  y=G(s)u_{i}
\end{equation*}
\begin{equation*}
  u_{i}=-K(s)G(s)u_{i}+d_{\text{in}}
\end{equation*}
\begin{equation*}
  (I+K(s)G(s))u_{i}=d_{\text{in}}
\end{equation*}
\begin{equation*}
  u_{i}=(I+K(s)G(s))^{-1}d_{\text{in}}
\end{equation*}
\begin{equation*}
  u_{i}=(I+L_{u}(s))^{-1}d_{\text{in}}
\end{equation*}
\begin{empheq}[box=\roomyfbox]{equation*}
  S_{u}(s)=(I+L_{u}(s))^{-1}
\end{empheq}

\paragraph{Complementary Input Sensitivity Transfer Function $T_{u}(s)$}

Unlike the $T_{y}(s)$, the input complementary sensitivity transfer function does not represent an relationship between any of the system inputs and outputs.
This transfer function is given by using the identity $S_{u}(s)+T_{u}(s)=I$, hence the name complementary sensitivity transfer function, but otherwise there is little intuition regarding what this transfer function represents.
\begin{equation*}
  \begin{split}
    S_{u}(s)+T_{u}(s)&=I \\
    (I+L_{u}(s))^{-1}+T_{u}&=I \\
    I+(I+L_{u}(s))T_{u}&=I+L_{u}(s) \\
    T_{u}&=(I+L_{u}(s))^{-1}L_{u}(s) \\
    T_{u}&=S_{u}(s)L_{u}(s)
  \end{split}
\end{equation*}
With $L(I+L)^{-1}=(I+L)^{-1}L$, which can be shown by pre- and post- multiplying both sides by $(I+L)$, we can also write $T_{u}(s)$ as
\begin{equation*}
  T_{u}(s)=L_{u}(I+L_{u}(s))^{-1}
\end{equation*}

\paragraph{Stability Robustness}

\begin{equation*}
  1+L_{u}^{-1}
\end{equation*}
At low frequencies $L_{u}^{-1}\rightarrow0$, so this loop shape will be unity for low frequencies and large at high frequencies, since at high frequencies $L_{u}^{-1}\rightarrow\infty$.
It will dip below 0 dB before going up, and the more it dips below 0 dB, the worse the gain margin will be.

\subsection{Output}

\paragraph{Loop Transfer Function $L_{y}(s)$}

Breaking the loop at the plant output $y$ means to evaluate the transfer function from ``input'' $y_{i}$ to ``output'' $y_{o}$ while all other signals are zero.
\begin{equation*}
  e=-y_{i}
\end{equation*}
\begin{equation*}
  u_{i}=u_{o}=K(s)e=-K(s)y_{i}
\end{equation*}
\begin{equation*}
  y_{o}=G(s)u_{i}
\end{equation*}
\begin{equation*}
  y_{o}=-G(s)K(s)y_{i}=-L_{y}(s)y_{i}
\end{equation*}
\begin{empheq}[box=\roomyfbox]{equation*}
  L_{y}(s)=G(s)K(s)
\end{empheq}

\paragraph{Return Difference Transfer Function}

Differencing the ``input'' $y_{i}$ and ``output'' $y_{o}$ using the expression for output from above:
\begin{equation*}
  y_{i}-y_{o}=y_{i}+G(s)K(s)y_{i}
\end{equation*}
\begin{equation*}
  y_{i}-y_{o}=(I+G(s)K(s))y_{i}
\end{equation*}
\begin{equation*}
  y_{i}-y_{o}=(I+L_{y}(s))y_{i}
\end{equation*}
\begin{empheq}[box=\roomyfbox]{equation*}
  I+L_{y}(s)
\end{empheq}

\paragraph{Output Sensitivity Transfer Function $S_{y}(s)$}

The output sensitivity is from $d_{\text{out}}$ to $y_{i}$ with all other signals are zero.
``The sensitivity function tells how the variations in the output are influenced by feedback''~\cite{astrom.feedbackintro.2010}

\begin{equation*}
  y_{i}=y_{o}+d_{\text{out}}
\end{equation*}
\begin{equation*}
  y_{o}=G(s)u_{i}=G(s)u_{o}
\end{equation*}
\begin{equation*}
  u_{o}=K(s)e=-K(s)y_{i}
\end{equation*}
\begin{equation*}
  y_{i}=-G(s)K(s)y_{i}+d_{\text{out}}
\end{equation*}
\begin{equation*}
  (I+G(s)K(s))y_{i}=d_{\text{out}}
\end{equation*}
\begin{equation*}
  y_{i}=(I+G(s)K(s))^{-1}d_{\text{out}}
\end{equation*}
\begin{equation*}
  y_{i}=(I+L_{y}(s))^{-1}d_{\text{out}}
\end{equation*}
\begin{empheq}[box=\roomyfbox]{equation*}
  S_{y}(s)=(I+L_{y}(s))^{-1}
\end{empheq}
At frequencies where plant disturbances are to be rejected, we want $S_{y}(s)\rightarrow0$.

\paragraph{Complementary Output Sensitivity Transfer Function $T_{y}(s)$}

Unlike $T_{u}(s)$, this transfer function represents the relationship between the noise $n$ and the output $y_{i}=y_{o}$.
This transfer function also satisfies the identity $S_{y}(s)+T_{y}(s)=I$, hence the name complementary sensitivity transfer function.

\begin{equation*}
  \begin{split}
    e&=r-w \\
    w&=y_{i}-n \\
    y_{i}&=G(s)K(s)e \\
    e&=r-y_{i}+n \\
    e&=r-G(s)K(s)e+n \\
    (I+G(s)K(s))e&=r+n \\
    e&=(I+G(s)K(s))^{-1}n \\
    y_{i}&=G(s)K(s)e \\
    y_{i}&=G(s)K(s)(I+G(s)K(s))^{-1}n
  \end{split}
\end{equation*}
\begin{empheq}[box=\roomyfbox]{equation*}
  T_{y}(s)=L_{y}(s)(I+L_{y}(s))^{-1}
\end{empheq}
This transfer function is the same as that between $r$ and the output $y_{i}=y_{o}$.

\subsection{The Gang of Six}

Now that the basic transfer functions have been found for a generic plant and controller feedback system, and an example of how to find the transfer function for the LQR-PI has been presented, we want to explain how to use the transfer functions to create some plots that will aid in control system analysis and design.
The following figure shows singular value plots of the ``gang of six''.

\subsection{Margins for MIMO System}

\section{Stuff}

\subsection{Gain and Phase of Poles and Zeros}

% TODO@dpwiese - Why do zeros add phase and poles reduce phase?

These two examples that follow connect the transfer function representation of the integrator and differentiator to a differential equation and show how, when the system is given a sinusoidal input, that the zero causes the output to lead the input, and the pole causes the output to lag behind the input.

\begin{equation*}
  \frac{x}{u}=\frac{1}{s}
\end{equation*}
The differential equation is

\begin{equation*}
  \dot{x}=u
\end{equation*}
This whole thing of gain and phase is for a given sinusoidal input, so $u(t)=A\sin(\omega t)$ and then we want to see how that will affect the output $x(t)$ for this system.

\begin{equation*}
  \frac{dx}{dt}=A\sin(\omega t)
\end{equation*}
separate and integrate back

\begin{equation*}
  \int_{x_{0}}^{x} dx=\int_{t_{0}}^{t} A\sin(\omega t)dt
\end{equation*}
giving

\begin{equation*}
  x-x_{0}=-\frac{A}{\omega}\cos(\omega t)+\frac{A}{\omega}\cos(\omega t_{0})
\end{equation*}

\begin{equation*}
  x(t)=-\frac{A}{\omega}\cos(\omega t)+\frac{A}{\omega}\cos(\omega t_{0})+x_{0}
\end{equation*}

\begin{equation*}
  x(t)=-\frac{A}{\omega}\cos(\omega t)
\end{equation*}
but $-\cos(x)=\sin(x-90^{\circ})$ so the input and corresponding output can be written

\begin{equation*}
  \begin{split}
    u(t)&=A\sin(\omega t) \\
    x(t)&=\frac{A}{\omega}\sin(\omega t-90^{\circ})
  \end{split}
\end{equation*}
So we can see that the magnitude of the output depends inversely on $\omega$, getting smaller as $\omega$ gets larger.
More importantly we can see clearly that there is a $90^{\circ}$ phase lag from the input to the output.
Consider now a differentiator.

\begin{equation*}
  \frac{x}{u}=s
\end{equation*}
gives

\begin{equation*}
  x=\dot{u}
\end{equation*}
and with $u(t)=A\sin(\omega t)$ we have

\begin{equation*}
  x(t)=A\omega\cos(\omega t)
\end{equation*}
together the input and output are

\begin{equation*}
  \begin{split}
    u(t)&=A\sin(\omega t) \\
    x(t)&=A\omega\cos(\omega t)
  \end{split}
\end{equation*}
But we have $\cos(x)=\sin(x+90^{\circ})$ giving

\begin{equation*}
  \begin{split}
    u(t)&=A\sin(\omega t) \\
    x(t)&=A\omega\sin(x+90^{\circ})
  \end{split}
\end{equation*}
and here we can see that there is a positive phase shift, or say that the output leads the input by $90$ degrees.

\subsection{How to Make Bode Plots}

first normalize the transfer function, so all the factors look like $(1+sa_{i})$

\subsection{Nyquist Plots}

\subsection{Output Filters}

\subsubsection{Types of Filters}

Talk about the different types of filters here, including elliptical filter.
Talk about why I want to use any particular one, and which ones work best.

\subsubsection{First Order Low-Pass Filter}

Filters can be used to condition an output signal which is to be used in feedback.
A low pass filter is given by the following transfer function, where the input to the filter is $u$ and the output is $y$.

\begin{equation*}
  \frac{y}{u}=\frac{10}{s+10}
\end{equation*}
Such a filter is best implemented in \textsc{Simulink} by representing it in state-space form, thus allowing the initial conditions to be set, which cannot be done using a transfer function representation.

\begin{equation*}
  \frac{y}{u}=\frac{y}{x}\frac{x}{u}=\frac{10}{s+10}
\end{equation*}
\begin{equation*}
  \frac{x}{u}=\frac{1}{s+10}
\end{equation*}
\begin{equation*}
  \frac{y}{x}=10
\end{equation*}
\begin{equation*}
  \dot{x}+10x=u
\end{equation*}
\begin{empheq}[box=\roomyfbox]{alignat*=2}
  \dot{x}&=-10x+u \\
  y&=10x
\end{empheq}
\begin{equation*}
  A=-10\quad B=1\quad C=10\quad D=0
\end{equation*}
This state-space representation of a low-pass filter can now be implemented in \textsc{Simulink}, but the initial conditions must be specified.
The filter takes as its input the unfiltered state $x$ and outputs the filtered state $x_{f}$.
When the simulation begins, if the initial conditions are not set, the filter will cause an abrupt spike in the state before settling down.
The initial conditions must be set such that when the simulation begins, at the first time step the output signal is the same as the input signal, and the filter state derivative should be zero.
That is, $\dot{x}(0)=0$ and $x_{f}(0)=x(0)$.
Using the state as the input $u=x$, the filtered state as the output $y=x_{f}$, and the actual internal filter state $x=x_{s}$\ldots

\begin{empheq}{alignat*=2}
  0&=-10x_{s}(0)+x(0) \\
  x_{f}(0)&=10x_{s}(0)
\end{empheq}
We see $x_{s}(0)=x(0)/10=(0)$ will make the filter state derivative $\dot{x}_{s}=0$ and the filtered output the same as the input.

% TODO@dpwiese - Put a Bode plot of the first order low-pass filter here

\chapter{Linear System Stuff}

\section{The Matrix Exponential}

\subsection{General System Stability}

Given a linear ODE of the following form
\begin{equation*}
  a_{n}y^{(n)}+\cdots+a_{2}\ddot{y}+a_{1}\dot{y}=b_{m}u^{(m)}+\cdots+b_{2}\ddot{u}+b_{1}\dot{u}
\end{equation*}
with a specified input function $u(t)$, the solution is the output function $y(t)$.
We say the system is BIBO stable if, given a bounded input function $u(t)$, the output function $y(t)$ is bounded for all time.
That is $|y(t)|<\alpha<\infty$.
Considering the Laplace transform of this system

\begin{equation*}
  Y(s)(a_{n}s^{n}+\cdots+a_{2}s^{2}+a_{1}s)=U(s)(b_{m}s^{m}+\cdots+b_{2}s^{2}+b_{1}s)
\end{equation*}
\begin{equation*}
  \frac{Y(s)}{U(s)}=\frac{(b_{m}s^{m}+\cdots+b_{2}s^{2}+b_{1}s)}{(a_{n}s^{n}+\cdots+a_{2}s^{2}+a_{1}s)}=
  \frac{N(s)}{D(s)}=G(s)
\end{equation*}
And for BIBO stability this corresponds to the denominator $D(s)$ having all of its roots have real part that is negative.
When taking the inverse Laplace transform of $G(s)$ if any of the roots were positive, this would result in the output taking the input and multiplying it by some increasing exponential.
So, regardless of which bounded input was fed to the system, the output would grow unbounded.
That is why stability requires the roods of $D(s)$ be negative.
Considering the transfer function representation of a stable system such as

\begin{equation*}
  \frac{Y(s)}{U(s)}=\frac{N(s)}{D(s)}=G(s)
\end{equation*}
Now, although the system is stable, we may want to know how stable it is.
We do this by looking at the roots of the denominator (which must all be all in the LHP for stability) and see how far they have to go before they become in the right half plane.

\subsection{Stability Margins}

Stability margins for a system have no meaning when considered outside the context of feedback.
Take a stable system $G(s)$.
If an additional gain or time delay is introduced between the input and the system, the output will be delayed, and scaled by this gain.
The same goes for delays or gains at the output.
But these will not effect the stability of the system.
Likewise if the system $G(s)$ is unstable, regardless of how the input is magnified or time-shifted, the resulting output will always ``blow up''.
Stability margins for a system $G(s)$ have to do with placing the system in feedback, and then determining how delays or gains added to the system will affect stability for the closed-loop system.
Consider the following system where the plant $G(s)$ is stable.
(It doesn't have to be) and we are designing a feedback controller to achieve some performance objectives out of the closed-loop system.
The input to the system is $U(s)$ and the output $Y(s)$.

\begin{equation*}
  \frac{Y(s)}{U(s)}=H(s)=\frac{KG}{1+KGH}
\end{equation*}
Call the quantity

\begin{equation*}
  L=KGH
\end{equation*}
giving

\begin{equation*}
  \frac{Y(s)}{U(s)}=H(s)=\frac{KG}{1+L}
\end{equation*}
Now the loop transfer function $L$ simply takes as an input a complex frequency $s$, and the result is a complex number with some magnitude and phase.
It is not obvious what values of $s$ would result in what complex numbers from $L$, or even what a ``good'' or ``bad'' value of $L$ is.
However, we can see from this equation that if $L=-1$ that the closed-loop system will ``blow up'', which is bad.

Intuitively, we know that given an arbitrary input, if the system is amplifying the signal through the feedback loop, the output will become larger and larger, indicating system instability.
One way to think about this is: after some initial amount of time with an arbitrary input, turn the input off.
If the signal within the loop eventually decays, the closed-loop system is stable.
If the signal in the loop grows, the system is unstable.

We consider the case when the input to the system is an arbitrary sinusoidal input.

Consider the block diagram of the system $H$ above, with the loop broken at the output.
Inject a signal $\delta_{\text{in}}$ into $H$ and see what happens when it goes through the blocks and comes out of the output $y$ and call this signal $\delta_{\text{out}}$.
Notice that the output signal is
\begin{equation*}
  \delta_{\text{out}}=-L\delta_{\text{in}}
\end{equation*}

Again keeping in mind that the input and output are both sinusoidal signals, and if we consider sweeping across all frequencies with our input signal $\delta_{\text{in}}$, the output will be a sine wave of the same frequency that has been phase shifted and scaled by some magnitude.
When is $L$ bad? What must $L$ do to the input to be bad?

Consider the case where we find the frequency such that $L$ has a phase shift of $180^{\circ}$.
This is equivalent to flipping the sine wave, or multiplying it by a negative.
When this happens the magnitude of $L$ then must be less than unity, otherwise the output will be the same phase as the input, but larger? Is this true?

What is the explanation for why $|L(s)|$ can be larger than unity when its phase is $-180^{\circ}$? Finish this explanation.

In any case, looking at the denominator, we know that $L(s)=-1$ is bad.
So, we sweep across all input frequencies and look at when $|L(\omega)|=1$, we then want to know, at this value of $\omega$, how far is the phase from being $-180^{\circ}$? This is called the phase margin.

For gain margin, sweep across all the frequencies $\omega$ and find the one such that $\angle L(\omega)=-180^{\circ}$.
Then, for this value of $\omega$, determine how far the magnitude of $L$ is from being unity.
This is gain margin.

\subsection{Time Delay Margin}

$s=\sigma+j\omega$
Considering sinusoidal inputs only, that is $s=j\omega$
Considering a Bode plot of a transfer function $G(s)$, the phase margin is
Consider an input $u(t)$ and output $y(t)$.
The input and output of the system can be represented as an exponential.
That is consider the input

\begin{equation*}
  u(t)=e^{st}
\end{equation*}
The output will be of a similar form, of which we are trying to find the specifics when there is a delay between the input and output

\begin{equation*}
  y(t)=u(t-\tau)
\end{equation*}
and the input with this delay is

\begin{equation*}
  u(t-\tau)=e^{s(t-\tau)}=e^{st}e^{-s\tau}
\end{equation*}
and we can write

\begin{equation*}
  y(t)=e^{st}e^{-s\tau}
\end{equation*}
which is

\begin{equation*}
  y(t)=u(t)e^{-s\tau}
\end{equation*}
and so we can see given an output that is delayed by $\tau$ from the input is represented by $e^{-s\tau}$.
Taking a transfer function with delay

\begin{equation*}
  \frac{Y(s)}{U(s)}=G(s)e^{-s\tau}
\end{equation*}
Now we want to know when this system is placed in feedback, how large would the delay have to get before the closed-loop system becomes unstable? A delay does not affect the magnitude of the system, only the phase.
Look at the transfer function $G(s)$ when its magnitude is 1.
Then we want to know what the relationship of the delay to phase is, where we are looking for how much phase shift can occur before $G(s)$ with the delay hits $-1$.
Evaluating $G$ with the delay at the frequency where its magnitude is 1.

\begin{equation*}
  G(j\omega_{cg})e^{-j\omega_{cg}\tau}=-1
\end{equation*}
\begin{equation*}
  \angle(G(j\omega_{cg})e^{-j\omega_{cg}\tau})=-180^{\circ}
\end{equation*}
The magnitude of $G$ is 1 and the magnitude of the delay is $1$, so now we just need to check when the combined phase of the two is $-180^{\circ}$.

\begin{equation*}
  \angle(G(j\omega_{cg})e^{-j\omega_{cg}\tau})=\angle G(j\omega_{cg})+\angle e^{-j\omega_{cg}\tau}=-180^{\circ}
\end{equation*}
and the angle of the delay is

\begin{equation*}
  \angle e^{-j\omega_{cg}\tau}=-\omega_{cg}\tau
\end{equation*}
\begin{equation*}
  \angle G(j\omega_{cg})-\omega_{cg}\tau=-180^{\circ}
\end{equation*}
Recalling the definition of phase margin

\begin{equation*}
  \text{PM}=180^{\circ}+\angle G(j\omega_{cg})
\end{equation*}
we get

\begin{equation*}
  PM=\omega_{cg}\tau
\end{equation*}
and solving for the delay $\tau$ we get

\begin{empheq}[box=\roomyfbox]{equation*}
  \tau=\frac{PM}{\omega_{cg}}
\end{empheq}

% TODO@dpwiese - what does $G(s)$ need to satisfy for stability?
% TODO@dpwiese - Magnitude less than 1 OK always, regardless of phase?

Magnitude more than 1 OK only when phase is $\pm180^{\circ}$
The maximum tolerable time delay is one which causes the transfer function $\frac{Y(s)}{U(s)}$ to become $-1$,

\subsection{Introduction}

%feedback systems Astrom and Murray pg 136.
%define
%\begin{equation*}
%\dot{x}(t)\triangleq\frac{dx(t)}{dt}
%\end{equation*}
Consider the following linear, time varying, autonomous state space equation where $A(t) \in \mathbb{R}^{n\times n}$ and $x(t) \in \mathbb{R}^{n\times1}$.

\begin{equation*}
  \dot{x}(t)=A(t)x(t)
\end{equation*}
We want to gain insight into solution of this matrix equation by first considering the time invariant scalar equation

\begin{equation*}
  \dot{x}(t)=x(t)
\end{equation*}
Proposing a solution of the following form:

\begin{equation*}
  x(t)=1+t+\frac{t^{2}}{2!}+\frac{t^{3}}{3!}+\dots
\end{equation*}
differentiating

\begin{equation*}
  \dot{x}(t)=0+1+t+\frac{t^{2}}{2!}+\dots
\end{equation*}
and notice that the function $x(t)$ is in fact the derivative of itself, and satisfies the given equation.
Define this function $x(t)=e^{t}$, which is described by the following sum, to be the exponential function, noting that $0!=1$.

\begin{equation*}
  e^{t}=\sum\limits_{n=0}^{\infty}\frac{t^{n}}{n!}=
  1+t+\frac{t^{2}}{2!}+\frac{t^{3}}{3!}+\dots
\end{equation*}
(See Rudin pg 63 for definition of $e$) Extending this function definition to the scalar first order differential equation

\begin{equation*}
  \dot{x}(t)=ax(t)
\end{equation*}
where $a \in \mathbb{R}$.
We are looking for a function $x(t)$ which, when differentiated, results in $x(t)$ being multiplied my $a$.
We propose a solution $x(t)=e^{at}$ by replacing each $t$ in the above definition by $at$.
That is

\begin{equation*}
  x(t)=e^{at}=1+at+\frac{(at)^{2}}{2!}+\frac{(at)^{3}}{3!}+\dots
\end{equation*}
which, when differentiated gives

\begin{equation*}
  \begin{split}
    \dot{x}(t)&=0+a+a^{2}t+\frac{a^{3}t^{2}}{2!}\dots \\
    &=a\left(1+at+\frac{a^{2}t^{2}}{2!}\dots \right) \\
    &=ae^{at} \\
    &=ax(t)
  \end{split}
\end{equation*}
which solves the given differential equation.
In general

\begin{equation*}
  x(t)=e^{at}c
\end{equation*}
is a solution, where $c=x(0)$

\begin{equation*}
  x(t)=e^{at}x(0)
\end{equation*}
Or more generally for $t_{0}\neq0$ the solution to the differential equation $\dot{x}(t)=ax(t)$ is given by

\begin{equation*}
  x(t)=e^{a(t-t_{0})}x(t_{0})
\end{equation*}

\subsection{Matrix Exponential}

Similarly, if the following solution is proposed for the matrix differential equation
\begin{equation*}
  x(t)=I+At+\frac{(At)^{2}}{2!}+\frac{(At)^{3}}{3!}+\dots
\end{equation*}
it can be differentiated in the same way as the scalar case, thus defining the function known as the \textit{matrix exponential}.
\begin{empheq}[box=\roomyfbox]{equation*}
  e^{At}\triangleq{}I+At+\frac{(At)^{2}}{2!}+\frac{(At)^{3}}{3!}+\dots
\end{empheq}
giving the following solution to the matrix differential equation $\dot{x}(t)=Ax(t)$
%\begin{equation*}
%x(t)=e^{At}x(0)
%\end{equation*}
\begin{equation*}
  x(t-t_{0})=e^{A(t-t_{0})}x(t_{0})
\end{equation*}
The quantity given by evaluating the matrix exponential is known as the \textit{state transition matrix}:
\begin{equation*}
  x(t-t_{0})=\Phi(t,t_{0})x(t_{0})
\end{equation*}
which is sometimes written $\Phi(t-t_{0})$ as well.
The state transition matrix may be time varying, or time invariant, depending on the system from which it resulted.
The following examples will help show different way in which the state transition matrix can be found by evaluating the matrix exponential.

\subsubsection{Diagonal $A$ Matrix}

\begin{equation*}
  e^{\Lambda t}=
  \left[
    \begin{array}{cccc}
      e^{\lambda_{1}t} & 0 & \cdots & 0 \\
      0 & e^{\lambda_{2}t} & \cdots & 0 \\
      \vdots & \vdots & \ddots & \vdots \\
      0 & 0 & \cdots & e^{\lambda_{n}t}
    \end{array}
  \right]
\end{equation*}

\subsubsection{Finding the State Transition Matrix}

\begin{example}[Using the definition \textemdash{} Time Invariant]
  For the system $\dot{x}(t)=Ax(t)$ with $A$ given below, the matrix exponential can be evaluated using the series definition.

  \begin{equation*}
    A=
    \left[
      \begin{array}{cc}
        0 & 1 \\
        0 & 0 \\
      \end{array}
    \right]
  \end{equation*}
  \begin{equation*}
    e^{A(t-t_{0})}=
    \left[
      \begin{array}{cc}
      1 & 0 \\
      0 & 1 \\
      \end{array}
    \right]+
    \left[
      \begin{array}{cc}
      0 & 1 \\
      0 & 0 \\
      \end{array}
    \right](t-t_{0})+\frac{1}{2!}
    \left[
      \begin{array}{cc}
      0 & 1 \\
      0 & 0 \\
      \end{array}
    \right]^{2}(t-t_{0})^{2}+\ldots
  \end{equation*}
  but
  \begin{equation*}
  A^{n}=
    \left[
      \begin{array}{cc}
      0 & 0 \\
      0 & 0 \\
      \end{array}
    \right] \text{for } n\in\mathbb{N}\geq2
  \end{equation*}
  giving
  \begin{equation*}
    e^{A(t-t_{0})}=
    \left[
    \begin{array}{cc}
      1 & 0 \\
      0 & 1 \\
    \end{array}
    \right]+
    \left[
    \begin{array}{cc}
      0 & 1 \\
      0 & 0 \\
    \end{array}
    \right](t-t_{0})=
    \left[
    \begin{array}{cc}
      1 & (t-t_{0}) \\
      0 & 1 \\
    \end{array}
    \right]
  \end{equation*}
  So the state transition matrix is given by:
  \begin{equation*}
    \Phi(t,t_{0})=
    \left[
      \begin{array}{cc}
      1 & (t-t_{0}) \\
      0 & 1 \\
      \end{array}
    \right]
  \end{equation*}
  and the solution to the state space equation is:
  \begin{equation*}
    x(t)=
    \left[
      \begin{array}{cc}
      1 & (t-t_{0}) \\
      0 & 1 \\
      \end{array}
    \right]x(t_{0})
  \end{equation*}
\end{example}

\begin{example}[Using Inverse Laplace Transform \textemdash{} Time Invariant]
  For the system $\dot{x}(t)=Ax(t)$ with $A$ given below, the matrix exponential can be evaluated using inverse Laplace transforms.

  \begin{equation*}
    A=
    \left[
      \begin{array}{cc}
        0 & 1 \\
        0 & 0 \\
      \end{array}
    \right]
  \end{equation*}
  \begin{equation*}
    x(t)=\mathscr{L}^{-1}((sI-A)^{-1})x(t_{0})
  \end{equation*}
  where

  \begin{equation*}
    \Phi(t,t_{0})=\mathscr{L}^{-1}((sI-A)^{-1})
  \end{equation*}
  \begin{equation*}
    (sI-A)=
    \left[
      \begin{array}{cc}
        s & -1 \\
        0 & s \\
      \end{array}
    \right]
  \end{equation*}
  Using the formula to invert a $2\times2$ matrix:

  \begin{equation*}
    (sI-A)^{-1}=\frac{1}{\det(sI-A)}
    \left[
      \begin{array}{cc}
        s & 1 \\
        0 & s \\
      \end{array}
    \right]=
    \left[
      \begin{array}{cc}
        \frac{1}{s} & \frac{1}{s^{2}} \\
        0 & \frac{1}{s} \\
      \end{array}
    \right]
  \end{equation*}
  Taking the inverse Laplace transform:

  \begin{equation*}
    \mathscr{L}^{-1}
    \left(\left[
      \begin{array}{cc}
        \frac{1}{s} & \frac{1}{s^{2}} \\
        0 & \frac{1}{s} \\
      \end{array}
    \right]\right)=
    \left[
      \begin{array}{cc}
        1 & (t-t_{0}) \\
        0 & 1 \\
      \end{array}
    \right]
  \end{equation*}
  So the state transition matrix is given by:

  \begin{equation*}
    \Phi(t,t_{0})=
    \left[
      \begin{array}{cc}
        1 & (t-t_{0}) \\
        0 & 1 \\
      \end{array}
    \right]
  \end{equation*}
  which matches the answer we got in the first example by using the series definition.
\end{example}

\begin{example}[Using the definition \textemdash{} Time Invariant]
  The last example showed how the series definition could be used to find the state transition matrix for a simple linear time invariant system.
  This example was made particularly easy because the series terminated after the first two terms.
  In this example, the entire series will have to be considered, and recognized as a series representation of a commonly known trigonometric function.
  For the system $\dot{x}(t)=Ax(t)$ $A$ is given by:

  \begin{equation*}
    A=
    \left[
      \begin{array}{cc}
        0 & 1 \\
        -a^{2} & 0 \\
      \end{array}
    \right]
  \end{equation*}
  Evaluating the first terms in the series definition of the matrix exponential:

  \begin{equation*}
    \begin{split}
      A^{2}=
      \left[
        \begin{array}{cc}
          0 & 1 \\
          -a^{2} & 0 \\
        \end{array}
      \right]
      \left[
        \begin{array}{cc}
          0 & 1 \\
          -a^{2} & 0 \\
        \end{array}
      \right]&=
      \left[
        \begin{array}{cc}
          -a^{2} &0 \\
          0 & -a^{2} \\
        \end{array}
      \right] \\
      A^{3}=A^{2}A=
      \left[
        \begin{array}{cc}
          -a^{2} &0 \\
          0 & -a^{2} \\
        \end{array}
      \right]
      \left[
        \begin{array}{cc}
          0 & 1 \\
          -a^{2} & 0 \\
        \end{array}
      \right]&=
      \left[
        \begin{array}{cc}
          0 & -a^{2} \\
          a^{4} & 0 \\
        \end{array}
      \right] \\
      A^{4}=A^{3}A=
      \left[
        \begin{array}{cc}
          0 & -a^{2} \\
          a^{4} & 0 \\
        \end{array}
      \right]
      \left[
        \begin{array}{cc}
          0 & 1 \\
          -a^{2} & 0 \\
        \end{array}
      \right]&=
      \left[
        \begin{array}{cc}
          a^{4} & 0 \\
          0 & a^{4} \\
        \end{array}
      \right] \\
      A^{5}=A^{4}A=
      \left[
        \begin{array}{cc}
          a^{4} & 0 \\
          0 & a^{4} \\
        \end{array}
      \right]
      \left[
        \begin{array}{cc}
          0 & 1 \\
          -a^{2} & 0 \\
        \end{array}
      \right]&=
      \left[
        \begin{array}{cc}
          0 & a^{4} \\
          -a^{6} & 0 \\
        \end{array}
      \right] \\
    \end{split}
  \end{equation*}
  Assembling these components using the series definition of the matrix exponential, the state transition matrix becomes

  \begin{equation*}
    \Phi(t,t_{0})=
    \left[
      \begin{array}{cc}
        1-a^{2}\frac{t^{2}}{2!}+a^{4}\frac{t^{4}}{4!}-\cdots& t-\cdots\\
        -a^{2}t+\cdots& 1-\cdots \\
      \end{array}
    \right]
  \end{equation*}
  Recognizing the series in the entries of the state transition matrix, it can be simplified to:

  \begin{equation*}
    \Phi(t,t_{0})=
    \left[
      \begin{array}{cc}
        xxx & xxx \\
        xxx & xxx \\
      \end{array}
    \right]
  \end{equation*}
  and the solution to the state space equation is:

  \begin{equation*}
    x(t)=
    \left[
      \begin{array}{cc}
        xxx & xxx \\
        xxx & xxx \\
      \end{array}
    \right]x(t_{0})
  \end{equation*}
  See Hogan's notes \textit{Unforced\_LTI\_Response.pdf}
\end{example}

\begin{example}[Directly from $A$ Matrix \textemdash{} Time Varying]
  6.241 notes Wed.\ 2/29

  \begin{equation*}
    A=
    \left[
      \begin{array}{cc}
        0 & t \\
        0 & 0 \\
      \end{array}
    \right]
  \end{equation*}

  \begin{equation*}
    \begin{split}
      \dot{x}_{1}(t)&=tx_{2}(t) \\
      \dot{x}_{2}(t)&=0 \\
    \end{split}
  \end{equation*}

  \begin{equation*}
  \begin{split}
      \dot{x}_{1}(t)&=tx_{2}(t_{0}) \\
      \dot{x}_{2}(t)&=0 \\
    \end{split}
  \end{equation*}
\end{example}

\begin{example}[Using Inverse Laplace Transform \textemdash{} Time Varying]
  6.241 HW 3.4.
  Find an expression for $\Phi(t_{2},t_{0})$ for the system $\dot{x}(t)=A(t)x(t)$ given

  \begin{equation*}
    A=
    \begin{bmatrix}
      0 & 1 \\ -k & 0
    \end{bmatrix}
  \end{equation*}
  when

  \begin{equation*}
    \begin{cases}
      k=0 & \text{for } t<0\\
      k=1 & \text{for } t\geq0
    \end{cases}
  \end{equation*}
   for $t_{0}<0$ to $t_{2}>0$.
  Since the matrix $A(t)$ is time varying and described for two different cases of $k$, only on state transition matrix $\Phi$ will not be able to be used.
  Two state transition matrices are needed.

  \begin{equation*}
    \Phi(t_{2},t_{0})=\Phi(t_{2},t_{1})\Phi(t_{1},t_{0})
  \end{equation*}
  The first one will go from $t=t_{0}<0$ to $t=t_{1}=0$, and is given by:

  \begin{equation*}
    \begin{split}
      \Phi(t_{1},t_{0})
      &=\exp\left(
        \begin{bmatrix}
          0 & 1 \\ 0 & 0
        \end{bmatrix}(t_{1}-t_{0})
        \right) \\
        &=\exp\left(
        \begin{bmatrix}
          0 & 1 \\ 0 & 0
        \end{bmatrix}(-t_{0})
      \right)
    \end{split}
  \end{equation*}
  Using the series definition of the matrix exponential, the state transition matrix is calculated.
  The series definition can be used because the series terminates after the first two terms.
  That is all powers of $A$ greater than 1 are zero.

  \begin{equation*}
    \begin{split}
      \exp\left(
        \begin{bmatrix}
          0 & 1 \\ 0 & 0
        \end{bmatrix}(-t_{0})
      \right)&=
      \left[
        \begin{array}{cc}
          1 & 0 \\
          0 & 1 \\
        \end{array}
      \right]+
      \left[
        \begin{array}{cc}
          0 & 1 \\
          0 & 0 \\
        \end{array}
      \right](-t_{0})+\frac{1}{2!}
      \left[
        \begin{array}{cc}
          0 & 1 \\
          0 & 0 \\
        \end{array}
      \right]^{2}(-t_{0})^{2}+\ldots\\
      &=
      \begin{bmatrix}
        1 & -t_{0} \\ 0 & 1
      \end{bmatrix}+
      \begin{bmatrix}
        0 & 0 \\ 0 & 0
      \end{bmatrix} + \ldots\\
      \Phi(t_{1},t_{0})&=
      \begin{bmatrix}
        1 & -t_{0} \\ 0 & 1 \\
      \end{bmatrix}
    \end{split}
  \end{equation*}
  Now, the second state transition matrix $\Phi(t_{2},t_{1})$ must be calculated from $t=t_{1}=0$ to $t=t_{2}>0$:

  \begin{equation*}
    \begin{split}
      \Phi(t_{2},t_{1})
      &=\exp\left(
      \begin{bmatrix}
        0 & 1 \\ -1 & 0
      \end{bmatrix}(t_{2}-t_{1})
      \right) \\
      &=\exp\left(
      \begin{bmatrix}
        0 & 1 \\ -1 & 0
      \end{bmatrix}(t_{2})
      \right)
    \end{split}
  \end{equation*}
  The series definition can not be used to evaluate the state transition matrix in this case, since it does not terminate after two terms like it did before.
  Another way to evaluate the state transition matrix is the following:

  \begin{equation*}
    x(t_{2})=\mathscr{L}^{-1}((sI-A)^{-1})x(t_{1})
  \end{equation*}
  where

  \begin{equation*}
    \begin{split}
      \Phi(t_{2},t_{1})&=\mathscr{L}^{-1}((sI-A)^{-1}) \\
      &=\mathscr{L}^{-1}
      \left(
        \left(sI-
          \begin{bmatrix}
            0 & 1 \\ -1 & 0
          \end{bmatrix}
        \right)^{-1}
      \right) \\
      &=\mathscr{L}^{-1}
      \left(
        \left(
          \begin{bmatrix}
          s & -1 \\ 1 & s
          \end{bmatrix}
        \right)^{-1}
      \right) \\
    \end{split}
  \end{equation*}
  Using the formula for the inverse of a $2\times2$ matrix:

  \begin{equation*}
    (sI-A)^{-1}=
    \begin{bmatrix}
      s & -1 \\ 1 & s
    \end{bmatrix}^{-1}=\frac{1}{\det(sI-A)}
    \begin{bmatrix}
      s & 1 \\ -1 & s
    \end{bmatrix}=\frac{1}{s^2+1}
    \begin{bmatrix}
      s & 1 \\ -1 & s
    \end{bmatrix}=
    \begin{bmatrix}
      \frac{s}{s^2+1} & \frac{1}{s^2+1} \\ \frac{-1}{s^2+1} & \frac{s}{s^2+1}
    \end{bmatrix}
  \end{equation*}
  Now, taking the inverse Laplace transform of $(sI-A)^{-1}$ (which only depends on $t_{2}$ and not $t_{1}$) using a Laplace transform table, by hand:

  \begin{equation*}
    \mathscr{L}^{-1}
    \begin{bmatrix}
      \frac{s}{s^2+1} & \frac{1}{s^2+1} \\ \frac{-1}{s^2+1} & \frac{s}{s^2+1}
    \end{bmatrix}=
    \begin{bmatrix}
      \cos(t_{2}) & \sin(t_{2}) \\ -\sin(t_{2}) & \cos(t_{2})
    \end{bmatrix}
  \end{equation*}
  Combining the two state transition matrices:

  \begin{equation*}
    \begin{split}
      \Phi(t_{2},t_{0})
      &=\Phi(t_{2},t_{1})\Phi(t_{1},t_{0})=
      \begin{bmatrix}
        \cos(t_{2}) & \sin(t_{2}) \\ -\sin(t_{2}) & \cos(t_{2})
      \end{bmatrix}
      \begin{bmatrix}
        1 & -t_{0} \\ 0 & 1 \\
      \end{bmatrix} \\
      &=
      \begin{bmatrix}
        \cos(t_{2}) & \sin(t_{2})-t_{0}\cos(t) \\ -\sin(t_{2}) & \cos(t_{2})+t_{0}\sin(t_{2})
      \end{bmatrix}
    \end{split}
  \end{equation*}
  Several other state transition matrices $\Phi(t_{2},t_{0})$ would exist for different conditions of $t_{2}$ and $t_{0}$.
  For instance, if $t_{2}$ and $t_{0}$ were both greater than zero, the state transition matrix would only be calculated for $k=1$ giving:

  \begin{equation*}
    \Phi(t_{2},t_{0})=
    \begin{bmatrix}
      1 & t_{2}-t_{0} \\ 0 & 1 \\
    \end{bmatrix}
  \end{equation*}
\end{example}

\subsection{Non-Autonomous Systems}

In order to find the state of a state space model at time $t_{1}$ based on initial conditions at $t_{0}$ and in input $u(t)$, the methods of the state transition matrix can still be used, although they must be extended to include the input.

\begin{equation*}
  x(t_{1})=\Phi(t_{1},t_{0})x(t_{0})+\int_{t_{0}}^{t_{1}}\Phi(t_{1},\tau)B(\tau)u(\tau)d\tau
\end{equation*}

% TODO@dpwiese - Redo this problem - there are errors.
\begin{example}[Non-Autonomous System \textemdash{} Time Varying QR10B from 6.241 midterm review]
  Given the following differential equation, find $y(2\pi)$.
  The initial conditions are $y(0)=1$ and $\dot{y}(0)=1$.
  The input $u(t)=1$ for all time.
  \begin{equation*}
    \ddot{y}(t)+k(t)y(t)=u(t) \quad \text{where} k(t)=
    \begin{cases}
      1 & \text{for } \sin(t)>0\\
      0 & \text{for } \sin(t)\leq0
    \end{cases}
  \end{equation*}
  Putting this information into the differential equation, and based on the final time at which we are asked to calculate $y$, this problem can be broken into two parts, and solved separately using the formula above.
  That is, with $t_{0}=0$ and $t_{1}=\pi$, we will first find the value of $y(t_{1})$ and $\dot{y}(t_{1})$.
  Over this time interval $k(t)=1$ is a constant, and the problem can be solved as a time invariant one.
  Once the values of $y$ and $\dot{y}$ are had at $t_{1}$, the problem will be repeated with $t_{2}=2\pi$.

  The given differential equation will be rewritten for the first interval over which it will be solved, and the corresponding state space model for this system must be found.
  \begin{equation*}
    \ddot{y}+y=1
  \end{equation*}
  Define the following state vector $x(t)$:
  \begin{equation*}
    x(t)=\begin{bmatrix} y(t) \\ \dot{y}(t) \end{bmatrix}
  \end{equation*}
  with the state vector derivative
  \begin{equation*}
    \dot{x}(t)=\begin{bmatrix} \dot{y}(t) \\ \ddot{y}(t) \end{bmatrix}
  \end{equation*}
  Using this state vector, the system equation can be expressed using the following state space model
  \begin{equation*}
    \begin{bmatrix}
      \dot{y}(t) \\ \ddot{y}(t)
    \end{bmatrix}=
    \begin{bmatrix}
      0 & 1 \\ -1 & 0
    \end{bmatrix}
    \begin{bmatrix}
      y(t) \\ \dot{y}(t)
    \end{bmatrix}+
    \begin{bmatrix}
      0 \\ 1
    \end{bmatrix}
  \end{equation*}
  From this state space model, the state transition matrix $\Phi(t_{1},t_{0})$ must be found.
  \begin{equation*}
    \Phi(t_{1},t_{0})=\exp
    \left(
      \begin{bmatrix}
        0 & 1 \\ -1 & 0
      \end{bmatrix}(t_{1}-t_{0})
    \right)
  \end{equation*}
  This state transition matrix may be more difficult to evaluate using the series definition of the matrix exponential, so the inverse Laplace transform method will be used:
  \begin{equation*}
    \begin{split}
      \Phi(t_{1},t_{0})&=\mathscr{L}^{-1}((sI-A)^{-1}) \\
      &=\mathscr{L}^{-1}
      \left(
        \left(sI-
          \begin{bmatrix}
            0 & 1 \\ -1 & 0
          \end{bmatrix}
        \right)^{-1}
      \right) \\
      &=\mathscr{L}^{-1}
      \left(
        \left(
          \begin{bmatrix}
          s & -1 \\ 1 & s
          \end{bmatrix}
        \right)^{-1}
      \right) \\
      &=\mathscr{L}^{-1}
      \left(
        \frac{1}{s^{2}+1}
        \left(
          \begin{bmatrix}
            s & 1 \\ -1 & s
          \end{bmatrix}
        \right)
      \right) \\
      &=\mathscr{L}^{-1}
      \left(
        \begin{bmatrix}
          \frac{s}{s^{2}+1} & \frac{1}{s^{2}+1} \\ \frac{-1}{s^{2}+1} & \frac{s}{s^{2}+1}
        \end{bmatrix}
      \right) \\
    \end{split}
  \end{equation*}
  Using a Laplace transform table, or by evaluating the inverse Laplace transforms by hand:
  \begin{equation*}
    \Phi(t_{1},t_{0})=
    \begin{bmatrix}
      \cos(t_{1}-t_{0}) & \sin(t_{1}-t_{0}) \\ -\sin(t_{1}-t_{0}) & \cos(t_{1}-t_{0})
    \end{bmatrix}
  \end{equation*}
  With the initial conditions plugged into the state vector:
  \begin{equation*}
    x(t_{0})=x(0)=\begin{bmatrix} 1 \\ 1 \end{bmatrix}
  \end{equation*}
  All of the components to use the equation are had.
  Plugging them in:
  \begin{equation*}
    \begin{split}
      x(\pi)&=
      \begin{bmatrix}
        \cos(\pi) & \sin(\pi) \\ -\sin(\pi) & \cos(\pi)
      \end{bmatrix}
      \begin{bmatrix}
        1 \\ 1
      \end{bmatrix}+
      \int_{0}^{\pi}
      \begin{bmatrix}
        \cos(\pi-\tau) & \sin(\pi-\tau) \\ -\sin(\pi-\tau) & \cos(\pi-\tau)
      \end{bmatrix}
      \begin{bmatrix}
        0 \\ 1
      \end{bmatrix}
      d\tau \\
      &=
      \begin{bmatrix}
        -1 & 0 \\ 0 & -1
      \end{bmatrix}
      \begin{bmatrix}
        1 \\ 1
      \end{bmatrix}+
      \int_{0}^{\pi}
      \begin{bmatrix}
        \sin(\pi-\tau) \\ \cos(\pi-\tau)
      \end{bmatrix}
      d\tau \\
      &=
      \begin{bmatrix}
        -1 \\ -1
      \end{bmatrix}+
      \begin{bmatrix}
        \cos(\pi-\tau) \\ \sin(\pi-\tau)
      \end{bmatrix} \Biggr|_{0}^{\pi} \\
      &=
      \begin{bmatrix}
        -1 \\ -1
      \end{bmatrix}+
      \begin{bmatrix}
        \cos(0)-\cos(\pi) \\ \sin(0)-\sin(\pi)
      \end{bmatrix} \\
      &=
      \begin{bmatrix}
        -1 \\ -1
      \end{bmatrix}+
      \begin{bmatrix}
        2 \\ 0
      \end{bmatrix} \\
      &=
      \begin{bmatrix}
        1 \\ -1
      \end{bmatrix}
    \end{split}
  \end{equation*}
  This procedure must now be repeated for the second time interval, from $t_{1}=\pi$ to $t_{2}=2\pi$, using the following state space model
  \begin{equation*}
    \begin{bmatrix}
      \dot{y}(t) \\ \ddot{y}(t)
    \end{bmatrix}=
    \begin{bmatrix}
      0 & 1 \\ 0 & 0
    \end{bmatrix}
    \begin{bmatrix}
      y(t) \\ \dot{y}(t)
    \end{bmatrix}+
    \begin{bmatrix}
      0 \\ 1
    \end{bmatrix}
  \end{equation*}
  with the ``initial'' conditions:
  \begin{equation*}
    x(t_{1})=x(\pi)=\begin{bmatrix} 1 \\ -1 \end{bmatrix}
  \end{equation*}
  Again, using the inverse Laplace transform method to find the state transition matrix $\Phi(t_{2},t_{1})$:
  \begin{equation*}
    \begin{split}
      \Phi(t_{2},t_{1})&=\mathscr{L}^{-1}((sI-A)^{-1}) \\
      &=\mathscr{L}^{-1}\left(
      \left(sI-\begin{bmatrix}
      0 & 1 \\ 0 & 0
      \end{bmatrix}\right)^{-1}
      \right) \\
      &=\mathscr{L}^{-1}\left(
      \left(\begin{bmatrix}
      s & -1 \\ 0 & s
      \end{bmatrix}\right)^{-1}
      \right) \\
      &=\mathscr{L}^{-1}\left(\frac{1}{s^{2}}
      \left(\begin{bmatrix}
      s & 1 \\ 0 & s
      \end{bmatrix}\right)
      \right) \\
      &=\mathscr{L}^{-1}
      \left(\begin{bmatrix}
      \frac{1}{s} & \frac{1}{s^{2}} \\ 0 & \frac{1}{s}
      \end{bmatrix}\right) \\
    \end{split}
  \end{equation*}
  Using a Laplace transform table, or by evaluating the inverse Laplace transforms by hand:
  \begin{equation*}
    \Phi(t_{2},t_{1})=
    \begin{bmatrix}
      1 & t_{2}-t_{1} \\ 0 & 1
    \end{bmatrix}
  \end{equation*}
  \begin{equation*}
    x(t_{1})=x(\pi)=\begin{bmatrix} 1 \\ -1 \end{bmatrix}
  \end{equation*}
  All of the components to use the equation are had.
  Plugging them in:
  \begin{equation*}
    \begin{split}
      x(2\pi)&=
      \begin{bmatrix}
        1 & \pi \\ 0 & 1
      \end{bmatrix}
      \begin{bmatrix}
        1 \\ -1
      \end{bmatrix}+
      \int_{0}^{\pi}
      \begin{bmatrix}
        1 & 2\pi-\tau \\ 0 & 1
      \end{bmatrix}
      \begin{bmatrix}
        0 \\ 1
      \end{bmatrix}
      d\tau \\
      &=
      \begin{bmatrix}
        1 & \pi \\ 0 & 1
      \end{bmatrix}
      \begin{bmatrix}
        1 \\ -1
      \end{bmatrix}+
      \int_{0}^{\pi}
      \begin{bmatrix}
        2\pi-\tau \\ 1
      \end{bmatrix}
      d\tau \\
      &=
      \begin{bmatrix}
        1-\pi \\ -1
      \end{bmatrix}+
      \begin{bmatrix}
        2\pi\tau-\frac{1}{2}\tau^{2} \\ \tau
      \end{bmatrix} \Biggr|_{0}^{\pi} \\
      &=
      \begin{bmatrix}
        1-\pi \\ -1
      \end{bmatrix}+
      \begin{bmatrix}
        \frac{3}{2}\pi^{2} \\ \pi
      \end{bmatrix} \\
      &=
      \begin{bmatrix}
        1-\pi \\ -1
      \end{bmatrix}+
      \begin{bmatrix}
        \frac{3}{2}\pi^{2} \\ \pi
      \end{bmatrix} \\
      &=
      \begin{bmatrix}
        \frac{3}{2}\pi^{2}-\pi+1 \\ \pi-1
      \end{bmatrix}
    \end{split}
  \end{equation*}
\end{example}

% \section{garbage}
% Separable first order ODE
% \begin{equation*}
%   dx(t)=ax(t)dt
% \end{equation*}
% integrate both sides
% \begin{equation*}
%   \int_{x(t_{0})}^{x(T)}\frac{dx(t)}{x(t)}=\int_{t_{0}}^{T}adt
% \end{equation*}

% \begin{equation*}
%   \ln{(x(t))+c_{1}}\Bigr|_{x(t_{0})}^{x(T)}=at+c_{2}\Bigr|_{t_{0}}^{T}
% \end{equation*}

%   \begin{equation*}
% \ln{(x(T))}-\ln{(x(t_{0}))}=a(T-t_{0})
% \end{equation*}
% exponentiating both sides with $\exp(C-D)=\frac{\exp(C)}{\exp(D)}$

% \begin{equation*}
%   \frac{x(T)}{x(t_{0})}=\exp(a(T-t_{0}))
% \end{equation*}
% so the solution is
% \begin{equation*}
%   x(T)=e^{a(T-t_{0})}x(t_{0})
% \end{equation*}

% \begin{itemize}
%   \item{Reachability always implies controllability}
%   \item{Easiest way to determine rank of a matrix???}
%   \item{Does it mean anything if eigenvalues are not unique? Can the matrix still be diagonalized? The matrix can still be diagonalized in the trivial case where $A=0$\ldots
%   what about other examples? Yes, a matrix $A\neq0$ may have repeated eigenvalues and still be diagonalizable}
%   \item{Distinct eigenvalues gives independent eigenvectors}
% \end{itemize}

\section{Controllability, Reachability, and Observability}

\subsection{Introduction}

The concepts of controllability, reachability, and observability will be explained, as well as the weaker conditions of stabilizability and detectability.
The differences between these terms will be explained for continuous and discrete time.
In a broad sense, the concept of controllability is the ability to command a system to do what we want it to do through the action of a control input.
The concept of observability is the ability to see what is going on inside a dynamical system given the sensor outputs.
To better illustrate these concepts, eigenvalue decomposition will be used, and is explained next.

\subsection{Eigenvalue Decomposition}

Eigenvalue decomposition is the representation of a matrix $A$ in terms of its eigenvalues and eigenvectors.
Only diagonalizable matrices can be factored this way, and the result is a diagonal matrix with the eigenvalues of $A$ along the diagonal.

The matrix $A$ is diagonalizable if and only if $A$ has $n$ linearly independent eigenvectors.
 To check whether $A$ is diagonalizable, first find its characteristic equation $\delta_{A}=\det(\lambda I-A)=|\lambda I-A|=0$.
From the characteristic equation, all of the eigenvalues $\lambda_{i}$ can be found.
Then find the eigenvectors by plugging in each of the eigenvalues into $(\lambda_{i} I-A)v_{i}=0$ and solving for all of the eigenvectors $v_{i}$.
Once all of the eigenvectors are obtained, their linear independence can be checked by combining them into an eigenvector matrix $V$.
If the determinant of this matrix is nonzero, the eigenvectors are linearly independent and the matrix $A$ can be diagonalized.
The diagonalizability of $A$ can also be verified by attempting to do so through row operations, although if it is verified this way that $A$ is diagonalizable, the eigenvalues and eigenvectors will have to be found anyway.

The eigenvalue problem, or eigenvalue equation can be stated as follows, and is the basis for finding the eigenvalues and eigenvectors of $A$.
\begin{equation*}
  Av_{i}=v_{i}\lambda_{i}
\end{equation*}
Assembling these $n$ linearly independent eigenvectors in a matrix $V$, and the eigenvalues along the diagonals of a matrix $\Lambda$, the eigenvalue equation can be written in matrix form.
\begin{equation*}
  AV=
  \left[
    \begin{array}{cccc}
      Av_{1} & Av_{2} & \cdots & Av_{n}
    \end{array}
  \right]
\end{equation*}
\begin{equation*}
  V\Lambda=
  \left[
    \begin{array}{cccc}
      v_{1}\lambda_{1} & v_{2}\lambda_{2} & \cdots & v_{n}\lambda_{n}
    \end{array}
  \right]
\end{equation*}
\begin{equation*}
  AV=V\Lambda
\end{equation*}
Since $V$ is composed of the $n$ linearly independent eigenvectors, it has full rank, and is thus invertible, allowing the following to be written:
\begin{equation*}
  A=V\Lambda V^{-1}
\end{equation*}
\begin{equation*}
  \Lambda=V^{-1}AV
\end{equation*}
This is the process of diagonalizing a matrix $A$ using its eigenvalues and eigenvectors.

Given the system $\dot{x}=Ax+Bu$ with state vector $x$, a linear transformation $z=Mx$ can be proposed, so long as $M$ is full rank.
The requirement of $M$ to have full rank has to do with the necessity of all information in $x$ to be preserved under the transformation.
Since $M$ has full rank, it is invertible, and the state vector $x$ can be written
\begin{equation*}
  x=M^{-1}z
\end{equation*}
with derivative
\begin{equation*}
  \dot{x}=M^{-1}\dot{z}
\end{equation*}
substituting the transformed state into the system equation
\begin{equation*}
  M^{-1}\dot{z}=AM^{-1}z+Bu
\end{equation*}
\begin{equation*}
  \dot{z}=MAM^{-1}z+MBu
\end{equation*}
looking at this representation, and recalling that we can select $M$ to be any matrix with full rank, we select $M=V$.
The system can then be simplified and represented as follows
\begin{equation*}
  \dot{z}=\Lambda z+VBu
\end{equation*}
This shows that given a state space model $\dot{x}=Ax+Bu$, the system can be rewritten using a new state $z$ where the matrix $A$ has been transformed into a diagonal matrix $\Lambda$ with the eigenvalues of $A$ along the diagonal.

The following examples will help show the process of finding the eigenvalues and eigenvectors, checking the diagonalizability of $A$, and then finding the representation $\dot{z}=\Lambda z+VBu$ when possible.

\begin{example}[Eigenvalue decomposition with distinct eigenvalues] Given the matrix $A$ below, we would like to determine if it can be decomposed using its eigenvalues and eigenvectors.
\begin{equation*}
  A=
  \left[
    \begin{array}{cc}
      1 & 2 \\ 2 & 4
    \end{array}
  \right]
\end{equation*}
Find the characteristic equation $\delta_{A}=\det(\lambda I-A)=0$ of $A$.
First, setting up the matrix $\lambda I-A$:
\begin{equation*}
  \lambda I-A=
  \left[
    \begin{array}{cc}
      \lambda-1 & -2 \\ -2 & \lambda-4
    \end{array}
  \right]
\end{equation*}
taking the determinant
\begin{equation*}
  \begin{split}
    (\lambda-1)(\lambda-4)-4&=0 \\
    \lambda^{2}-5\lambda&=0 \\
    \lambda(\lambda-5)&=0 \\
  \end{split}
\end{equation*}
giving the following eigenvalues
\begin{equation*}
  \begin{split}
    \lambda_{1}&=0 \\
    \lambda_{2}&=5
  \end{split}
\end{equation*}
both eigenvalues are distinct, so we expect that the corresponding eigenvectors be linearly independent.
Finding the corresponding eigenvectors
\begin{equation*}
  (\lambda_{i} I-A)v_{i}=0
\end{equation*}
\begin{equation*}
  \left[
    \begin{array}{cc}
      \lambda_{i}-1 & -2 \\ -2 & \lambda_{i}-4
    \end{array}
  \right]
  \left[
    \begin{array}{c}
      v_{i,1} \\ v_{i,2}
    \end{array}
  \right]=
  \left[
    \begin{array}{c}
      0 \\ 0
    \end{array}
  \right]
\end{equation*}
For $\lambda_{1}=0$
\begin{equation*}
  \left[
    \begin{array}{cc}
      -1 & -2 \\ -2 & -4
    \end{array}
  \right]
  \left[
    \begin{array}{c}
    v_{1,1} \\ v_{1,2}
    \end{array}
  \right]=
  \left[
    \begin{array}{c}
      0 \\ 0
    \end{array}
  \right]
  \quad v_{1}=
  \left[
    \begin{array}{c}
      -2a \\ a
    \end{array}
  \right]
\end{equation*}
For $\lambda_{2}=5$
\begin{equation*}
  \left[
    \begin{array}{cc}
      4 & -2 \\ -2 & 1
    \end{array}
  \right]
  \left[
    \begin{array}{c}
      v_{2,1} \\ v_{2,2}
    \end{array}
  \right]=
  \left[
    \begin{array}{c}
      0 \\ 0
    \end{array}
  \right]
  \quad v_{2}=
  \left[
    \begin{array}{c}
      a \\ 2a
    \end{array}
  \right]
\end{equation*}
It is verified that the two eigenvectors are in fact linearly independent, as we expected.
Eigenvectors are not true vectors\ldots
they are like a set of vectors\ldots
So any choice for the eigenvectors will work.
Choosing $a=1$ gives the following eigenvectors, which are arranged in the eigenvector matrix $V$.
\begin{equation*}
  v_{1}=
  \left[
    \begin{array}{c}
      -2 \\ 1
    \end{array}
  \right]
  \quad
  v_{2}=
  \left[
    \begin{array}{c}
      1 \\ 2
    \end{array}
  \right]
  \quad
  V=
  \left[
    \begin{array}{cc}
      -2 & 1 \\ 1 & 2
    \end{array}
  \right]
\end{equation*}
Since the matrix $A$ is diagonalizable, and we all of the eigenvalues and eigenvectors of $A$, we can write the following:
\begin{equation*}
  \left[
    \begin{array}{cc}
    0 & 0 \\ 0 & 5
    \end{array}
  \right]
  =
  \left[
    \begin{array}{cc}
    -2 & 1 \\ 1 & 2
    \end{array}
  \right]^{-1}
  \left[
    \begin{array}{cc}
    1 & 2 \\ 2 & 4
    \end{array}
  \right]
  \left[
    \begin{array}{cc}
    -2 & 1 \\ 1 & 2
    \end{array}
  \right]
\end{equation*}
The significance of this will become clearer with further examples.
\end{example}

\begin{example}[Eigenvalue decomposition with repeated eigenvalues]
  Given the matrix $A$ below, we would like to determine if it can be decomposed using its eigenvalues and eigenvectors.
  \begin{equation*}
    A=
    \left[
      \begin{array}{ccc}
        1 & 0 & 1 \\ 0 & 1 & 0 \\ 0 & 0 & 2
      \end{array}
    \right]
  \end{equation*}
  This matrix has repeated eigenvalues, but is diagonalizable.
\end{example}

\begin{example}[Eigenvalue decomposition with repeated eigenvalues]
  Given the matrix $A$ below, we would like to determine if it can be decomposed using its eigenvalues and eigenvectors.
  \begin{equation*}
    A=
    \left[
      \begin{array}{cc}
        1 & 1 \\ 0 & 1
      \end{array}
    \right]
  \end{equation*}
  Find the characteristic equation $\delta_{A}=\det(\lambda I-A)=0$ of $A$.
  First, setting up the matrix $\lambda I-A$:
  \begin{equation*}
    \lambda I-A=
    \left[
      \begin{array}{cc}
        \lambda-1 & -1 \\ 0 & \lambda-1
      \end{array}
    \right]
  \end{equation*}
  taking the determinant
  \begin{equation*}
    \begin{split}
      (1-\lambda)(1-\lambda)&=0 \\
      (\lambda-1)^{2}&=0
    \end{split}
  \end{equation*}
  giving the following eigenvalues
  \begin{equation*}
    \begin{split}
      \lambda_{1}&=1 \\
      \lambda_{2}&=1
    \end{split}
  \end{equation*}
  With repeated eigenvalues there is no guarantee that the eigenvectors will be linearly independent.
  Finding the corresponding eigenvectors
  \begin{equation*}
    (\lambda_{i} I-A)v_{i}=0
  \end{equation*}
  \begin{equation*}
    \left[
      \begin{array}{cc}
        \lambda_{i}-1 & -1 \\ 0 & \lambda_{i}-1
      \end{array}
    \right]
    \left[
      \begin{array}{c}
        v_{i,1} \\ v_{i,2}
      \end{array}
    \right]
    =
    \left[
    \begin{array}{c}
      0 \\ 0
    \end{array}
    \right]
  \end{equation*}
  For $\lambda_{1}=\lambda_{2}=1$
  \begin{equation*}
    \left[
      \begin{array}{cc}
        0 & -1 \\ 0 & 0
      \end{array}
    \right]
    \left[
      \begin{array}{c}
        v_{1,1} \\ v_{1,2}
      \end{array}
    \right]
    =
    \left[
      \begin{array}{c}
        0 \\ 0
      \end{array}
    \right]
    \quad v_{1}=
    \left[
      \begin{array}{c}
        a \\ 0
      \end{array}
    \right]
  \end{equation*}
  There is only one linearly independent eigenvector of $A$, so $A$ is not diagonalizable.
\end{example}

\subsection{Controllability, Reachability, and Stabilizability}

Controllability and reachability are two concepts with relate to the ability to command a system to do what we want it to do through the action of a control input.
In continuous time (CT) systems, these terms have the same meaning, given by the following definition:

\begin{defn-dan}[Controllability (CT)]
  A continuous time system is controllable if for all initial states $x_{0}$ all states $x$, and some time $t_{1}$ which is greater than $t_{0}$, there exists a control input which will take the state $x$ from $x(t_{0})=x_{0}$ to $x(t_{1})=x_{1}$.
  \begin{equation*}
    \forall x_{0},x \in \mathbb{R}^{n} \forall T>t_{0} \exists u(t)\bigr|_{t_{0} \leq t \leq T}^{}:x(t):x(t_{0})=x_{0}, x(t_{1})=x_{1}
  \end{equation*}
\end{defn-dan}

For discrete time systems, controllability and reachability are different, as given by the following definitions\ (Kalman 1961).

\begin{defn-dan}[Controllability (DT)]
  A discrete time system is controllable if there exists a control input which will take the state to the origin in finite time.
\end{defn-dan}

\begin{defn-dan}[Reachability (DT)]
  A discrete time system is reachable if there exists a control input which will take the state from any initial state to any final state in finite time.
\end{defn-dan}

\subsection{Controllability versus Reachability}

The need for the two different, but similar definitions for the discrete time case is explained here\dots Examples:
\begin{equation*}
  x(t+1)=
  \left[
    \begin{array}{cc}
      0 & 0 \\ 0 & 1
    \end{array}
  \right]
  x(t)+
  \left[
    \begin{array}{c}
      0  \\  1
    \end{array}
  \right]
  u(t)
\end{equation*}

\begin{equation*}
  \dot{x}(t)=
  \left[
    \begin{array}{cc}
      0 & 0 \\ 0 & 1
    \end{array}
  \right]
  x(t)+
  \left[
    \begin{array}{c}
      0 \\ 1
    \end{array}
  \right]
  u(t)
\end{equation*}

\textit{Include example of DT system which is controllable but not reachable}

\subsection{Applying the Concept of Controllability}

Now that the definitions for controllability and reachability have been presented and explained, we will focus our attention only on CT systems.
The process of determining if a system is controllable will be explained, and some examples using eigenvalue decomposition will be used to make the concept of controllability clear.To investigate the controllability of a system, the controllability matrix must be found.
This matrix will serve as the basis for controllability calculations
\begin{itemize}
  \item{Explain how to derive the controllability matrix}
\end{itemize}

\begin{equation*}
  M_{c}=
  \left[
    \begin{array}{ccccc}
      B & AB & A^{2}B & \cdots & A^{n-1}B
    \end{array}
  \right]
\end{equation*}

In order for a system to be controllable, the controllability matrix must have full rank.
For a system system with a single input this corresponds to the column vectors $B$, $AB$, $A^{2}B \dots$ being linearly independent.
That is to say the square controllability matrix $M_{c}$ must be non-singular; its determinant must be non-zero.
The following examples show the process of determining the controllability for CT systems.

\begin{example}
  A controllable system $\dot{x}=Ax+Bu$
  \begin{equation*}
    A=\left[
      \begin{array}{cc}
        -1 & 0 \\
        1 & 1
      \end{array}
    \right]
    \quad B=
    \left[
      \begin{array}{c}
        2 \\
        1
      \end{array}
    \right]
  \end{equation*}
  Calculate the controllability matrix $M_{c}$:
  \begin{equation*}
    M_{c}=
    \left[
      \begin{array}{cc}
        B & AB
      \end{array}
    \right]
    =
    \left[
      \begin{array}{cc}
        2 & -2 \\
        1 & 3
      \end{array}
    \right]
  \end{equation*}
  The controllability matrix has full rank of 2, so the system is controllable.
\end{example}

\begin{example}
  An uncontrollable system $\dot{x}=Ax+Bu$
  \begin{equation*}
    A=
    \left[
      \begin{array}{cc}
        -1 & 0 \\
        -1 & 1
      \end{array}
    \right]
    \quad B=
    \left[
      \begin{array}{c}
        2 \\
        1
      \end{array}
    \right]
  \end{equation*}
  Calculate the controllability matrix $M_{c}$:
  \begin{equation*}
    M_{c}=
    \left[
      \begin{array}{cc}
        B & AB
      \end{array}
    \right]
    =
    \left[
      \begin{array}{cc}
        2 & -2 \\
        1 & -1
      \end{array}
    \right]
  \end{equation*}
  The controllability matrix has rank 1, so the system is not controllable.
\end{example}

Determining the controllability of a system by checking the rank of the controllability matrix is procedural operation which results in only a \textit{yes} or \textit{no} answer to the question: \textit{is this system controllable?} However, if a system is uncontrollable, this does not mean we must pack up and go home.
We would like to gain some more insight into systems which are not controllable to better understand what is going on.

When we say that a CT system is uncontrollable, this does not mean that we have zero influence over the output of the system, but rather that not every state vector in the state space can be achieved.
The range of the controllability matrix $M_{c}$ (the span of the columns of $M_{c}$) gives the possible state vectors that can be achieved by the system by application of control.
For a square matrix $M_{c}$, if its columns are linearly independent, it will span $\mathbb{R}^{n}$, and any state vector in the state space $\mathbb{R}^{n}$ can be achieved.
The state vectors that are achievable by application of control are called controllable \textbf{primal states}.
We call a state vector a primal state to differentiate it from individual state elements or components of the state vector.

If $M_{c}$ does not have full rank, then there are primal states in the state space which are not spanned by the columns of $M_{c}$.

So, we know that for a system that is not controllable, there may be some primal states which are controllable, and some that are not.
The uncontrollable states are best described in terms of uncontrollable \textbf{dual states}.
The concept of dual states may be best explained by first providing some examples.

\begin{example}
  Revisited: A controllable system Consider again the system $\dot{x}=Ax+Bu$ with the following $A$ and $B$ matrices.
  \begin{equation*}
    A=
    \left[
      \begin{array}{cc}
      -1 & 0 \\
      1 & 1
      \end{array}
    \right]
    \quad B=
    \left[
      \begin{array}{c}
        2 \\
        1
      \end{array}
    \right]
  \end{equation*}
  The controllability matrix was found before to have full rank, meaning the system is controllable.
  Based on the definition of controllability for CT systems, we know it is possible to to command the state vector $x$ to any desired value.
  To better see this we will represent this system using the transformed state $z=Vx$.
  This results in the system
  \begin{equation*}
    \dot{z}=\Lambda z+VBu
  \end{equation*}
  where $\Lambda$ is given by
  \begin{equation*}
    \Lambda=V^{-1}AV
  \end{equation*}
  Finding $V$ and $\Lambda$: Find the characteristic equation $\delta_{A}=\det(\lambda I-A)=0$ of $A$.
  First, setting up the matrix $\lambda I-A$:
  \begin{equation*}
    \lambda I-A=
    \left[
      \begin{array}{cc}
        \lambda+1 & 0 \\
        -1 & \lambda-1
      \end{array}
    \right]
  \end{equation*}
  taking the determinant
  \begin{equation*}
    (\lambda-1)(\lambda+1)=0
  \end{equation*}
  giving the following eigenvalues
  \begin{equation*}
    \begin{split}
      \lambda_{1}&=1 \\
      \lambda_{2}&=-1
    \end{split}
  \end{equation*}
  both eigenvalues are distinct, so we expect that the corresponding eigenvectors be linearly independent.
  Finding the corresponding eigenvectors
  \begin{equation*}
    (\lambda_{i} I-A)v_{i}=0
  \end{equation*}
  \begin{equation*}
    \left[
      \begin{array}{cc}
        \lambda_{i}+1 & 0 \\
        -1 & \lambda_{i}-1
      \end{array}
    \right]
    \left[
      \begin{array}{c}
        v_{i,1} \\
        v_{i,2}
      \end{array}
    \right]
    =
    \left[
      \begin{array}{c}
        0 \\
        0
      \end{array}
    \right]
  \end{equation*}
  For $\lambda_{1}=1$
  \begin{equation*}
    \left[
      \begin{array}{cc}
        2 & 0 \\
        -1 & 0
      \end{array}
    \right]
    \left[
      \begin{array}{c}
        v_{1,1} \\
        v_{1,2}
      \end{array}
    \right]=
    \left[
      \begin{array}{c}
        0 \\
        0
      \end{array}
    \right]
    \quad v_{1}=
    \left[
      \begin{array}{c}
        0 \\
        a
      \end{array}
    \right]
  \end{equation*}
  For $\lambda_{2}=-1$
  \begin{equation*}
    \left[
      \begin{array}{cc}
        0 & 0 \\
        -1 & -2
      \end{array}
    \right]
    \left[
      \begin{array}{c}
        v_{2,1} \\
        v_{2,2}
      \end{array}
    \right]
    =
    \left[
      \begin{array}{c}
        0 \\
        0
      \end{array}
    \right]
    \quad v_{2}=
    \left[
      \begin{array}{c}
        -2a \\
        a
      \end{array}
    \right]
  \end{equation*}
  using $a=1$
  \begin{equation*}
    V=
    \left[
      \begin{array}{cc}
        0 & -2 \\
        1 & 1
      \end{array}
    \right]
  \end{equation*}
  allowing the system to be written
  \begin{equation*}
    \dot{z}=
    \left[
      \begin{array}{cc}
        1 & 0 \\
        0 & -1
      \end{array}
    \right]
    z+
    \left[
      \begin{array}{cc}
        0 & -2 \\
        1 & 1
      \end{array}
    \right]
    \left[
      \begin{array}{c}
        2 \\
        1
      \end{array}
    \right]
    u
  \end{equation*}
  simplifying
  \begin{equation*}
    \dot{z}=
    \left[
      \begin{array}{cc}
        1 & 0 \\
        0 & -1
      \end{array}
    \right]
    z+
    \left[
      \begin{array}{c}
        -2 \\
        3
      \end{array}
    \right]
    u
  \end{equation*}
  From this representation using the new state vector $z$, it may now be more clear that since $z_{1}$ and $z_{2}$ are decoupled, and the control effort can effect both state variables, thus allowing any state to be reached through application of a specific control input.
\end{example}

\begin{itemize}
  \item{How to find unreachable primal states? Is that even a thing?}
  \item{Explain what dual states are}
  \item{Do controllable dual states mean anything?}
  \item{Explain controllability of a system (fully controllable system) versus controllability of a mode}
\end{itemize}

\begin{example}
  Revisited: An uncontrollable system $\dot{x}=Ax+Bu$
  \begin{equation*}
    A=
    \left[
      \begin{array}{cc}
        -1 & 0 \\
        -1 & 1
      \end{array}
    \right]
    \quad B=
    \left[
      \begin{array}{c}
        2 \\
        1
      \end{array}
    \right]
  \end{equation*}
  The controllability matrix $M_{c}$ was calculated and found to be rank deficient (it did not have full rank) and thus the system is not controllable.
  What else can we find out about this uncontrollable system?
\end{example}

\subsection{How Controllable?}

condition number of controllability matrix

\subsection{Observability and Detectability}

\begin{equation*}
M_{o}=
\left[
  \begin{array}{c}
    C \\ CA \\ CA^{2} \\ \vdots \\ CA^{n-1}
  \end{array}
\right]
\end{equation*}

\subsection{Reachable Primal States, Uncontrollable Dual States}

Given a state-space model, be able to find the set of all reachable primal states, and uncontrollable dual states.
\begin{equation*}
  A=
  \begin{bmatrix}
    0 & 1 & 0 \\
    0 & 0 & 1\\
    a & 2 & 0
  \end{bmatrix}
  \quad B=
  \begin{bmatrix}
    0 \\
    1 \\
    1
  \end{bmatrix}
  \quad C=
  \begin{bmatrix}
    0 & 1 & 1
  \end{bmatrix}
  \quad D=
  \begin{bmatrix}
    0
  \end{bmatrix}
\end{equation*}

\begin{itemize}
  \item{Reachable primal states are given by the span of the columns of the controllability matrix $M_{c}$}
\end{itemize}

Computing the controllability matrix:
\begin{equation*}
  M_{c}=
  \begin{bmatrix}
    B & AB & A^{2}B
  \end{bmatrix}=
  \begin{bmatrix}
    0 & 1 & 1 \\
    1 & 1 & 2 \\
    1 & 2 & a+2
  \end{bmatrix}
\end{equation*}

\paragraph{Reachable Primal States} For this square $3\times3$ matrix, if it has full rank, its columns would span $\mathbb{R}^{3}$ and the entire states-space, i.e.\ $\mathbb{R}^{3}$ would be a reachable primal state.
Because it is square, we can take the determinant.
When the determinant is zero, the controllability matrix loses rank, and then its columns would not span $\mathbb{R}^{3}$.
\begin{equation*}
  \det(M_{c})=-a+1
\end{equation*}
So the controllability matrix is full rank for $a\neq1$, and it loses rank when $a=1$.
With full rank, the reachable primal states are anything in $\mathbb{R}^{3}$.
This can be written:
\begin{equation*}
  \boxed{%
    \text{for $a\neq1$ the reachable primal state is: }x=c_{1}
    \begin{bmatrix}
      1 \\
      0 \\
      0
    \end{bmatrix}+c_{2}
    \begin{bmatrix}
      0 \\
      1 \\
      0
    \end{bmatrix}+c_{3}
    \begin{bmatrix}
      0 \\
      0 \\
      1
    \end{bmatrix}
    \quad \text{for}\;c_{1},\;c_{2},\;c_{3}\;\in\;\mathbb{R}
  }
\end{equation*}

When $a=1$ and the controllability matrix loses rank, we need to still find the set of reachable primal states.
That is, with $a=1$, what is the span of the columns of $M_{c}$? In the case when $a=1$, $M_{c}$ becomes:
\begin{equation*}
  M_{c}=
  \begin{bmatrix}
    0 & 1 & 1 \\
    1 & 1 & 2 \\
    1 & 2 & 3
  \end{bmatrix}
\end{equation*}
By inspection, or through a series of row reductions, it is seen that only two of the columns are linearly independent.
Thus, the reachable primal states when $a=1$ are given by a linear combination of any two of the columns of $M_{c}$.
That is:
\begin{equation*}
  \boxed{%
    \text{for $a=1$ the reachable primal state is: }x=c_{1}
    \begin{bmatrix}
      0 \\
      1 \\
      1
    \end{bmatrix}+c_{2}
    \begin{bmatrix}
      1 \\
      1 \\
      2
    \end{bmatrix}
    \quad \text{for}\;c_{1},\;c_{2}\;\in\;\mathbb{R}
  }
\end{equation*}

\paragraph{Uncontrollable Dual States}
Uncontrollable states are a linear combination of each of the entries of the state vector $x$.
That is, an uncontrollable state $z_{i}$ is given by:
\begin{equation*}
  z_{i}=Px \quad \text{where $P$ is a row vector}
\end{equation*}
The row vector $P$ is such that:
\begin{equation*}
  PM_{c}=0 \quad\text{or, alternatively}\quad {M_{c}}^{\text{T}}P^{\text{T}}=0
\end{equation*}
Using the second expression this gives:
\begin{equation*}
\begin{bmatrix}
    0 & 1 & 1 \\
    1 & 1 & 2 \\
    1 & 2 & a+2
  \end{bmatrix}
  \begin{bmatrix}
    p_{1} \\
    p_{2} \\
    p_{3}
  \end{bmatrix}=
  \begin{bmatrix}
    0 \\
    0 \\
    0
  \end{bmatrix}
\end{equation*}
When $a\neq1$, $P=\begin{bmatrix} 0 & 0 & 0 \end{bmatrix}$.
The answer would be given as:

``when $a\neq1$ the uncontrollable dual state is given by: $z=Px$, with $P$ defined by: $P=\begin{bmatrix} 0 & 0 & 0 \end{bmatrix}$.''

When $a=1$, the following system would have to be solved for $p_{1}$, $p_{2}$, and $p_{3}$.
\begin{equation*}
  \begin{bmatrix}
    0 & 1 & 1 \\
    1 & 1 & 2 \\
    1 & 2 & 3
  \end{bmatrix}
  \begin{bmatrix}
    p_{1} \\
    p_{2} \\
    p_{3}
  \end{bmatrix}=
  \begin{bmatrix}
    0 \\
    0 \\
    0
  \end{bmatrix}
\end{equation*}

\begin{equation*}
  p_{2}=-p_{3}
\end{equation*}

\begin{equation*}
  p_{1}+p_{2}+2p_{3}=0\quad\rightarrow\quad p_{1}+p_{3}=0\quad\rightarrow\quad p_{1}=-p_{3}
\end{equation*}

\begin{equation*}
  p_{1}+2p_{2}+3p_{3}=0\quad\rightarrow\quad -p_{3}-2p_{3}+3p_{3}=0\quad\rightarrow\quad 0p_{3}=0
\end{equation*}
So, when $a=1$, $p_{3}$ can be selected arbitrarily, and then $p_{1}=-p_{3}$ and $p_{2}=-p_{3}$.
The answer would be given as:

``when $a=1$ the uncontrollable dual state is given by: $z=Px$, with $P$ defined by: $P=k\begin{bmatrix} -1 & -1 & 1 \end{bmatrix}$ for $k\;\in\;\mathbb{R}$.''

\paragraph{Reachability of System} A system is reachable if the entire state-space is reachable.
That is, the only uncontrollable dual state is $z=0$.

\subsection{Observable Dual States, Unobservable Primal States}
\paragraph{Unobservable Primal States} Unobservable primal states given by the nullspace of $M_{o}$, which is: $M_{o}x=0$.
\begin{equation*}
  M_{o}=
  \begin{bmatrix}
    C \\
    CA \\
    CA^{2}
  \end{bmatrix}=
  \begin{bmatrix}
    0 & 1 & 1 \\
    a & 2 & 1 \\
    a & a+2 & 2
  \end{bmatrix}
\end{equation*}
Take the determinant of $M_{o}$:
\begin{equation*}
  \det(M_{o})=a(a-1)
\end{equation*}
The observability matrix loses rank when $a\in\{0,1\}$.
\begin{itemize}
  \item{When the observability matrix $M_{o}$ has full rank, the system has no unobservable primal states.}
  \item{When $M_{o}$ loses rank, there will be some unobservable primal states}
\end{itemize}
To find the unobservable primal states, plug in each value of $a$ which make $M_{o}$ lose rank, and solve $M_{o}x=0$.
For $a=0$:
\begin{equation*}
  \begin{bmatrix}
    0 & 1 & 1 \\
    0 & 2 & 1 \\
    0 & 2 & 2
  \end{bmatrix}
  \begin{bmatrix}
    x_{1} \\
    x_{2} \\
    x_{3}
  \end{bmatrix}=
  \begin{bmatrix}
    0 \\
    0 \\
    0
  \end{bmatrix}
\end{equation*}
By inspection, $x_{1}$ can be made anything, and $x_{2}=x_{3}=0$.
\begin{equation*}
  \boxed{%
    \text{for $a=0$ the unobservable primal state is: }x=k
    \begin{bmatrix}
      1 \\
      0 \\
      0
    \end{bmatrix}
    \quad\text{for $k\in\mathbb{R}$}
  }
\end{equation*}
For $a=1$:
\begin{equation*}
  \begin{bmatrix}
    0 & 1 & 1 \\
    1 & 2 & 1 \\
    1 & 3 & 2
  \end{bmatrix}
  \begin{bmatrix}
    x_{1} \\
    x_{2} \\
    x_{3}
  \end{bmatrix}=
  \begin{bmatrix}
    0 \\
    0 \\
    0
  \end{bmatrix}
\end{equation*}
Solving:
\begin{equation*}
  x_{2}=-x_{3}
\end{equation*}
\begin{equation*}
  x_{1}+2x_{2}+x_{3}=0\quad\rightarrow\quad x_{1}-x_{3}=0\quad\rightarrow\quad x_{1}=x_{3}
\end{equation*}
\begin{equation*}
  x_{1}+3x_{2}+2x_{3}=0\quad\rightarrow\quad x_{3}-3x_{3}+2x_{3}=0\quad\rightarrow\quad 0x_{3}=0
\end{equation*}
$x_{3}$ can be selected arbitrarily, with $x_{1}=x_{3}$, and $x_{2}=-x_{3}$.
This gives the following unobservable primal state:
\begin{equation*}
  \boxed{%
    \text{for $a=1$ the unobservable primal state is: }x=k
    \begin{bmatrix}
      1 \\
      -1 \\
      1
    \end{bmatrix}
    \quad\text{for $k\in\mathbb{R}$}
  }
\end{equation*}

\paragraph{Observable Dual States}
\begin{itemize}
  \item{Observable dual states are given by linear combinations of $Cx$, $CAx$, $CA^{2}x$ and so forth.}
\end{itemize}
To find the observable dual states expressed as $z=Px$ where $P$ is a row, transpose the observability matrix and take the linearly independent columns.
In the example above, when $a\notin\{0,1\}$ the observability matrix has full rank, and all of its rows and columns are linearly independent.
Thus, when it is transposed, the span of these linearly independent columns can be expressed as:
\begin{equation*}
  \boxed{%
    \text{Observable dual state for $a\notin\{0,1\}$:}\quad
    x=c_{1}
    \begin{bmatrix}
      1 & 0 & 0
    \end{bmatrix}+
    c_{2}
    \begin{bmatrix}
      0 & 1 & 0
    \end{bmatrix}+
    c_{3}
    \begin{bmatrix}
      0 & 0 & 1
    \end{bmatrix}
  }
\end{equation*}
For $a\in\{0,1\}$ the observability loses rank, and the observable dual states are found by taking the linearly independent columns of ${M_{o}}^{\text{T}}$.
For $a=0$:
\begin{equation*}
  {M_{o}}^{\text{T}}=
  \begin{bmatrix}
    0 & 0 & 0 \\
    1 & 2 & 2 \\
    1 & 1 & 2
  \end{bmatrix}
\end{equation*}
and only two of the columns are linearly independent, giving:
\begin{equation*}
  \boxed{%
    \text{Observable dual state for $a=0$:}\quad
    x=c_{1}
    \begin{bmatrix}
      0 & 1 & 1
    \end{bmatrix}+
    c_{2}
    \begin{bmatrix}
      0 & 2 & 1
    \end{bmatrix}
  }
\end{equation*}
For $a=1$:
\begin{equation*}
  {M_{o}}^{\text{T}}=
  \begin{bmatrix}
    0 & 1 & 1 \\
    1 & 2 & 3 \\
    1 & 1 & 2
  \end{bmatrix}
\end{equation*}
and only two of the columns are linearly independent, giving:
\begin{equation*}
  \boxed{%
    \text{Observable dual state for $a=1$:}\quad
    x=c_{1}
    \begin{bmatrix}
    0 & 1 & 1
    \end{bmatrix}+
    c_{2}
    \begin{bmatrix}
    1 & 2 & 1
    \end{bmatrix}
  }
\end{equation*}

\section{More Linear System Stuff}

\subsection{Zeros}

Rosenbrock matrix
\begin{equation*}
  R(s)=
  \begin{bmatrix}
    sI-A & B \\
    -C & D
  \end{bmatrix}
\end{equation*}

Let's take $D=0$ for now

\begin{equation*}
  R(s_{0})=
  \begin{bmatrix}
    s_{0}I-A & B \\
    -C & 0
  \end{bmatrix}
  \begin{bmatrix}
    x_{0} \\
    u_{0}
  \end{bmatrix}
  =
  \begin{bmatrix}
    0 \\
    0
  \end{bmatrix}
\end{equation*}

$s_{0}$ is a transmission zero if $R$ loses rank and so there is a nonzero vector $v_{0}=[\;x_{0}^{\top}\;u_{0}^{\top}\;]^{\top}$ such that $Rv_{0}=0$.

\subsubsection{Zeros Introduced by Postcompensator}

The zeros are $s_{0}$ and $v_{0}$ such that $(s_{0})v_{0}=0$.
So if we post compensate the output as

\begin{equation*}
  R_{s}(s_{0})=
  \begin{bmatrix}
    s_{0}I-A & B \\
    -S_{1}C & 0
  \end{bmatrix}
  \begin{bmatrix}
    x_{0} \\
    u_{0}
  \end{bmatrix}
  =
  \begin{bmatrix}
    0 \\
    0
  \end{bmatrix}
\end{equation*}

Then all of the zeros of $R$ are also zeros of $R_{s}$, and there might be additional zeros.
We can see by looking at

\begin{equation*}
  C=
  \begin{bmatrix}
    C_{1} \\
    C_{2} \\
    C_{3}
  \end{bmatrix}
\end{equation*}
and we know that $C_{1}x_{0}=C_{2}x_{0}=C_{3}x_{0}=0$.
But if we square down using
\begin{equation*}
  S_{1}=
  \begin{bmatrix}
    S_{11} & S_{12} & S_{13}
  \end{bmatrix}
\end{equation*}

\begin{equation*}
  S_{1}C=[S_{11}C_{1}+S_{12}C_{2}+S_{13}C_{3}]
\end{equation*}

and

\begin{equation*}
  [S_{11}C_{1}+S_{12}C_{2}+S_{13}C_{3}]x_{0}=0
\end{equation*}

\begin{equation*}
  S_{11}C_{1}x_{0}+S_{12}C_{2}x_{0}+S_{13}C_{3}x_{0}=0
\end{equation*}

so there can be additional zeros.

\chapter{Robust Control}

\section{\texorpdfstring{$H_{2}$}{H2} Optimization Using Completion of Squares}

General state-space form of plant for which the optimal controller $K(s)$ will be designed:
\begin{empheq}[box=\roomyfbox]{alignat*=1}
  \dot{x}&=Ax+B_{1}w+B_{2}u \\
  e&=C_{1}x+D_{11}w+D_{12}u \\
  y&=C_{2}x+D_{21}w
\end{empheq}

The optimization setup has control singularity when either of the following matrices are not left invertible for all $\omega\;\in\;[0,\infty]$ and for $D_{12}$ at $\omega=\infty$.
\begin{equation*}
  E_{c}(s)=
  \begin{bmatrix}
    A-j\omega I & B_{2} \\
    C_{1} & D_{12}
  \end{bmatrix}
  \quad \text{and} \quad
  D_{12}
\end{equation*}
The optimization setup has sensor singularity when either of the following matrices are not right invertible all $\omega\;\in\;[0,\infty]$ and for $D_{21}$ at $\omega=\infty$.
\begin{equation*}
  E_{m}(s)=
  \begin{bmatrix}
    A-j\omega I & B_{1} \\
    C_{2} & D_{21}
  \end{bmatrix}
  \quad \text{and} \quad
  D_{21}
\end{equation*}
A matrix $A$ is right invertible if there is a matrix $B$ such that $AB=I$.
A matrix $A$ is left invertible if there is a matrix $B$ such that $BA=I$.
For a square matrix $A$, left and right invertibility are the same, and is just regular invertibility.
\begin{equation*}
  {A_{\text{right}}}^{-1}=A^{\text{T}}(AA^{\text{T}})^{-1}
\end{equation*}
\begin{equation*}
  {A_{\text{left}}}^{-1}=(A^{\text{T}}A)^{-1}A^{\text{T}}
\end{equation*}
Finding the optimal controller $K(s)$ with the general form:
\begin{align*}
  \dot{x}_{e}&=(A+LC_{2}+B_{2}F)x_{e}-Ly \\
  u&=Fx_{e}
\end{align*}
General form of completion of squares used to find the optimal control and observer gains $F$ and $L$, respectively, where the vertical bar brackets mean 2-norm:
\begin{equation*}
  |C_{1}x+D_{12}u|^{2}+2x'P_{c}(Ax+B_{2}u)=|D_{12}(u-Fx)|^{2}
\end{equation*}
\begin{equation*}
  |{B_{1}}'\psi+{D_{21}}'\xi|^{2}+2\psi P_{e}(A'\psi+{C_{2}}'\xi)=|{D_{21}}'(\xi-L'\psi)|^{2}
\end{equation*}
where $A+B_{2}F$ and $A+LC_{2}$ are Hurwitz matrices.

Once the stabilizing solutions for $P_{c}$ and $P_{e}$ and thus $F$ and $L$ are found, the corresponding minimal square of the closed loop $H_{2}$ norm is given by:
\begin{equation*}
  J_{\min}=\text{tr}({B_{1}}'P_{c}B_{1})+\text{tr}(D_{12}FP_{e}F'{D_{12}}')
\end{equation*}

Also, once the matrices $F$ and $L$ are found, a transfer function for the controller can be written by using\dots
\begin{equation*}
  K(s)=C(sI-A)^{-1}B+D
\end{equation*}

\begin{example}
  A state space plant of the general form has matrices:
  \begin{alignat*}{3}
    A&=a \quad &B_{1}=
    \begin{bmatrix}
      0 & 1
    \end{bmatrix} && \quad B_{2}&=1 \\
    C_{1}&=0 \quad &D_{11}=
    \begin{bmatrix}
      0 & 0
    \end{bmatrix} && \quad D_{12}&=1 \\
    C_{2}&=1 \quad &D_{21}=
    \begin{bmatrix}
      b & 0
    \end{bmatrix} &&
  \end{alignat*}
  Substituting these matrices into the first completion of squares equation:
  \begin{equation*}
    |u|^{2}+2x'P_{c}(ax+u)=|u-Fx|^{2}
  \end{equation*}
  Since the system is scalar, $x'=x$, and also $|n|^{2}=n^{2}$ allows this expression to be simplified to:
  \begin{equation*}
    u^{2}+2xP_{c}(ax+u)=(u-Fx)^{2}
  \end{equation*}
  \begin{equation*}
    u^{2}+2xP_{c}(ax+u)=u^{2}-2Fxu+F^{2}x^{2}
  \end{equation*}
  \begin{equation*}
    2P_{c}ax^{2}+2xP_{c}u=-2Fxu+F^{2}x^{2}
  \end{equation*}
  Equating coefficients on both sides:
  \begin{equation*}
    2P_{c}a=F^{2}
    \quad \text{and} \quad
    P_{c}=-F
  \end{equation*}
  These equations need to be combined into the Riccati equation for $P_{c}$ in terms of the plant parameters.
  This equation will have multiple solutions for $P_{c}$, and the stabilizing one that makes $A+B_{2}F$ a Hurwitz matrix should be selected.
  \begin{equation*}
    2P_{c}a={P_{c}}^{2}
  \end{equation*}
  \begin{equation*}
    P_{c}(P_{c}-2a)=0
  \end{equation*}
  \begin{equation*}
    P_{c}=0\;,\;2a
  \end{equation*}
  If $a<0$, the plant is stable, and no control is even needed to stabilize it.
  That is, the stabilizing solution is $F=0$, giving $P_{c}=0$.
  However, when $a>0$ the plant is not stable, and the stabilizing solution $F=-2a$, and $P_{c}=2a$ is used.
  In general, the larger value of $P_{c}$ should be selected as the stabilizing solution.
  \begin{empheq}[box=\roomyfbox]{alignat*=3}
    &\text{for $a<0$}\quad && F=0 \quad &&  P_{c}=0 \\
    &\text{for $a>0$}\quad && F=-2a \quad && P_{c}=2a
  \end{empheq}

  Substituting the plant matrices into the second completion of squares equation does not simplify as easily as the first equation.
  \begin{equation*}
    |{B_{1}}'\psi+{D_{21}}'\xi|^{2}+2\psi P_{e}(A'\psi+{C_{2}}'\xi)=|{D_{21}}'(\xi-L'\psi)|^{2}
  \end{equation*}
  This equation is scalar, with $\psi\in\mathbb{R}$ and $\xi\in\mathbb{R}$? Comparing the two completion of square equations and looking at dimensions, $\psi$ should have same dimensions as $x$, and $\xi$ same dimensions as $y$.
  So, for this problem $\psi$ and $\xi$ are scalars, and so are $L$ and $P_{e}$.

  I am pretty sure the absolute value sign that Magretski uses is actually the vector 2-norm, making the completion of squares actually written:
  \begin{equation*}
    {\|{B_{1}}'\psi+{D_{21}}'\xi\|_{2}}^{2}+2\psi P_{e}(A'\psi+{C_{2}}'\xi)={\|{D_{21}}'(\xi-L\psi)\|_{2}}^{2}
  \end{equation*}
  substituting values from problem:
  \begin{equation*}
    \left\|
      \begin{bmatrix}
        0 \\ 1
      \end{bmatrix}
      \psi+
      \begin{bmatrix}
        b \\ 0
      \end{bmatrix}\xi
    \right\|_{2}^{2}+
  2\psi P_{e}(a\psi+\xi)=
    \left\|
      \begin{bmatrix}
        b \\ 0
      \end{bmatrix}(\xi-L\psi)
    \right\|_{2}^{2}
  \end{equation*}
  \begin{equation*}
    \left\|
      \begin{bmatrix}
        b\xi \\
        \psi
      \end{bmatrix}
    \right\|_{2}^{2}+
    2\psi P_{e}(a\psi+\xi)=
    b^{2}(\xi-L\psi)^{2}
  \end{equation*}
  \begin{equation*}
    {\left\|\begin{bmatrix} b\xi \\ \psi \end{bmatrix}\right\|_{2}}=\sqrt{(b\xi)^{2}+\psi^{2}}
  \end{equation*}
  \begin{equation*}
    b^{2}\xi^{2}+\psi^{2}+2\psi P_{e}(a\psi+\xi)=b^{2}(\xi-L\psi)^{2}
  \end{equation*}
  \begin{equation*}
    b^{2}\xi^{2}+\psi^{2}+2aP_{e}\psi^{2}+2P_{e}\psi\xi=b^{2}(\xi-L\psi)^{2}
  \end{equation*}
  \begin{equation*}
    b^{2}\xi^{2}+\psi^{2}+2aP_{e}\psi^{2}+2P_{e}\psi\xi=b^{2}(\xi^{2}-2L\psi\xi+L^{2}\psi^{2})
  \end{equation*}
  \begin{equation*}
    b^{2}\xi^{2}+\psi^{2}+2aP_{e}\psi^{2}+2P_{e}\psi\xi=b^{2}\xi^{2}-2b^{2}L\psi\xi+b^{2}L^{2}\psi^{2}
  \end{equation*}
  \begin{equation*}
    \psi^{2}+2aP_{e}\psi^{2}+2P_{e}\psi\xi=-2b^{2}L\psi\xi+b^{2}L^{2}\psi^{2}
  \end{equation*}
  \begin{equation*}
    \psi^{2}(1+2aP_{e})+2P_{e}\psi\xi=-2b^{2}L\psi\xi+b^{2}L^{2}\psi^{2}
  \end{equation*}
  Equating coefficients on both sides:
  \begin{equation*}
    1+2aP_{e}=b^{2}L^{2} \quad \text{and} \quad 2P_{e}=-2b^{2}L
  \end{equation*}
  Again combining these equations to find an equation for $P_{e}$ with multiple solutions by first solving for $L$:
  \begin{equation*}
    L=-\frac{P_{e}}{b^{2}}
  \end{equation*}
  \begin{equation*}
    L^{2}=\frac{{P_{e}}^{2}}{b^{4}}
  \end{equation*}
  \begin{equation*}
    1+2aP_{e}=b^{2}\frac{{P_{e}}^{2}}{b^{4}}
  \end{equation*}
  \begin{equation*}
    1+2aP_{e}=\frac{{P_{e}}^{2}}{b^{2}}
  \end{equation*}
  \begin{equation*}
    {P_{e}}^{2}-2ab^{2}P_{e}-b^{2}=0
  \end{equation*}
  Solving this quadratic equation for $P_{e}$
  \begin{equation*}
    P_{e}=\frac{2ab^{2}\pm\sqrt{4a^{2}b^{4}+4b^{2}}}{2}
  \end{equation*}
  \begin{equation*}
    P_{e}=\frac{2ab^{2}\pm\sqrt{4b^{2}(a^{2}b^{2}+1)}}{2}
  \end{equation*}
  \begin{equation*}
    P_{e}=\frac{2ab^{2}\pm2b\sqrt{a^{2}b^{2}+1}}{2}
  \end{equation*}
  \begin{equation*}
    P_{e}=ab^{2}\pm b\sqrt{a^{2}b^{2}+1}
  \end{equation*}
  In general, select the larger value of $P_{e}$ to be the stabilizing solution.
  \begin{empheq}[box=\roomyfbox]{equation*}
    P_{e}=ab^{2}+b\sqrt{a^{2}b^{2}+1}
  \end{empheq}
  Solve for $L$:
  \begin{empheq}[box=\roomyfbox]{equation*}
    L=-a-\frac{\sqrt{a^{2}b^{2}+1}}{b}
  \end{empheq}
\end{example}

\subsubsection{Small Gain Theorem}
For the feedback interconnection of LTI system $P$ and $\Delta$ a memoryless system, the small gain theorem states that if the product of $L_{2}$ gains for $P$ and $\Delta$ are less than one, that the closed loop $L_{2}$ gain will satisfy the following, where the $L_{2}$ gains are denoted by $\gamma$, and the closed loop system is $G$
\begin{equation*}
  \text{if }\quad \gamma_{P}\gamma_{\Delta}<1\quad\text{then: }\quad
  \gamma_{G}\leq\frac{\gamma_{P}}{1-\gamma_{P}\gamma_{\Delta}}
\end{equation*}

\section{Q-Parameterization}
In this note Q-parameterization is used to express a given feedback control structure in terms of a different structure with feed-forward only.
The closed-loop system $G$ is to be expressed using Q-parameterization, where $e$ can be any general output.
\begin{figure}[H]
  \begin{center}
    \psfragfig[width=5.0in]{\figurepath/fb_block_v2}{%
      \psfrag{w}[bc][bc][1.0]{$w$}
      \psfrag{s}[bc][bc][1.0]{$+$}
      \psfrag{m}[bc][bc][1.0]{}
      \psfrag{y}[bc][bc][1.0]{$y$}
      \psfrag{ks}[bc][bc][1.0]{$K$}
      \psfrag{u}[bc][bc][1.0]{$u$}
      \psfrag{e}[bc][bc][1.0]{$e$}
      \psfrag{ps}[bc][bc][1.0]{$P$}
      \psfrag{q}[bc][bc][1.0]{$q$}
      \psfrag{g}[bc][bc][1.0]{$G$}
    }
    \caption{General feedback control block diagram for closed-loop system $G$\label{linear.label_fig_3}}
  \end{center}
\end{figure}

\subsection{General Form of Plant}
The plant $P$ in the block diagram is given in its general form by:
\paragraph{Continuous Time}
\begin{empheq}[box=\roomyfbox]{alignat*=1}
  \dot{x}&=Ax+B_{1}w+B_{2}u \\
  e&=C_{1}x+D_{11}w+D_{12}u \\
  y&=C_{2}x+D_{21}w
\end{empheq}
\paragraph{Discrete Time}
\begin{empheq}[box=\roomyfbox]{alignat*=1}
  x(t+1)&=Ax(t)+B_{1}w(t)+B_{2}u(t) \\
  e(t)&=C_{1}x(t)+D_{11}w(t)+D_{12}u(t) \\
  y(t)&=C_{2}x(t)+D_{21}w(t)
\end{empheq}

Q-parameterization basically lets the closed loop plant from above be expressed as the following system.
Then, from the equations for $S_{2}$ and $S_{1}$, the blocks $G_{0}$, $G_{1}$, and $G_{2}$ can be found.
\begin{figure}[H]
  \begin{center}
    \psfragfig[width=4.0in]{\figurepath/s1s2_block_v1}{%
      \psfrag{w}[bc][bc][1.0]{$w$}
      \psfrag{s2}[bc][bc][1.0]{$S_{2}$}
      \psfrag{th}[bc][bc][1.0]{$\theta$}
      \psfrag{v}[bc][bc][1.0]{$v$}
      \psfrag{dw}[bc][bc][1.0]{$\Delta$ $w$}
      \psfrag{q}[bc][bc][1.0]{$Q$}
      \psfrag{s1}[bc][bc][1.0]{$S_{1}$}
      \psfrag{e}[bc][bc][1.0]{$e$}
    }
    \caption{Feedback control block diagram}
  \end{center}
\end{figure}

\begin{figure}[H]
  \begin{center}
    \psfragfig[width=5.0in]{\figurepath/g0g1g2_block_v1}{%
      \psfrag{w}[bc][bc][1.0]{$w$}
      \psfrag{g2}[bc][bc][1.0]{$G_{2}$}
      \psfrag{g0}[bc][bc][1.0]{$G_{0}$}
      \psfrag{th}[bc][bc][1.0]{$\theta$}
      \psfrag{q}[bc][bc][1.0]{$Q$}
      \psfrag{v}[bc][bc][1.0]{$v$}
      \psfrag{g1}[bc][bc][1.0]{$G_{1}$}
      \psfrag{s}[bc][bc][1.0]{$+$}
      \psfrag{e}[bc][bc][1.0]{$e$}
    }
    \caption{Feedback control block diagram\label{label_fig_4}}
  \end{center}
\end{figure}

\begin{empheq}[left=S_{2}:\quad\empheqlbrace]{align*}
  \dot{\Delta}&=(A+LC_{2})\Delta+(B_{1}+LD_{21})w \\
  \theta&=C_{2}\Delta+D_{21}w
\end{empheq}

\begin{empheq}[left=S_{1}:\quad\empheqlbrace]{align*}
  \dot{x}&=(A+B_{2}F)x+B_{2}(v-F\Delta)+B_{1}w \\
  e&=(C_{1}+D_{12}F)x+D_{12}(v-F\Delta)+D_{11}w
\end{empheq}

\section{LQR-PI With Anti-windup}

\begin{figure}[H]
  \begin{center}
    \psfragfig[width=5.5in]{\figurepath/sensitivity_tf_lqrpi}{%
      \psfrag{r}[bc][bc][1.0]{$r$}
      \psfrag{rp}[bc][bc][1.0]{$0$}
      \psfrag{m}[bc][bc][1.0]{$-$}
      \psfrag{e}[bc][bc][1.0]{$e$}
      \psfrag{s}[bc][bc][1.0]{$\Sigma$}
      \psfrag{ks}[bc][bc][1.0]{$K(s)$}
      \psfrag{gs}[bc][bc][1.0]{$G(s)$}
      \psfrag{uo}[bc][bc][1.0]{$u_{o}$}
      \psfrag{ui}[bc][bc][1.0]{$u_{i}$}
      \psfrag{yo}[bc][bc][1.0]{$x_{o}$}
      \psfrag{yi}[bc][bc][1.0]{$x_{i}$}
      \psfrag{d}[bc][bc][1.0]{$d$}
      \psfrag{n}[bc][bc][1.0]{$n$}
    }
    \caption{MIMO Control Block Diagram for LQR-PI}
  \end{center}
\end{figure}

The plant which we would like to control is given in state-space form as
\begin{align*}
  \dot{x}_{p}&=A_{p}x_{p}+B_{p}u \\
  y&=C_{p}x_{p}+D_{p}u
\end{align*}
where everything is scalar for the velocity plant subsystem.
An LQR-PI controller can be represented in state-space form as
\begin{align*}
  \dot{x}_{e}&=A_{c}x_{e}+B_{c}e+B_{r}r \\
  u&=K_{V}e+K_{e}x_{e}
\end{align*}
where $e=-V_{T}$ is the full state feedback.
Since
\begin{equation*}
  \dot{x}_{e}=V_{T,\text{cmd}}-V_{T}
\end{equation*}
and $r=V_{T,\text{cmd}}$ the controller can be rewritten
\begin{align*}
  \dot{x}_{e}&=0x_{e}-B_{c}V_{T}+B_{r}V_{T,\text{cmd}} \\
  u&=K_{V}V_{T}+K_{e}x_{e}
\end{align*}

In order to implement anti-windup, logic needs to be written which will reset the integrator.
This logic will require that the actual velocity is greater than the commanded velocity, and the throttle input is saturating for the integrator to be reset.
This will keep integration error from accumulating, causing the throttle to continue to saturate, even while the commanded velocity has been exceeded.
The question is what to reset the integrator to.

In a classical control feedback setup, where the integration error $e=r-y$ needs only to be reset to zero, with LQR-PI this is not the case.
For LQR-PI the reset value is found by first determining the throttle input required to maintain the commanded velocity in equilibrium, based on the plant parameters.
That is
\begin{equation*}
  \dot{V}_{T}=A_{p}V_{T}+B_{p}u_{th}
\end{equation*}
\begin{equation*}
  0=A_{p}V_{T}+B_{p}u_{th}
\end{equation*}
want $V_{T}=V_{T,\text{cmd}}$
\begin{equation*}
  u_{th}=\frac{-A_{p}V_{T,\text{cmd}}}{B_{p}}
\end{equation*}
Then, knowing the required throttle to maintain equilibrium, the value of $x_{e}$ that must exist at equilibrium to maintain this condition (since $V_{T}$, $K_{V}$, and $K_{e}$ are known) can be found
\begin{equation*}
  u_{th}=K_{V}V_{T}+K_{e}x_{e}
\end{equation*}
again ith $V_{T}=V_{T,\text{cmd}}$
\begin{equation*}
  x_{e}=\frac{u_{th}-K_{V}V_{T,\text{cmd}}}{K_{e}}
\end{equation*}
which is the value the integrator must be reset to.

\section{MIMO Zeros: Introduction}

MIMO zeros for non square systems, MIMO zeros for square systems, how many zeros there will be, how squaring up by augmenting $B$ moves existing zeros.
Zeros of MIMO system not zeros of each TF in the transfer matrix.
See 16.31 Lecture 8.

\begin{defn-dan}[MIMO zeros]
  Zeros of a MIMO system are $\zeta_{0}$ such that $\lim_{s\rightarrow\zeta_{0}}\left(H(s)u(s)\right)=0$.
\end{defn-dan}

\begin{example}
  The following system has a zero at $s=3$.

  \begin{equation*}
    H(s)=
    \begin{bmatrix}
      1 & \frac{1}{s-3} \\
      0 & 1
    \end{bmatrix}
    \hspace{0.5in}
    u(s)=
    \begin{bmatrix}
      -1 \\
      s-3
    \end{bmatrix}
  \end{equation*}
  $u$ is finite.
\end{example}

\begin{equation*}
  \lim_{s\rightarrow3}
  \left(
    \begin{bmatrix}
      1 & \frac{1}{s-3} \\
      0 & 1
    \end{bmatrix}
    \begin{bmatrix}
      -1 \\
      s-3
    \end{bmatrix}
  \right)=
  \lim_{s\rightarrow3}
  \begin{bmatrix}
    0 \\
    s-3
  \end{bmatrix}=
  \begin{bmatrix}
    0 \\
    0
  \end{bmatrix}
\end{equation*}

%http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-241j-dynamic-systems-and-control-spring-2011/readings/MIT6_241JS11_chap27.pdf

$H(s)$ has a pole at a frequency $p_{0}$ if some entry of $H(s)$ has a pole at $s=p_{0}$.

From DDV book: $H(s)$ has a zero at $\zeta_{0}$ if it \textit{drops rank} at $s=\zeta_{0}$.
This particular defnition corresponds to what is termed a \textit{transmission zero}.

$H(s)$ has full column rank if there is no rational vector $u(s)\neq0$ such that $H(s)u(s)=0$.
At a transmission zero of $H(s)$, it will drop rank, and then there is a $u_{0}\neq0$ such that $H(\zeta_{0})u_{0}=0$.
The problem with this is if the MIMO system has a pole at the same frequency as a zero, and so this zero may not be detected.

MIMO transfer functions can have poles and zeros at the same frequency.
So the refined zero definition is the limit one above.
The above example is from DDV.\@
We can see there is a pole at 3, but if we look in the limit as $s\rightarrow3$ we see that the second column looks like the first one:
\begin{equation*}
  \begin{bmatrix}
    1 \\
    0
  \end{bmatrix}
  \hspace{0.5in}
  \begin{bmatrix}
    \infty \\
    1
  \end{bmatrix}
\end{equation*}
(the ratio of the terms in each column are $\infty$) So we use the updated definition text and find the zero.

The following matrix is the Rosenbrock matrix.
\begin{equation*}
  R(s)=
  \begin{bmatrix}
    sI-A & -B \\
    C & D
  \end{bmatrix}
\end{equation*}

\begin{itemize}
  \item{$sI-A$ is full rank, except at system poles}
  \item{\textbf{Input decoupling zeros} are where the following matrix loses rank, which can only happen when $sI-A$ loses rank.}
  \begin{equation*}
    R_{I}(s)=\begin{bmatrix} sI-A & -B \end{bmatrix}
  \end{equation*}
  \textit{Input decoupling zeros are a subset of system poles}
  \item{\textbf{Output decoupling zeros} are $s$ where the following matrix loses rank}
  \begin{equation*}
    R_{O}(s)=\begin{bmatrix} sI-A \\ C \end{bmatrix}
  \end{equation*}
  \textit{Output decoupling zeros are a subset of system poles}
  \item{\textbf{Invariant zeros} are values of $s$ where $\text{rank}(S(s))<\text{min}\{n+\text{rank}(B),n+\text{rank}(C)\}$}
  \item{For a controllable and observable system, the invariant zeros are the same as the transmission zeros}
\end{itemize}

\textit{Difference between invariant zeros and transmission zeros?}

\textit{Difference between a system's transfer function $G(s)=C(sI-A)^{-1}B$ and its realization $\Sigma_{p}=\{A,B,C\}$?}

\chapter{Passivity}

% \section{Introduction}

The concept of passivity was first introduced by Popov.
The essential feature of a passive system is its inability to increase its own energy~\cite{terrell.stability.2009}.
For example, a network of passive components, e.g.\ inductors, resistors, and capacitors does not generate any energy and is therefore stable.
Another example given in Reference~\cite{bao.process.2007} is a gravity tank into which water flows in to the top of the tank and out through the bottom.
It is straightforward to show that the rate of change of stored energy in the tank is less than that supplied to it by the inlet flow rate.
Passivity relates a system's input and output to the storage function and thus defines a set of useful input-output properties~\cite{bao.process.2007}.
The following document repeats some definitions from the literature and presents an example of a passive and non-passive system using a mass-spring-damper.

% \section{Preliminaries}

Consider the following square system $\Sigma$:
\begin{equation}
  \label{eqn.nonlinear_system}
  \begin{split}
    \dot{x} & = f(x,u) \\
    y & = h(x,u)
  \end{split}
\end{equation}
where $x\in \mathcal{X}\subset\mathbb{R}^{n}$, $y\in \mathcal{Y}\subset\mathbb{R}^{m}$ and $u\in \mathcal{U}\subset\mathbb{R}^{m}$.
The \textit{Instantaneous Power Supply Rate} is denoted~\cite{willems.part1.1972}
\begin{equation}
  w=w(u(t),y(t))
\end{equation}

\begin{ass-dan} $ $\cite{willems.part1.1972}, pp.~327
  Given the system in~\eqref{eqn.nonlinear_system} the instantaneous power supply rate $w(t)$ satisfies
  \begin{equation*}
    \int_{t_{0}}^{t_{1}}|w(\tau)|d\tau<\infty
    \qquad
    \forall t\geq0
  \end{equation*}
\end{ass-dan}

\begin{defn-dan}[Dissipative System and Storage Function]\label{defn.dissipative}\cite{willems.part1.1972}, pp.~327.
  The system in~\eqref{eqn.nonlinear_system} with supply rate $w$ is \textit{dissipative} if there exists a positive semi-definite function $S(x):\mathcal{X}\rightarrow\mathbb{R}^{+}$, called the \textit{Storage Function} such that
  \begin{equation}
    \label{eqn.storage_inequality}
    S(x(t_{1}))-S(x(t_{0}))\leq\int_{t_{0}}^{t_{1}}w(\tau)d\tau
  \end{equation}
  for all $x\in \mathcal{X}$, $u\in \mathcal{U}$ and $t\geq0$.
\end{defn-dan}

The inequality in~\eqref{eqn.storage_inequality} is called the \textit{dissipation inequality}, and says that the stored energy $S(x(t_{1}))$ at time $t_{1}$ can never be greater than the sum of the initial energy in the system at time $t_{0}$ plus the energy into the system between $t_{0}$ and $t_{1}$.
In other words, the system in~\eqref{eqn.nonlinear_system} is dissipative if it is not generating any internal power: the increase in energy (storage function) during the interval $(t_{0},t_{1})$ is no greater than the energy supplied (via the supply rate) to it.


\begin{defn-dan}[Passive System]\cite{byrnes.passivitiy.1991}
  pp.~1229\label{defn.passive}
  The system $\Sigma$ in~\eqref{eqn.nonlinear_system} in \textit{passive} if it is dissipative with respect to the following supply rate
  \begin{equation}
    w(u(t),y(t))=y(t)^{\top}u(t)
  \end{equation}
  and the storage function $S$ satisfies $S(0)=0$.
\end{defn-dan}


%See definition of passivity 1 from Wyatt.
%
%Passive if:
%\begin{equation*}
%\int_{0}^{T}y^{\top}(t)u(t)dt \geq 0
%\end{equation*}

\begin{example}
  \textbf{Mass-spring-damper}
  Take a mass-spring-damper system, and let $m=1$, $b=1$, and $k=1$.
  The transfer function from force to \textit{velocity} is given by the following:
  \begin{equation*}
    \frac{V(s)}{F(s)} = \frac{s}{s^{2}+s+1}
  \end{equation*}
  Given a sinusoidal input
  \begin{equation}
    \label{eqn.sinusoidalInput}
    u(t) = f(t) = \sin(\omega t)
  \end{equation}
  we can show the particular solution has the following form
  \begin{equation}
    \label{eqn.particularSolution}
    y(t) = v(t) = A\sin(\omega t + \phi)
  \end{equation}
  where the phase shift $\phi\in(0, \pi/2)$.
  With this input and choice of output we use Definition~\ref{defn.dissipative} and show that the system is dissipative with respect to the following supply rate, as given in Definition~\ref{defn.passive}.
  \begin{equation}
    \label{eqn.exSupplyRate}
    w(u(t),y(t)) = A\sin(\omega t + \phi)\sin(\omega t)
  \end{equation}
  We evaluate the following integral from Definition~\ref{defn.dissipative} from $t_{0}$ to $t_{1}$
  \begin{equation*}
    \int_{t_{0}}^{t_{1}} A\sin(\omega \tau + \phi)\sin(\omega \tau) d\tau
  \end{equation*}
  and using the identity
  \begin{equation*}
    \sin(a)\sin(b) = \frac{1}{2}\left[\cos(a-b) - \cos(a+b)\right]
  \end{equation*}
  we can rewrite and then evaluate the integral as follows
  \begin{equation}
    \label{eqn.evaluateIntegral}
    \begin{split}
      \int_{t_{0}}^{t_{1}} A\sin(\omega \tau + \phi)\sin(\omega \tau) d\tau
      &=
      \frac{1}{2} \int_{t_{0}}^{t_{1}} \cos(\phi) - \cos(2\omega\tau + \phi) d\tau \\
      &=
      \frac{1}{2}\cos(\phi)\tau\biggr|_{t_{0}}^{t_{1}} - \frac{1}{4\omega}\sin(2\omega\tau + \phi)\biggr|_{t_{0}}^{t_{1}} \\
      &=
      \frac{1}{2}\cos(\phi)(t_{1}-t_{0}) -\biggr[\frac{1}{4\omega}\sin(2\omega t_{1} + \phi) - \frac{1}{4\omega}\sin(2\omega t_{0} + \phi)\biggr]
    \end{split}
  \end{equation}
  From this we can see the bracketed term is bounded and the first term is always positive because the phase shift between force and velocity is $\phi\in(0, \pi/2)$.
  This example is not sufficient to show that the mass-spring-damper with velocity as an output is or is not passive, but is useful to see.

  However, if \textit{position} is selected as the output, the transfer function is given by
  \begin{equation*}
  \frac{X(s)}{F(s)} = \frac{1}{s^{2}+s+1}
  \end{equation*}
  If now this system is driven by a sinusoidal input as in~\eqref{eqn.sinusoidalInput} we can again show that the output is given by~\eqref{eqn.particularSolution} where now $\phi\in(0,\pi)$.
  As before, the supply rate in Definition~\ref{defn.passive} is given by~\eqref{eqn.exSupplyRate}.
  We evaluate the integral from Definition~\ref{defn.dissipative} with this supply rate and get~\eqref{eqn.evaluateIntegral}.
  The difference now is that $\phi\in(0,\pi)$ and so the first term in~\eqref{eqn.evaluateIntegral} for the case where \textit{position} is the output is negative for all $\phi>\pi/2$, while the bracketed term remains bounded.
  So we can see that when driving the system with a sufficiently large input frequency, we can pick $t_{0}$ and $t_{1}$ such that no positive semi-definite storage function exists satisfying the inequality~\eqref{eqn.storage_inequality}.
  Thus the spring-mass-damper system with force as an input and \textit{position} as an output is not passive.
\end{example}

\section{Difference Between Passive and Positive Real}

For linear time invariant systems they are the same, as long as the system is detectable.\cite{bao.process.2007}
Passive systems are positive real.
``The notion of Positive Real system may be seen as a generalization of the positive definiteness of a matrix to the case of a dynamical system with inputs and outputs'' Reference~\cite{lozano.dissipative.2000}
Positive-realness is a property of a function of a complex variable $s$.
From Reference~\cite{bao.process.2007}, pp.~14\textemdash{}15.
The input-output property of passive systems is called positive realness.
Passivity implies positive realness.
For a detectable LTI system passivity is equivalent to positive realness.
For LTI systems passive and positive real are the same.

\begin{defn-dan}[Available Storage]\label{defn.available_storage}\cite{willems.part1.1972}, pp.~327
  The \textit{available storage}, $S_{a}$ of a dynamical system $\Sigma$ with supply rate $w$ is the function from $X$ into $R^{e}$, where $R^{e}$ is the extended real number system $\{-\infty\}\cup\mathbb{R}\cup\{\infty\}$, is defined by
  \begin{equation*}
    S_{a}(x) = \sup_{x\rightarrow t_{1}\geq 0} -\int_{0}^{t_{1}}w(t)dt
  \end{equation*}
  where the notation $x\rightarrow$ denotes the supremum over all motions starting in state $x$ at time $0$ and where the supremum is taken over all $u\in\mathcal{U}$.
\end{defn-dan}

\begin{thm-dan}[{$\;$\hspace{-0.1in}}]\label{thm.storage_dissipative}\cite{willems.part1.1972}
  pp.~328
  The available storage, $S_{a}$, is finite for all $x\in X$ if and only if $\Sigma$ is dissipative.
\end{thm-dan}

\begin{example}
  \textbf{Mass with velocity output}\label{example.massvout}
  Consider a mass $m$ with force $f$ as the input and velocity $v$ as the output.
  This system is represented as
  \begin{equation*}
    f = m \dot{v}
  \end{equation*}
  or in the form of~\eqref{eqn.control_affine_system} with $x=v$, $u=f$, $y=v$,$f(x)=0$, $g(x)=\frac{1}{m}$ and $h(x)=x$.
  This system is passive if it is dissipative with respect to $w=fv$.
  That is the inequality in Definition~\ref{defn.dissipative} must be satisfied for all $x$, $u$, and $t\geq0$.
  The mass starts from rest at time $t_{0}=0$ and is driven by a sinusoidal force input
  \begin{equation*}
    f = \sin (t)
  \end{equation*}

  The velocity of the system is given by
  \begin{equation*}
    \begin{split}
      v &= \frac{1}{m} \int_{0}^{t} \sin (\tau) d\tau \\
      &= \frac{1}{m}(1-\cos (t))
    \end{split}
  \end{equation*}
  Look at the inequality in~\eqref{eqn.passive} with this particular choice of $f$ and the corresponding $v$, the system is passive if it satisfies the following inequality
  \begin{equation*}
    0 \leq \frac{1}{m} \int_{0}^{t} \sin (\tau) (1-\cos (\tau)) d\tau
  \end{equation*}
  This function is periodic and we can look at the integral over the first period and argue that this inequality is always satisfied.
\end{example}

\begin{example}
  \textbf{Mass with position output}
  If we go through the same process as in Example~\ref{example.massvout} only now taking the position output, it is easy to show that our choice of $f$ does not satisfy Definition~\ref{defn.dissipative} for all $t$, indicating that in this case the system is \textit{not} passive.
  \begin{equation*}
    f = m \ddot{x}
  \end{equation*}
  integrating, with zero initial conditions
  \begin{equation*}
    \dot{x} = \frac{1}{m} \int_{0}^{t}f d\tau
  \end{equation*}
  This system is in the form of~\eqref{eqn.nonlinear_system} with $u=f$ and $y=\dot{x}$.
   we choose $u=\sin(t)$,
  \begin{equation*}
    \begin{split}
      \dot{x} &= \frac{1}{m} \int_{0}^{t}\sin(\tau) d\tau \\
      &= -\frac{1}{m} \cos(\tau)\bigr|_{0}^{t} \\
      &= -\frac{1}{m} \bigr(\cos(t) - 1\bigr) \\
    \end{split}
  \end{equation*}
  Integrating again
  \begin{equation*}
    \begin{split}
      x &= \frac{1}{m} \int_{0}^{t} 1 - \cos(\tau) d\tau \\
      &= \frac{1}{m}\bigr(t - \sin(t)\bigr) \\
    \end{split}
  \end{equation*}
  Now we can let $m=1$ and calculate the supply rate $w$ as
  \begin{equation*}
    \begin{split}
      w &= ux \\
      &= \sin(t)\bigr(t - \sin(t)\bigr)
    \end{split}
  \end{equation*}
  Using Definition~\ref{defn.available_storage} to determine the available storage
  \begin{equation*}
    S_{a}(x) = \sup_{x\rightarrow t_{1}\geq 0} -\int_{0}^{t_{1}}\sin(t)\bigr(t - \sin(t)\bigr)dt
  \end{equation*}
  Integrating this we get
  \begin{equation*}
    S_{a}(x) = \sup_{x\rightarrow t_{1}\geq 0} -\frac{1}{4}\bigr(-2t+4\sin(t)+\sin(2t)-4t\cos(t)\bigr)\biggr|_{0}^{t_{1}}
  \end{equation*}
  which is not finite as $t_{1}\rightarrow\infty$.
  Thus, by Theorem~\ref{thm.storage_dissipative} this system is not dissipative.
  Since it is not dissipative with respect to the supply rate $w=uy$, by Definition~\ref{defn.passive} this system is not passive.

  %The following is a plot of $\sin(t)\bigr(t - \sin(t)\bigr)$
  %\begin{center}
  %\includegraphics[width=3in]{sinxtimestminussinx.pdf}
  %\end{center}

  %Look also at the differential form of the dissipation inequality
  %\begin{equation*}
  %\frac{d}{dt}S(x(t)) \leq w
  %\end{equation*}

\end{example}

\section{More Stuff}

Reference~\cite{kottenstette.passive.2010} gives some definitions of passive and SPR.\@
If the storage function in~\eqref{eqn.storage_inequality} is differentiable, we can write~\eqref{eqn.storage_inequality} as

\begin{equation*}
  \frac{dS}{dt}\leq w(t)
\end{equation*}
which says that the rate of increase of system energy is no greater than the input power~\cite{bao.process.2007}.
Consider now a special case of~\eqref{eqn.nonlinear_system}

%\begin{defn-dan}[Power Supply Rate]
%\cite{terrell.stability.2009}
%Given the system in \eqref{eqn.nonlinear_system} the \textit{Power Supply Rate} $w(t)$
%\begin{equation}
%w(u(t),y(t))\triangleq y(t)^{\top}u(t)
%\end{equation}
%\end{defn-dan}

\begin{equation}
  \label{eqn.control_affine_system}
  \begin{split}
    \dot{x} & = f(x) + g(x)u \\
    y & = h(x)
  \end{split}
\end{equation}

If we look at Definition~\ref{defn.dissipative} and Definition~\ref{defn.passive}, the system in~\eqref{eqn.control_affine_system} with $x_{0}=0$ is passive if

\begin{equation}
  \label{eqn.passive}
  0\leq S(x(t))\leq\int_{0}^{t}y^{\top}(\tau)u(\tau)d\tau
\end{equation}
for all $x\in \mathcal{X}$, $u\in \mathcal{U}$ and $t\geq0$.

\begin{defn-dan}[Positive-Real System]\cite{byrnes.passivitiy.1991}
  pp.~1230
  The system in~\eqref{eqn.control_affine_system} is \textit{positive-real} if for all $t\geq0$
  \begin{equation*}
    0\leq\int_{0}^{t}y^{\top}(\tau)u(\tau)d\tau
  \end{equation*}
  whenever $x(0)=0$.
\end{defn-dan}

\begin{defn-dan}[Positive-Real System]\cite{narendra.stable.2005}
  pp.~63
  A rational function $H(s)$ of the complex variable $s=\sigma+j\omega$ is PR if
  \begin{enumerate}[(i)]
    \item{$H(s)$ is real for real $s$}
    \item{$\text{Re}[H(s)]\geq0$ for all $\text{Re}[s]>0$}
  \end{enumerate}
\end{defn-dan}

The essential feature of a passive system is its inability to increase its own energy.\cite{terrell.stability.2009} Think about a system that is just a mass.
$E$ is energy, $P$ is power \textit{into} the system, and power is the time rate of change of energy

\begin{equation*}
  \frac{d}{dt}\text{[stored energy] = external power input + internal power generation}
\end{equation*}

\begin{equation*}
  P=\frac{d}{dt}E
\end{equation*}
Integrating both sides

\begin{equation*}
  E(t)=E(0)+\int_{0}^{t}P(\tau)d\tau
\end{equation*}
A passive element is one for which $E(t)\geq0$ for all $t$.
For if not, this would mean that the integral of power is negative, even more negative than $E(0)$, meaning the system increased its own energy.
If we think about our system that is a mass, power is given by force times velocity

\begin{equation*}
  E(t)=E(0)+\int_{0}^{t}f(\tau)v(\tau)d\tau
\end{equation*}
And we know this is true.
However, the definition for passive systems is more complicated than this, as it is an input output property of a system, and thus depends on which inputs and outputs are used.

\subsection{The Dissipation Inequality}

We said before that a passive system is one that cannot deliver more energy than it has received.
But when we say ``energy'', what we mean is the integral of an \textit{instantaneous power supply rate}, which does not have to correspond to physical energy.

The definition of passivity relates the change in storage along solutions to the total supply, which is given by the integral of the supply rate, and the supply rate $y^{\top}u$ involves only the input and output.
The \textit{supply}, or \textit{instantaneous power supply rate} $w(u,y)$ is given by

\begin{equation*}
  w(u,y)=y^{\top}u
\end{equation*}

\begin{equation*}
  \dot{S}=y^{\top}u-g
\end{equation*}
where $g$ is used in Slotine's book Reference~\cite{slotine.appliednonlinear.1991} as the negative of the internal power generation term, i.e.\ $g\geq0$ for passive system.
$S$ is a \textit{storage function}, and is positive-semidefinite.
Since $S$ need only be positive semi-definite, it does not make it necessarily a Lyapunov function.
The storage function for a passive linear system must be quadratic.

\subsection{How to Determine if a System is Passive}

\begin{defn-dan}
  a strictly stable linear SISO is passive if and only if
  \begin{equation*}
    \forall\omega\geq 0, \text{~Re}[h(j\omega)]\geq0
  \end{equation*}
\end{defn-dan}

\begin{defn-dan}
  a strictly stable linear SISO is passive if and only if its phase shift in response to a sinusoidal input is always less than or equal to 90$^{\circ}$.
\end{defn-dan}

Properties
\begin{enumerate}
  \item{Necessary conditions for passivity: system be minimum phase and relative degree 0 or 1.}
  \item{%
    Passive system are not necessarily stable.
    This is only the case if a positive-definite storage function is used, but since the storage function only needs to be positive-semi-definite, stability is not always ensured by passivity~\cite{bao.process.2007}.
  }
\end{enumerate}

The poles of LTI passive systems have negative real parts.

\subsection{Interconnections of Passive Systems}

Parallel and feedback interconnections of passive systems are passive.\cite{lozano.dissipative.2000}

``If the system $Z(s)$ is SPR, this implies that the system remains stable for any positive static gain, even arbitrarily large, i.e.\ $Z(s)/(1+kZ(s))$ is stable for any $k\geq0$.''

\subsection{Positive Real Systems in Adaptive Control}

``The choice of the Lyapunov function is simplified substantially when the transfer function of the relevant linear time-invariant system is strictly positive real.''~\cite{rusnak.spr.2009}

\begin{equation*}
  \begin{split}
    \dot{e}_{x} &= (A+LC+B\Psi^{\top})e_{x} + B\Lambda\widetilde{\Theta}^{\top}x_{m} \\
    e_{y} &= Ce_{x}
  \end{split}
\end{equation*}

\section{Householder Transformation}

A Householder transformation is a linear transformation that can be used to transform a given matrix into one which is upper diagonal.
This transformation is Hermitian and unitary.
For operations on the matrices describing a linear state space system, all entries will be real valued, and so in the rest of this document we assume the Householder transformation matrix $H$ is real valued, and give its properties with this assumption.

\begin{equation*}
  H^{\top}=H^{-1}
\end{equation*}

When applying the Householder transformation we essentially want to find the matrix $H\in\mathbb{R}^{n\times n}$ such that given a vector $x\in\mathbb{R}^{n}$, when multiplied by $H$ gives the following
\begin{equation*}
  Hx=y
\end{equation*}
where
\begin{equation*}
  \begin{split}
    y&=
    \begin{bmatrix}
    \hat{x} & 0 \hdots & 0
    \end{bmatrix}^{\top} \\
    &=\hat{x}\mathbf{e}_{1}^{\top}
  \end{split}
\end{equation*}
where $\mathbf{e}_{1}$ is the standard basis vector
\begin{equation*}
  \mathbf{e}_{1}=
  \begin{bmatrix}
    1 & 0 \hdots & 0
  \end{bmatrix}^{\top}
\end{equation*}

%\begin{equation*}
%Hx=
%\begin{bmatrix}
%\hat{x} \\
%0 \\
%\vdots \\
%0
%\end{bmatrix}
%\end{equation*}

\subsection{Properties}

The Householder matrix is a matrix of the following form

\begin{equation*}
  H=I-2ww^{\top}
\end{equation*}
where $w\in\mathbb{R}^{n\times1}$ is a unit vector.
Evaluate the following

\begin{equation*}
  \begin{split}
    H^{\top}H&=(I-2ww^{\top})^{\top}(I-2ww^{\top}) \\
    &=(I-2ww^{\top})(I-2ww^{\top}) \\
    &=I-2ww^{\top}-2ww^{\top}+4ww^{\top}ww^{\top} \\
    &=I-4ww^{\top}+4w(w^{\top}w)w^{\top} \\
    &=I
  \end{split}
\end{equation*}
From this we see that the following property is in fact satisfied by $H$

\begin{equation*}
  H^{\top}=H^{-1}
\end{equation*}
Suppose we pick the unit vector $w$ as follows

\begin{equation*}
  w=\frac{u}{\|u\|}
\end{equation*}
where

\begin{equation*}
  u=x-\|x\|\mathbf{e}_{1}
\end{equation*}
giving

\begin{equation*}
  w=\frac{x-\|x\|\mathbf{e}_{1}}{\|x-\|x\|\mathbf{e}_{1}\|}
\end{equation*}
This gives

\begin{equation*}
  \begin{split}
    Hx&=(I-2ww^{\top})x \\
    &=x-2\left(\frac{x-\|x\|\mathbf{e}_{1}}{\|x-\|x\|\mathbf{e}_{1}\|}\right)\left(\frac{x-\|x\|\mathbf{e}_{1}}{\|x-\|x\|\mathbf{e}_{1}\|}\right)^{\top} \\
    &= \\
    &=\|x\|\mathbf{e}_{1}
  \end{split}
\end{equation*}
So we have defined $H$, showed that it is an orthogonal transformation, and showed how to pick $w$ so that $Hx=\hat{x}\mathbf{e}_{1}$.
The following section will clearly lay out the steps to code this algorithm for taking a matrix and making it upper diagonal.

\subsection{Applying Householder Transformation}

Given a matrix $B\in\mathbb{R}^{N\times M}$

\begin{equation*}
  B=
  \begin{bmatrix}
    B_{1} & B_{2} & \hdots & B_{m}
  \end{bmatrix}
\end{equation*}
where each $B_{i}\in\mathbb{R}^{N\times1}$.
We apply the Householder transformation to the first column first, and the proceed with the remaining columns.
Define

\begin{equation*}
  \mathbf{e}_{1}\in\mathbb{R}^{n\times1}
\end{equation*}
Let

\begin{equation*}
  x=B_{i}(i:N,i)
\end{equation*}
Note each $x\in\mathbb{R}^{n\times1}$, where $n=N-i$.
Calculate

\begin{equation*}
  \hat{x}=\|x\|
\end{equation*}
Calculate

\begin{equation*}
  w=\frac{x-\|x\|\mathbf{e}_{1}}{\|x-\|x\|\mathbf{e}_{1}\|}
\end{equation*}
Basically the idea is that at transforming the columns of $B$ in each step the calculated Householder matrix decreases in size, but we need to keep the matrix $N\times N$, so that when we multiply $H_{2}H_{1}B$, that $H_{2}$ will not alter the first column of $H_{1}B$.

\begin{equation*}
  H_{1}B=
  \begin{bmatrix}
    \hat{x}_{1}\mathbf{e}_{1} & B_{2} & \hdots & B_{m}
  \end{bmatrix}
\end{equation*}

\begin{equation*}
  H_{2}=
  \begin{bmatrix}
    1 & 0 \\
    0 & H_{\text{temp},2}
  \end{bmatrix}
\end{equation*}
Then, to find the matrix $T$, which will transform $B$ to an upper diagonal form, multiply the $H$ matrices together as

\begin{equation*}
  T=H_{m}\cdots H_{2}H_{1}
\end{equation*}
And we can show that $T$ is also an orthogonal transformation.
Because each $H_{i}^{\top}=H_{i}^{-1}$ and so

\begin{equation*}
  \begin{split}
    T^{\top}&=(H_{m}\cdots H_{2}H_{1})^{\top} \\
    &=H_{1}^{\top}H_{2}^{\top}\cdots H_{m}^{\top} \\
    &=H_{1}^{-1}H_{2}^{-1}\cdots H_{m}^{-1} \\
    &=(H_{m}\cdots H_{2}H_{1})^{-1} \\
    &=T^{-1}
  \end{split}
\end{equation*}

\section{Controls Quals Notes}

\subsection{Frequency Domain}

Frequency response method: give a system a sinusoidal input.
The output (will always be?) a sinusoid, with a magnitude and phase which may be different than the input, but the frequency will be the same.
Then, sweep the input frequency across a wide range, and observe how the gain and phase shift of the measured output change with frequency.

\subsection{Gain and Phase of Poles and Zeros}

\textit{Why do zeros add phase and poles reduce phase?}
These two examples that follow connect the transfer function representation of the integrator and differentiator to a differential equation and show how, when the system is given a sinusoidal input, that the zero causes the output to lead the input, and the pole causes the output to lag behind the input.
\begin{equation*}
  \frac{x}{u}=\frac{1}{s}
\end{equation*}
The differential equation is
\begin{equation*}
  \dot{x}=u
\end{equation*}
This whole thing of gain and phase is for a given sinusoidal input, so $u(t)=A\sin(\omega t)$ and then we want to see how that will affect the output $x(t)$ for this system.
\begin{equation*}
  \frac{dx}{dt}=A\sin(\omega t)
\end{equation*}
separate and integrate back
\begin{equation*}
  \int_{x_{0}}^{x} dx=\int_{t_{0}}^{t} A\sin(\omega t)dt
\end{equation*}
giving
\begin{equation*}
  x-x_{0}=-\frac{A}{\omega}\cos(\omega t)+\frac{A}{\omega}\cos(\omega t_{0})
\end{equation*}

\begin{equation*}
  x(t)=-\frac{A}{\omega}\cos(\omega t)+\frac{A}{\omega}\cos(\omega t_{0})+x_{0}
\end{equation*}

\begin{equation*}
  x(t)=-\frac{A}{\omega}\cos(\omega t)
\end{equation*}
but $-\cos(x)=\sin(x-90^{\circ})$ so the input and corresponding output can be written
\begin{equation*}
  \begin{split}
    u(t)&=A\sin(\omega t) \\
    x(t)&=\frac{A}{\omega}\sin(\omega t-90^{\circ})
  \end{split}
\end{equation*}
So we can see that the magnitude of the output depends inversely on $\omega$, getting smaller as $\omega$ gets larger.
More importantly we can see clearly that there is a $90^{\circ}$ phase lag from the input to the output.

Consider now a differentiator.
\begin{equation*}
  \frac{x}{u}=s
\end{equation*}
gives
\begin{equation*}
  x=\dot{u}
\end{equation*}
and with $u(t)=A\sin(\omega t)$ we have
\begin{equation*}
  x(t)=A\omega\cos(\omega t)
\end{equation*}
together the input and output are
\begin{equation*}
  \begin{split}
    u(t)&=A\sin(\omega t) \\
    x(t)&=A\omega\cos(\omega t)
  \end{split}
\end{equation*}
But we have $\cos(x)=\sin(x+90^{\circ})$ giving
\begin{equation*}
  \begin{split}
    u(t)&=A\sin(\omega t) \\
    x(t)&=A\omega\sin(x+90^{\circ})
  \end{split}
\end{equation*}
and here we can see that there is a positive phase shift, or say that the output leads the input by $90$ degrees.

\subsection{How to Make Bode Plots}

first normalize the transfer function, so all the factors look like $(1+sa_{i})$
